{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680a827b",
   "metadata": {},
   "source": [
    "# PDF Text Extraction and Processing\n",
    "\n",
    "This notebook demonstrates how to extract text from PDF files, process the content, and prepare it for further analysis.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d75e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6e427",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1b8980",
   "metadata": {},
   "source": [
    "## PDF Text Extraction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395560f",
   "metadata": {},
   "source": [
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = pypdf.PdfReader(file)\n",
    "            text = \"\"\n",
    "            \n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "            \n",
    "            return {\n",
    "                'filename': os.path.basename(pdf_path),\n",
    "                'text': text,\n",
    "                'pages': len(pdf_reader.pages)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20547a4d",
   "metadata": {},
   "source": [
    "## Loading PDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ceb97c",
   "metadata": {},
   "source": [
    "# Load all PDFs from directory\n",
    "pdf_files = list(Path(DATA_DIR).glob('**/*.pdf'))\n",
    "print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "# Process PDFs\n",
    "documents = []\n",
    "for pdf_path in tqdm(pdf_files):\n",
    "    doc = extract_text_from_pdf(pdf_path)\n",
    "    if doc:\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65c73f",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55bcbf",
   "metadata": {},
   "source": [
    "python# Create a DataFrame\n",
    "df = pd.DataFrame(documents)\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"Total documents: {len(df)}\")\n",
    "print(\"\\nDocument page distribution:\")\n",
    "print(df['pages'].describe())\n",
    "\n",
    "# Calculate text length\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "print(\"\\nText length statistics:\")\n",
    "print(df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef5d89",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d68ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize page count\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['pages'])\n",
    "plt.title('Number of Pages per Document')\n",
    "plt.xlabel('Pages')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01bedd",
   "metadata": {},
   "source": [
    "## Text Chunking for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a10f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks for better retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "# Process chunks\n",
    "all_chunks = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    chunks = text_splitter.split_text(row['text'])\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        all_chunks.append({\n",
    "            'chunk_id': f\"{row['filename']}_{i}\",\n",
    "            'document': row['filename'],\n",
    "            'text': chunk,\n",
    "            'chunk_length': len(chunk)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90f8e6",
   "metadata": {},
   "source": [
    "## Analyzing Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd969b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks DataFrame\n",
    "chunks_df = pd.DataFrame(all_chunks)\n",
    "\n",
    "print(f\"\\nTotal chunks created: {len(chunks_df)}\")\n",
    "print(f\"Average chunks per document: {len(chunks_df) / len(df):.2f}\")\n",
    "\n",
    "# Sample a chunk\n",
    "print(\"\\nSample chunk:\")\n",
    "sample = chunks_df.sample(1).iloc[0]\n",
    "print(f\"Document: {sample['document']}\")\n",
    "print(f\"Chunk ID: {sample['chunk_id']}\")\n",
    "print(f\"Preview: {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ab50e",
   "metadata": {},
   "source": [
    "## Saving Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9650912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed chunks for ingestion\n",
    "chunks_df.to_csv('processed_chunks.csv', index=False)\n",
    "print(f\"Saved {len(chunks_df)} chunks to processed_chunks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c8b357a39b9cfa652ce5eb494eea21f40e33742edb285e95e5860972a45bd4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
