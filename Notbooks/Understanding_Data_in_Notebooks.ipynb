{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Understanding Data in Notebooks\n", "### Assignment 2: Data Cleaning, Visualization, and Analysis\n", "**Authors:** Chaitanya Ravindra Inamdar, Shreya Deshpande, Ajin Abraham\n\n", "## 1. Abstract\n", "In this notebook, we explore the process of data cleaning, transformation, and visualization using the Iris dataset. We demonstrate how to handle missing data, normalize features, and use various Python libraries to visualize the dataset. The aim is to understand how these processes improve the accuracy of data analysis and decision-making.\n", "We conclude by showing how visual insights derived from cleaned and prepared data can provide actionable outcomes for further machine learning modeling.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Theory and Background\n", "Data cleaning and visualization play a vital role in ensuring accurate data analysis. According to research, up to 80% of the time in a data science project is spent cleaning and transforming data. This notebook demonstrates key principles such as handling missing data, normalizing values, and visualizing relationships between variables.\n", "We use the Iris dataset, a well-known dataset in the field of machine learning, to showcase how interactive environments like Jupyter Notebooks are excellent for real-time data exploration and visualization.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Problem Statement\n", "The Iris dataset contains measurements of iris flowers' sepals and petals. The challenge is to clean the dataset by handling missing data and transforming the values to prepare it for further analysis. This requires:\n", "- Handling missing values (imputation or removal)\n", "- Normalizing numerical features for model compatibility\n", "- Visualizing relationships between variables\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# 4. Data Preprocessing\n", "# Import necessary libraries\n", "import pandas as pd\n", "import seaborn as sns\n", "from sklearn.preprocessing import StandardScaler\n", "import matplotlib.pyplot as plt\n\n", "# Load the Iris dataset\n", "iris = sns.load_dataset('iris')\n\n", "# Check for missing values\n", "print(\"Missing values per column:\")\n", "print(iris.isnull().sum())\n\n", "# Fill missing values (if any) with the mean\n", "iris.fillna(iris.mean(), inplace=True)\n\n", "# Normalize the features (excluding the 'species' column)\n", "scaler = StandardScaler()\n", "iris_scaled = pd.DataFrame(scaler.fit_transform(iris.drop('species', axis=1)), columns=iris.columns[:-1])\n\n", "# Display the normalized data\n", "iris_scaled.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Explanation:\n", "- We first check for missing values and handle them using the `fillna` function.\n", "- We then normalize the numerical features using `StandardScaler`, which transforms them to have a mean of 0 and a standard deviation of 1.\n", "- This step is crucial for machine learning algorithms that are sensitive to feature scaling.\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# 5. Data Analysis\n", "# Pair plot to visualize feature relationships\n", "sns.pairplot(iris, hue='species')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Results and Data Analysis:\n", "- The pair plot visually demonstrates the relationships between the features in the dataset.\n", "- It helps us understand which features are most important for distinguishing between the species of iris.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Conclusion\n", "In this notebook, we walked through the process of cleaning, normalizing, and visualizing the Iris dataset. We explored how important it is to handle missing data and ensure that all features are scaled correctly. Visualization plays a key role in understanding the relationships between different variables, as demonstrated by the pair plot. This process ensures the data is ready for machine learning models, where the relationships between variables can be leveraged for predictive modeling.\n", "### Future Work:\n", "Further steps could include building machine learning models on the cleaned data, such as classification models to predict the species of an iris flower based on its features."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. References\n", "- Fisher, R.A. (1936). The use of multiple measurements in taxonomic problems. *Annals of Eugenics*, 7(2), 179-188.\n", "- Python Pandas Documentation: https://pandas.pydata.org/\n", "- Seaborn Documentation: https://seaborn.pydata.org/\n", "- Scikit-learn Documentation: https://scikit-learn.org/\n", "- Matplotlib Documentation: https://matplotlib.org/"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}