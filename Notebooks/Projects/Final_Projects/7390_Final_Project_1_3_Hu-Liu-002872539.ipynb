{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-QFeDiGkw1w",
    "outputId": "8e966459-e9d0-48ff-a92b-5d739dc1061b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
      "Requirement already satisfied: tokenizer in /usr/local/lib/python3.11/dist-packages (3.4.5)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets huggingface_hub tokenizer bitsandbytes accelerate streamlit requests beautifulsoup4\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3m43id02lPpE"
   },
   "outputs": [],
   "source": [
    "# ================== Config Section ===================\n",
    "HF_TOKEN = \"HUGGING_FACE_TOKEN\" # Please use your own token, I have removed my token from here;\n",
    "#model_name = \"xiaokeliu/dpo_model_round2\"\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUCybwJxlMgH",
    "outputId": "cfe4f018-ea3b-4737-9289-63f4378f8af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_utils.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def load_model(peft_model_id=\"xiaokeliu/lora_adapter_pair_based\",hf_token=None):\n",
    "    print(\"peft_model_id\",peft_model_id)\n",
    "    peft_config = PeftConfig.from_pretrained(peft_model_id,token=hf_token)\n",
    "    base_model_name = peft_config.base_model_name_or_path\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name,token=hf_token)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_name, token=hf_token,device_map=\"auto\")\n",
    "    model = PeftModel.from_pretrained(base_model, peft_model_id,token=hf_token)\n",
    "\n",
    "    return tokenizer,model\n",
    "def generate_response(model, tokenizer, instruction,num_response = 1):\n",
    "    input_ids = tokenizer.encode(instruction, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask = torch.ones_like(input_ids),\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            num_return_sequences=num_response,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9AXyXSQr76k",
    "outputId": "92dfcaaa-d1b7-4c31-9d14-6f8d45052bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_utils.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def scrape_text_from_url(url):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers,timeout = 10)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching URL: {e}\"\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    content = \"\\n\".join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])\n",
    "\n",
    "\n",
    "    return content[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpdbPu7lnmni",
    "outputId": "f8ef7ede-b336-428c-cc05-3f75e56b0b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "from model_utils import load_model, generate_response\n",
    "from data_utils import scrape_text_from_url\n",
    "\n",
    "st.title(\"AI Instruction Response Generator\")\n",
    "HF_TOKEN = \"HUGGING_FACE_TOKEN\" # Please use your own token, I have removed my token from here;\n",
    "@st.cache_resource\n",
    "def setup():\n",
    "  return load_model(hf_token=HF_TOKEN)\n",
    "\n",
    "#\n",
    "tokenizer, model = setup()\n",
    "\n",
    "instruction = st.text_area(\"Enter your question: \", height=200)\n",
    "\n",
    "if st.button(\"Generate Response\"):\n",
    "    if instruction.strip() == \"\":\n",
    "         st.warning(\"Please enter a valid question.\")\n",
    "    else:\n",
    "        with st.spinner(\"Generating response...\"):\n",
    "            outputs = generate_response(model, tokenizer, instruction)\n",
    "            for i, output in enumerate(outputs):\n",
    "                st.markdown(f\"**Response {i+1}:**\")\n",
    "                st.success(output)\n",
    "\n",
    "st.divider()\n",
    "st.header(\"Analyze Web Page Content\")\n",
    "\n",
    "url = st.text_input(\"Enter a URL to scrape (e.g. blog, news):\")\n",
    "\n",
    "if st.button(\"Fetch & Generate\"):\n",
    "    if not url.startswith(\"http\"):\n",
    "        st.warning(\"Please enter a valid URL (starting with http or https).\")\n",
    "    else:\n",
    "        with st.spinner(\"Scraping content...\"):\n",
    "            content = scrape_text_from_url(url)\n",
    "            st.text_area(\"🔍 Preview of scraped content:\", content, height=200)\n",
    "            if len(content.strip()) == 0:\n",
    "                st.error(\"No usable content found.\")\n",
    "            else:\n",
    "                prompt = f\"[INST] Please summarize the following content:\\n{content} [/INST]\"\n",
    "                response = generate_response(model, tokenizer, prompt)[0]\n",
    "                st.markdown(\"**Model Summary:**\")\n",
    "                st.success(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EzVj4mj8tfk",
    "outputId": "47f0e1a2-d248-4a3f-8b18-e77668239f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-23 21:14:08--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.4.0/cloudflared-linux-amd64 [following]\n",
      "--2025-04-23 21:14:08--  https://github.com/cloudflare/cloudflared/releases/download/2025.4.0/cloudflared-linux-amd64\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/f756c1d5-fdc6-4b60-9a49-bdc7883319c0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250423%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250423T211408Z&X-Amz-Expires=300&X-Amz-Signature=ab525d310712bbf1cbe9a4a0780e7d400e057696629acb36f0d0e91f9fe441f6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-04-23 21:14:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/f756c1d5-fdc6-4b60-9a49-bdc7883319c0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250423%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250423T211408Z&X-Amz-Expires=300&X-Amz-Signature=ab525d310712bbf1cbe9a4a0780e7d400e057696629acb36f0d0e91f9fe441f6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37831838 (36M) [application/octet-stream]\n",
      "Saving to: ‘cloudflared’\n",
      "\n",
      "cloudflared         100%[===================>]  36.08M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2025-04-23 21:14:09 (397 MB/s) - ‘cloudflared’ saved [37831838/37831838]\n",
      "\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.142.132.101:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[90m2025-04-23T21:14:14Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
      "\u001b[90m2025-04-23T21:14:14Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m |  https://spoken-whose-synthetic-touch.trycloudflare.com                                    |\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.4.0 (Checksum df13e7e0a027f648c410b5cc701fbcff028724d0e93209796cdbb79ec38695d4)\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 877cfb66-156b-44bb-8ab1-7c5621a667bf\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
      "\u001b[90m2025-04-23T21:14:19Z\u001b[0m \u001b[32mINF\u001b[0m Using [CurveID(4588) CurveID(25497) CurveP256] as curve preferences \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43\n",
      "2025/04/23 21:14:19 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
      "\u001b[90m2025-04-23T21:14:20Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m3c9df41e-4df5-4978-a988-6a10fa3c3a26 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mlocation=\u001b[0msin14 \u001b[36mprotocol=\u001b[0mquic\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 37 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 37 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 53 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 53 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/js/index.B-cSXLfy.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:35Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 73 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 77 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 77 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
      "\u001b[90m2025-04-23T21:14:38Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://spoken-whose-synthetic-touch.trycloudflare.com/static/js/index.B-cSXLfy.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.43 \u001b[36mtype=\u001b[0mhttp\n",
      "2025-04-23 21:14:55.138464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745442895.162435    5380 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745442895.169784    5380 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "peft_model_id xiaokeliu/lora_adapter_pair_based\n",
      "tokenizer_config.json: 100% 50.5k/50.5k [00:00<00:00, 50.4MB/s]\n",
      "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 6.90MB/s]\n",
      "special_tokens_map.json: 100% 301/301 [00:00<00:00, 2.30MB/s]\n",
      "config.json: 100% 843/843 [00:00<00:00, 6.06MB/s]\n",
      "model.safetensors: 100% 2.47G/2.47G [00:09<00:00, 270MB/s]\n",
      "generation_config.json: 100% 185/185 [00:00<00:00, 1.59MB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100% 624M/624M [00:01<00:00, 354MB/s]\n",
      "2025-04-23 21:15:19.945 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "2025-04-23 21:17:26.372 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
    "!chmod +x cloudflared\n",
    "!streamlit run app.py & sleep 5 && ./cloudflared tunnel --url http://localhost:8501\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
