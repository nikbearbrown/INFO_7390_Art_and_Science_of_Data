{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAw5p397Wz9q"
   },
   "source": [
    "# Lab1 summarize dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qh2NHiq4dCW",
    "outputId": "ddb718e3-86f5-471c-9b2c-38eb22769980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\kcsar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install Libraries\n",
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "d9b435ac405540bb8784f7746eab2e23",
      "e0cb30dfa089441da738316359923a38",
      "404c41de83b04a77a43b4f132474a33d",
      "2bdf2425e0f24510a35bb15984d97aea",
      "bad9196edf9f48f1b2555b3e799b7619",
      "c3e590bf625044b2a59aa7f3c9f6d813",
      "f58bd2519b834a02854123612b8d272e",
      "fc2e255d013d4f28a973fc1ce3874ce8",
      "cc53fd3726a04a5bb7b0f17cb0b2ef87",
      "0c21ed5919ab410bae4add1db65f08e4",
      "fda25a48119e4a5cbcf1b31bf2093c6c"
     ]
    },
    "id": "f-Ar0pT8T1PJ",
    "outputId": "4282ef7e-11cb-49ea-c0bc-0cf1c851ad03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b435ac405540bb8784f7746eab2e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"npc-engine/light-batch-summarize-dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3qsoV2tUCqy",
    "outputId": "e2e8fb9b-2bac-46b0-cd1c-dbaa0123af5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 17075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "Dp07_J7-UKzV",
    "outputId": "239d0035-6067-48a4-b8dc-19cfdc5f1002"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\\nsoldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\\ncourt wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\\nsoldier: I am a soldier doing my job\\ncourt wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\\nsoldier: No sir\\ncourt wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\\nsoldier: A year ago, Test it out or cause a need to use it\\ncourt wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\\nsoldier: Good idea, I agree, go do that\\ncourt wizard: Get off of me, you fool!  Who gave you permission to touch me!\\nsoldier: To the jail with you\\n\\nSummarize the dialogue'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]['dialogue_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SxYlZ1Ync4aR",
    "outputId": "c33008aa-5ee8-4830-b99f-e029f38033d4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['t0pp_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOkuXd9Hc8NK",
    "outputId": "211a6b0b-6d69-4273-f3e1-cd6fc3c1c3e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT DIALOGUE:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(dash_line)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINPUT DIALOGUE:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(dash_line)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBASELINE HUMAN SUMMARY:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#Loop over the Dataset\n",
    "example_indices = [0, 10]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print('INPUT DIALOGUE:')\n",
    "    print(dataset['test'][index]['dialogue_text'])\n",
    "    print(dash_line)\n",
    "    print('BASELINE HUMAN SUMMARY:')\n",
    "    print(dataset['test'][index]['t0pp_prediction'])\n",
    "    print(dash_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQN1WMkLWyy2"
   },
   "source": [
    "## Summarize Dialogue without Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jfXh5KeGQ2R8"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlWBytiCzYMd"
   },
   "source": [
    "Load the FLAN-T5 model, creating an instance of the AutoModelForSeq2SeqLM class with the .from_pretrained() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "db675fbb65d74ca6b1417f512d45ac26",
      "ff4f6daa3c624fae96b7bfe93c387dae",
      "30acc5313a9247c19af03e9434149e80",
      "7164cfaa96f8438a9c7f0318e3c9626a",
      "cdfc69ad5a8446cbb307868bed7f15ad",
      "0a7d32c78a764292b949d6947de2c9c6",
      "936577ac1f284728868ec2e6d879ea59",
      "ad2049edf78440e29678c1198b19dc32",
      "1239fcdcec9b409eb17ae440074d9e82",
      "d31541976ef740589f6f3bf1a2d1f350",
      "6f6acdb712a14424a8f1d63910f46442",
      "528051e895794cefb3a970202a168391",
      "a8bf3c4364fd4baab0d4d256c6cebc08",
      "191c55958be04f42a0990b8a76f40765",
      "970153e1dec8433690c8e246e424da9f",
      "0aefca061d89495ba0e1307135def6af",
      "6ee95d8239f648afb32d1a5eae3b2f1f",
      "5dbe9cb7ff044680b61cd5940f8ae9dd",
      "8ff11862c28243f787fae3c862ae1c5a",
      "e61fd9cff00042ad91957999f6a5f811",
      "abfd83929c5247c28602115d8c2ee985",
      "3c9f1eb5d85841d3ade023c6f68e4019",
      "8ce765416bcd4611b4fd71d51e0c1534",
      "d3ee07279d0542a6a3dcbd74271a9d2b",
      "3a0c370cea5b4909a5fad8a16d989bc2",
      "4da6a4319c774d8ca794606e67f92990",
      "9d5b9cf44f6b43f583c101b0cf963e17",
      "63468159691e4b3fa59ee40e4da5d612",
      "c86b7db535f243b1880b6052eb513fcb",
      "ff918ed720ee40fc8ed29cb2d0e4d99a",
      "0ec4b4c9c0344cb9ae7fa197fe1dc972",
      "e4f187d4a06e49b284e61ffbd317e645",
      "3698755ea8cc419298b7b400f0b874a0"
     ]
    },
    "id": "cvSVE4ZyQuTH",
    "outputId": "3911f1ee-967f-4622-9109-73f9b18e3d97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db675fbb65d74ca6b1417f512d45ac26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528051e895794cefb3a970202a168391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce765416bcd4611b4fd71d51e0c1534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use Model flan-t5\n",
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aS_mU8nzbZz"
   },
   "source": [
    "To perform encoding and decoding, we work with text in a tokenized form. Tokenization is the process of splitting texts into smaller units that can be processed by the LLM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "91095f8fb1944ab49d15b0f3baafebf5",
      "1373fc9ae45941eaa6ea028924e2e4d7",
      "027ecc2d035e4eb396bbeec01df6f25f",
      "1fb43199f93a4de584107239d0bac3c2",
      "89a85f8a572048a596b89b3fc0f5d14e",
      "7327f316e1fd412ca23078f7e330137a",
      "f970e8b182314bdebb5af6bc2af3a4a1",
      "2c7fc2d679fb4a519355d9f714f37f7f",
      "4906877023364f64af7e081e5d3ac686",
      "67142236414f4a0e97441b99d19a5994",
      "3a6e943f24b54d2ea5aca34cc924ae95",
      "8ce5e351eabb424a8d15806de65066cb",
      "3b8096fab86248fc9c725bee05d255d5",
      "d4dcac2f2b5e46129899bdb0ba947d80",
      "52c2d6b209c64619ae4ee1b5f49c9cc9",
      "a901aa9a6da34191b5bb8cf64f1a3b4b",
      "f2d12a67df2c4b9abcd11a29fe70bfd5",
      "e277e398cf7f4f3b9045f77b5936d23a",
      "d878acdaa271469896c7b8c6340e8037",
      "30e051f96c3445e0b7998b1099761799",
      "6821ed0c449d4d4ea1f360cb103f3bc6",
      "f0bb6ca5f8d0463d8f4849cbc7f47497",
      "448da687a7b94002ba2dda5d0360bf62",
      "b4e9d941c1bf477ebf20fcbb068a579c",
      "74e21f20186d4fadbc8e0aa2800b4e68",
      "a921a89da88746f397d28c8c7cb5934a",
      "5bbc14a35549475b8df92d97b5400a29",
      "bfc838acc7414d349e8ac50a8119ad91",
      "718d60ee34c84b80a5b035fc9b61e305",
      "cd3e74037aed41d9b1eaf4386ddb750a",
      "2fe6a592c6204280a97104617bf9c177",
      "0b638837398342ebad950dff6b4c3493",
      "dc696166acdd49b1b5998138aa686f35",
      "ff6811fb1f7341709d8c64625f813bb5",
      "f754d8ae08ed45c9a41b3ec67ecffebd",
      "5ed10e114bbf4c68aeca616190bccaad",
      "3b27aaef0b154038bffcad853f222ae1",
      "e9557c292dca4197bda09b0e731ab1db",
      "d0d55511b3bd4af4802faa94f5c14bee",
      "468d7f1483274b12831d74364775a519",
      "1eb050def9f7466ba826632e9a00af61",
      "2526f953adf54c5b9a888a2f8e374829",
      "671c75c18d634e5387ef8bd57262caf8",
      "770320f9ee854bebbb48438928359244"
     ]
    },
    "id": "jKel44D4QzQa",
    "outputId": "b10fe07b-af63-4c1a-c3dc-0b853cb97344"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91095f8fb1944ab49d15b0f3baafebf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce5e351eabb424a8d15806de65066cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448da687a7b94002ba2dda5d0360bf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6811fb1f7341709d8c64625f813bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenise the dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4--7WQohzfto"
   },
   "source": [
    "Now it's time to explore how well the base LLM summarizes a dialogue without any prompt engineering. Prompt engineering is an act of a human changing the prompt (input) to improve the response for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-j_sIXMHW7kG",
    "outputId": "d6853ccb-f1c6-4b81-ecd1-19540fe6f133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "Soldier is a common soldier. He is used to warmer weather. He has spells to keep him warm.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "princess: I don't have any money, but I need to cross the bridge to leave my horrible arranged marriage. I need to get supplies to run away with my love, the stable boy. Is there anything else I can do to cross?\n",
      "troll: Troll don't manage bridge for free. What you pay me? Maybe you have a ring?\n",
      "princess: I have a necklace of gems I can give you. It was given to me when I was born- there's a long tradition of this necklace being passed down to princesses in my family.\n",
      "troll: I will examine.\n",
      "princess: What do you say? Can I cross yet? I would rather not have to swim across these muddy waters... \n",
      "troll: What else you have for troll?\n",
      "princess: Maybe I can solve a riddle? \n",
      "troll: If you can figure out what troll want most you are free to pass.\n",
      "princess: Can you tell me what you want so we can both be done with this? \n",
      "troll: I show you.\n",
      "princess: How dare you!\n",
      "troll: Troll just want love.\n",
      "\n",
      "Summarize the dialogue\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "princess wants to cross the bridge to leave her arranged marriage. She has no money, but she has a necklace of gems she can give the troll. The troll wants a ring or a riddle. The troll wants love.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "Princess needs to cross the bridge to leave her arranged marriage. She has a necklace of gems she can give to troll. She will solve a riddle for troll.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting a index to be given as a prompt to the model\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['train'][index]['dialogue_text']\n",
    "    summary = dataset['train'][index]['t0pp_prediction']\n",
    "\n",
    "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=50,\n",
    "        )[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcZ-2pWeYPJD"
   },
   "source": [
    "## Summarize Dialogue with an Instruction Prompt\n",
    "Prompt engineering is an important concept in using foundation models for text generation. You can check out this blog from Amazon Science for a quick introduction to prompt engineering.\n",
    "\n",
    "\n",
    "### Zero Shot Inference with an Instruction Prompt\n",
    "In order to instruct the model to perform a task - summarize a dialogue - you can take the dialogue and convert it into an instruction prompt. This is often called zero shot inference. You can check out this blog from AWS for a quick description of what zero shot learning is and why it is an important concept to the LLM model.\n",
    "\n",
    "Wrap the dialogue in a descriptive instruction and see how the generated text will change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOGBbB4-XPTh",
    "outputId": "a5fa7162-ce3c-482d-aa28-6665b118cc97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "Summary:\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Soldier is a common soldier. He is used to warmer weather. He has spells to keep him warm.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "princess: I don't have any money, but I need to cross the bridge to leave my horrible arranged marriage. I need to get supplies to run away with my love, the stable boy. Is there anything else I can do to cross?\n",
      "troll: Troll don't manage bridge for free. What you pay me? Maybe you have a ring?\n",
      "princess: I have a necklace of gems I can give you. It was given to me when I was born- there's a long tradition of this necklace being passed down to princesses in my family.\n",
      "troll: I will examine.\n",
      "princess: What do you say? Can I cross yet? I would rather not have to swim across these muddy waters... \n",
      "troll: What else you have for troll?\n",
      "princess: Maybe I can solve a riddle? \n",
      "troll: If you can figure out what troll want most you are free to pass.\n",
      "princess: Can you tell me what you want so we can both be done with this? \n",
      "troll: I show you.\n",
      "princess: How dare you!\n",
      "troll: Troll just want love.\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "Summary:\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "princess wants to cross the bridge to leave her arranged marriage. She has no money, but she has a necklace of gems she can give the troll. The troll wants a ring or a riddle. The troll wants love.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Princess needs to cross the bridge to leave her arranged marriage. She has a necklace of gems she can give to troll. She will solve a riddle if she can.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['train'][index]['dialogue_text']\n",
    "    summary = dataset['train'][index]['t0pp_prediction']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    # Input constructed prompt instead of the dialogue.\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=50,\n",
    "        )[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuY6NaWr5bBZ"
   },
   "source": [
    "### 3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5\n",
    "Let's use a slightly different prompt. FLAN-T5 has many prompt templates that are published for certain tasks here. In the following code, we use one of the pre-built FLAN-T5 prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ex4AZkwRYe8p",
    "outputId": "0272e7de-b7a8-4f6f-f9b8-622320f84dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "The soldier is a common soldier. He is used to warmer weather. He has spells to keep him warm.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "princess: I don't have any money, but I need to cross the bridge to leave my horrible arranged marriage. I need to get supplies to run away with my love, the stable boy. Is there anything else I can do to cross?\n",
      "troll: Troll don't manage bridge for free. What you pay me? Maybe you have a ring?\n",
      "princess: I have a necklace of gems I can give you. It was given to me when I was born- there's a long tradition of this necklace being passed down to princesses in my family.\n",
      "troll: I will examine.\n",
      "princess: What do you say? Can I cross yet? I would rather not have to swim across these muddy waters... \n",
      "troll: What else you have for troll?\n",
      "princess: Maybe I can solve a riddle? \n",
      "troll: If you can figure out what troll want most you are free to pass.\n",
      "princess: Can you tell me what you want so we can both be done with this? \n",
      "troll: I show you.\n",
      "princess: How dare you!\n",
      "troll: Troll just want love.\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "princess wants to cross the bridge to leave her arranged marriage. She has no money, but she has a necklace of gems she can give the troll. The troll wants a ring or a riddle. The troll wants love.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Princess needs to cross the bridge to leave her arranged marriage. She has a necklace of gems she can give to troll. She will ask troll to help her solve a riddle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['train'][index]['dialogue_text']\n",
    "    summary = dataset['train'][index]['t0pp_prediction']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=50,\n",
    "        )[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-45PO7-R5sgO"
   },
   "source": [
    "## Summarize Dialogue with One Shot and Few Shot Inference\n",
    "One shot and few shot inference are the practices of providing an LLM with either one or more full examples of prompt-response pairs that match your task - before your actual prompt that you want completed. This is called \"in-context learning\" and puts your model into a state that understands your specific task. You can read more about it in this blog from HuggingFace.\n",
    "\n",
    "\n",
    "### One Shot Inference\n",
    "Let's build a function that takes a list of example_indices_full, generates a prompt with full examples, then at the end appends the prompt which you want the model to complete (example_index_to_summarize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Su9npUBP5orf"
   },
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt = ''\n",
    "    for index in example_indices_full:\n",
    "        dialogue = dataset['train'][index]['dialogue_text']\n",
    "        summary = dataset['train'][index]['t0pp_prediction']\n",
    "\n",
    "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
    "        prompt += f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "{summary}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    dialogue = dataset['train'][example_index_to_summarize]['dialogue_text']\n",
    "\n",
    "    prompt += f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9cPUlM_57IK",
    "outputId": "eb152d1d-1012-47f2-870b-ecb4b5252889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "pet goldfish: I suppose you've done a fine job. But I wish you could bring more... color into this dark, dismal place. \n",
      "the groundskeeper of the castle: You know what, you're right! First thing tomorrow I'll go into town and find some nice vibrant curtains for the room.\n",
      "pet goldfish: Maybe get a cotton mattress for this rough bed as well? My back hurts from this wooden bed. \n",
      "the groundskeeper of the castle: Even though it'll be a lot of work, you're absolutely right. The castle can wait! Time to tidy up this room.\n",
      "pet goldfish: Thank you. Now will you please consider dropping me off by the pond ... to ugh get some fresh air?\n",
      "the groundskeeper of the castle: I'd be happy to! Just let me pick you up and we'll go for a quick walk.\n",
      "pet goldfish: Oh this looks nice. The perfect rug to dance on! \n",
      "the groundskeeper of the castle: Oh, are we having an impromptu dance party?\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [0]\n",
    "example_index_to_summarize = 100\n",
    "\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60lYzxRoz8mA"
   },
   "source": [
    "Now pass this prompt to perform the one shot inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xozCL1m59G4",
    "outputId": "0cd9ed11-9e14-45fd-c5fb-1f90efe2e103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "the groundskeeper of the castle will buy some curtains and a mattress for the goldfish's room.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "The groundskeeper of the castle will go into town tomorrow to find some curtains and a cotton mattress. The groundskeeper of the castle will drop pet goldfish off by the pond to get some fresh air.\n"
     ]
    }
   ],
   "source": [
    "summary = dataset['train'][example_index_to_summarize]['t0pp_prediction']\n",
    "\n",
    "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxghfRVr8jLK"
   },
   "source": [
    "### Few Shot Inference\n",
    "\n",
    "Let's explore few shot inference by adding two more full dialogue-summary pairs to your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMy4U0lP7b9A",
    "outputId": "7ed46e21-1e26-4ff7-d545-eabccf5254b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "princess: I don't have any money, but I need to cross the bridge to leave my horrible arranged marriage. I need to get supplies to run away with my love, the stable boy. Is there anything else I can do to cross?\n",
      "troll: Troll don't manage bridge for free. What you pay me? Maybe you have a ring?\n",
      "princess: I have a necklace of gems I can give you. It was given to me when I was born- there's a long tradition of this necklace being passed down to princesses in my family.\n",
      "troll: I will examine.\n",
      "princess: What do you say? Can I cross yet? I would rather not have to swim across these muddy waters... \n",
      "troll: What else you have for troll?\n",
      "princess: Maybe I can solve a riddle? \n",
      "troll: If you can figure out what troll want most you are free to pass.\n",
      "princess: Can you tell me what you want so we can both be done with this? \n",
      "troll: I show you.\n",
      "princess: How dare you!\n",
      "troll: Troll just want love.\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "princess wants to cross the bridge to leave her arranged marriage. She has no money, but she has a necklace of gems she can give the troll. The troll wants a ring or a riddle. The troll wants love.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "pet goldfish: I suppose you've done a fine job. But I wish you could bring more... color into this dark, dismal place. \n",
      "the groundskeeper of the castle: You know what, you're right! First thing tomorrow I'll go into town and find some nice vibrant curtains for the room.\n",
      "pet goldfish: Maybe get a cotton mattress for this rough bed as well? My back hurts from this wooden bed. \n",
      "the groundskeeper of the castle: Even though it'll be a lot of work, you're absolutely right. The castle can wait! Time to tidy up this room.\n",
      "pet goldfish: Thank you. Now will you please consider dropping me off by the pond ... to ugh get some fresh air?\n",
      "the groundskeeper of the castle: I'd be happy to! Just let me pick you up and we'll go for a quick walk.\n",
      "pet goldfish: Oh this looks nice. The perfect rug to dance on! \n",
      "the groundskeeper of the castle: Oh, are we having an impromptu dance party?\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "the groundskeeper of the castle will buy some curtains and a mattress for the goldfish's room.\n",
      "\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "peasant: You're too kind, I look after my wife and kids all day and night so this means the world.\n",
      "boar: I think we can get something for your wife, I have lots of flowers\n",
      "peasant: They're gorgeous, I know she would love them. Is there any way that I could repay you?\n",
      "boar: No my friend, just keep being a good person that you are, I see you have alot of space in your place. I can give you seeds that you will plant and you will become a noble in no time. The seeds are magical passed on from my parents\n",
      "peasant: Thank you so much, what kind of plants do you speak of?\n",
      "boar: magical tomatoes eaten in fairyland, my grand mother was a fairy\n",
      "peasant: That's incredible! You must be a very powerful being.\n",
      "boar: oh no I am just a boar, but I am kind of different though because people don't hunt me like others and I can talk with humans\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [0, 10, 100]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTs91hWe8tq0"
   },
   "source": [
    "Now pass this prompt to perform a few shot inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1B-Bfs28pX2",
    "outputId": "3634911f-7096-44b4-8866-c76bfb43fd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "boar gives peasant flowers for his wife. He offers peasant seeds that will make him a noble.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - FEW SHOT:\n",
      "Peasant and boar are going to get flowers for their wife.\n"
     ]
    }
   ],
   "source": [
    "summary = dataset['train'][example_index_to_summarize]['t0pp_prediction']\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtB-4oSE9mbM"
   },
   "source": [
    "## Generative Configuration Parameters for Inference\n",
    "We can change the configuration parameters of the generate() method to see a different output from the LLM. So far the only parameter that you have been setting was max_new_tokens=50, which defines the maximum number of tokens to generate. A full list of available parameters can be found in the Hugging Face Generation documentation.\n",
    "\n",
    "A convenient way of organizing the configuration parameters is to use GenerationConfig class.\n",
    "\n",
    "Exercise:\n",
    "\n",
    "Change the configuration parameters to investigate their influence on the output.\n",
    "\n",
    "Putting the parameter do_sample = True, you activate various decoding strategies which influence the next token from the probability distribution over the entire vocabulary. You can then adjust the outputs changing temperature and other parameters (such as top_k and top_p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1H8f0ys80J8",
    "outputId": "1205e110-fdc2-4436-a032-2cda26141a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - FEW SHOT:\n",
      "Peasant and boar are going to get flowers for their wife.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "boar gives peasant flowers for his wife. He offers peasant seeds that will make him a noble.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(max_new_tokens=50)\n",
    "# generation_config = GenerationConfig(max_new_tokens=10)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        generation_config=generation_config,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDSnYqXA9rB5",
    "outputId": "fa537505-bdff-4d1d-b873-93e009d18f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - FEW SHOT:\n",
      "Peasant and boar are helping to find a gift for their wife. Boar will plant seeds for her.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "boar gives peasant flowers for his wife. He offers peasant seeds that will make him a noble.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        generation_config=generation_config,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J3h8Yno0Ng7"
   },
   "source": [
    "Comments related to the choice of the parameters in the code cell above:\n",
    "\n",
    "* Choosing max_new_tokens less will make the output text too short, so the dialogue summary will be cut.\n",
    "* Putting do_sample = True and changing the temperature value you get more flexibility in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TzoE95_-cVl"
   },
   "source": [
    "# Lab 2 Fine-Tune a Generative AI Model for Dialogue Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaLmFRDh9yBK",
    "outputId": "17446494-095b-491d-f37d-502b9c5b4880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.3.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UJQ8qGZE-kU0"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mqdEkpDaA7vF"
   },
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1QL2J4I8BpH"
   },
   "source": [
    "## Test the Model with Zero Shot Inferencing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8G6xIHE8HU_",
    "outputId": "e342b7f3-ea7e-43d5-8ae2-ceea46964b75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 17075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OjgZx0hBA2V",
    "outputId": "0c66edba-39bc-4540-aabc-75b722ca278e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "court wizard: Have any else come up this eve? I had hoped for a quiet night to examine the stars\n",
      "soldier: Yes, a few came through, but it is a cold night for me, I am used to warmer weather\n",
      "court wizard: Well, you are but a common soldier.  No doubt you are used to such a lot.  Thankfully I have my spells to keep me warm.\n",
      "soldier: I am a soldier doing my job\n",
      "court wizard: Yes... well... Very well then.  See that you do!  No slacking off while your betters are about.\n",
      "soldier: No sir\n",
      "court wizard: When, for example, was this horn last tested?  It looks dented.  How can we be sure it will work?\n",
      "soldier: A year ago, Test it out or cause a need to use it\n",
      "court wizard: Mayhap I will speak to the king about such lackness.  Or perhaps I can sell him a spell that will serve just as well.\n",
      "soldier: Good idea, I agree, go do that\n",
      "court wizard: Get off of me, you fool!  Who gave you permission to touch me!\n",
      "soldier: To the jail with you\n",
      "\n",
      "Summarize the dialogue\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Soldier is a common soldier. He is used to warmer weather. He has spells to keep him warm.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['train'][0]['dialogue_text']\n",
    "summary = dataset['train'][0]['t0pp_prediction']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3A5_8xX8jnU"
   },
   "source": [
    "# Perform Full Fine-Tuning\n",
    "\n",
    "## 1. Preprocess the Dialog-Summary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7J2I3uN8NTk",
    "outputId": "a52510ec-44d8-4ca3-dfc0-26e475f42610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-2cdcf5c350f0ce52.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-d349127e9d0323c8.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-7c64ed85841ab859.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue_text\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"t0pp_prediction\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['dialogue_text', 't0pp_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3p1aLNSN80D9",
    "outputId": "ffc2b45e-3678-461b-ddfc-1618015cf7a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-634665f735ae46ac.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-5fc4b2987861c5b3.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-6fdbc9c7df0aaf05.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbkIT7iqAU0t",
    "outputId": "fe6be83d-fddb-42a0-f54c-f37a37db3436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (171, 2)\n",
      "Validation: (10, 2)\n",
      "Test: (20, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 171\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNBsSfaF84kd"
   },
   "source": [
    "### 2. Fine-Tune the Model with the Preprocessed Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyUTDII99IEW",
    "outputId": "53923851-6abc-4e8d-d522-74ebe47dd17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xscv1_2C87CX"
   },
   "outputs": [],
   "source": [
    "output_dir = f'/content/drive/MyDrive/Advanced_DS/WorkedExample'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    warmup_steps=10,\n",
    "    prediction_loss_only=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "Lyjo9Y0E9k-N",
    "outputId": "d9e9c048-a7ed-43ee-fd1d-785958096d0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 05:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=215, training_loss=5.155523255813954, metrics={'train_runtime': 340.0497, 'train_samples_per_second': 2.514, 'train_steps_per_second': 0.632, 'total_flos': 585467536343040.0, 'train_loss': 5.155523255813954, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rM3zrLGGOx3"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "D21pz2TpGN6E",
    "outputId": "40d51b91-e245-46fe-e1cd-5c9680e6b668"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.4375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "eval_results['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oMAjevMtGN87"
   },
   "outputs": [],
   "source": [
    "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Advanced_DS/WorkedExample/checkpoint-200\", torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jo4Gy2JNGOAV",
    "outputId": "8b4d53aa-dbc3-46e9-d023-795496b8b104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INSTRUCT MODEL:\n",
      "Soldier is a common soldier. He is used to warmer weather.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['train'][0]['dialogue_text']\n",
    "human_baseline_summary = dataset['train'][0]['t0pp_prediction']\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXJu7vTSHuA6"
   },
   "source": [
    "### Evaluate the Model Quantitatively (with ROUGE Metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e35a4e5afc7c4cca884ea096951e283c",
      "8aae0f53ea7f4d748029fb27f0682f67",
      "870b71f731fb4f1bbad10e4ce8f220e1",
      "4affcf780bc840e2abe512444471be67",
      "9f3995f33cf84bb08ef97942a0aa585b",
      "9ed876973494467fa31f4d80bfef5743",
      "c1817231aa124b7e82cbc293a9f00882",
      "f6a1491312b548ab84beeddec0cb6a4e",
      "10be47defc7f46fa939cf640576b99a7",
      "2dd4947b23614e0f892133a90254ff72",
      "4716fb6c7f8746f193d38a50723480a6"
     ]
    },
    "id": "8E1o5G1GGOC-",
    "outputId": "a3370124-d77e-404d-f6b5-56af6fd07bd8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35a4e5afc7c4cca884ea096951e283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "FR5ZuAm9Hvxq",
    "outputId": "fb4d6f57-4e96-4b20-d59f-c8d9a11e90a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5cd9e15b-8069-4fd3-9f6c-e092087a90de\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>instruct_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>court wizard is cold on the night he is examin...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soldier is a soldier doing his job. Court wiza...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thief wants to buy a beer for a homeless man, ...</td>\n",
       "      <td>The thief is going to buy a beer for the person.</td>\n",
       "      <td>The thief is going to buy a beer for the person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thief wants to buy a beer for a homeless man b...</td>\n",
       "      <td>The thief is looking down on the person.</td>\n",
       "      <td>The thief is looking down on the person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>witch and fairy are stuck in the tower. They a...</td>\n",
       "      <td>Fairy is having a bad day. She has Felix, but ...</td>\n",
       "      <td>Fairy is having a bad day. She has Felix, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>witch is locked in a room with a fairy. She ca...</td>\n",
       "      <td>Fairy is locked in. She has Felix, her familia...</td>\n",
       "      <td>Fairy is locked in. She has Felix, her familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The king wants to see the prisoner. The prison...</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The king wants to see the prisoner. The prison...</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the king's bed frame is made of gold. archer w...</td>\n",
       "      <td>The king's bed frame is more valuable than his...</td>\n",
       "      <td>The king's bed frame is more valuable than his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the king has invited archer to his castle to t...</td>\n",
       "      <td>Archer is a good archer. The king is a good heir.</td>\n",
       "      <td>Archer is a good archer. The king is a good heir.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd9e15b-8069-4fd3-9f6c-e092087a90de')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5cd9e15b-8069-4fd3-9f6c-e092087a90de button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5cd9e15b-8069-4fd3-9f6c-e092087a90de');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-81566ba1-9d6c-4d16-9f4e-f2f387e301cb\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81566ba1-9d6c-4d16-9f4e-f2f387e301cb')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-81566ba1-9d6c-4d16-9f4e-f2f387e301cb button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  court wizard is cold on the night he is examin...   \n",
       "1  soldier is a soldier doing his job. Court wiza...   \n",
       "2  thief wants to buy a beer for a homeless man, ...   \n",
       "3  thief wants to buy a beer for a homeless man b...   \n",
       "4  witch and fairy are stuck in the tower. They a...   \n",
       "5  witch is locked in a room with a fairy. She ca...   \n",
       "6  The king wants to see the prisoner. The prison...   \n",
       "7  The king wants to see the prisoner. The prison...   \n",
       "8  the king's bed frame is made of gold. archer w...   \n",
       "9  the king has invited archer to his castle to t...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0  Soldier is a common soldier. He is used to war...   \n",
       "1  Soldier is a common soldier. He is used to war...   \n",
       "2   The thief is going to buy a beer for the person.   \n",
       "3           The thief is looking down on the person.   \n",
       "4  Fairy is having a bad day. She has Felix, but ...   \n",
       "5  Fairy is locked in. She has Felix, her familia...   \n",
       "6                    The king wants to see prisoner.   \n",
       "7                    The king wants to see prisoner.   \n",
       "8  The king's bed frame is more valuable than his...   \n",
       "9  Archer is a good archer. The king is a good heir.   \n",
       "\n",
       "                            instruct_model_summaries  \n",
       "0  Soldier is a common soldier. He is used to war...  \n",
       "1  Soldier is a common soldier. He is used to war...  \n",
       "2   The thief is going to buy a beer for the person.  \n",
       "3           The thief is looking down on the person.  \n",
       "4  Fairy is having a bad day. She has Felix, but ...  \n",
       "5  Fairy is locked in. She has Felix, her familia...  \n",
       "6                    The king wants to see prisoner.  \n",
       "7                    The king wants to see prisoner.  \n",
       "8  The king's bed frame is more valuable than his...  \n",
       "9  Archer is a good archer. The king is a good heir.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['train'][0:10]['dialogue_text']\n",
    "human_baseline_summaries = dataset['train'][0:10]['t0pp_prediction']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "\n",
    "for _, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to('cuda:0')\n",
    "\n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "\n",
    "    input_ids = input_ids.to(instruct_model.device)\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
    "\n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlJr8mLaJ6zs"
   },
   "source": [
    "Evaluate the models computing ROUGE metrics. Notice the improvement in the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hCYVPDnHv0T",
    "outputId": "e37b6247-139a-42f2-9cba-e999f5d90b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.3516232535782976, 'rouge2': 0.20553465562259934, 'rougeL': 0.3092992752080421, 'rougeLsum': 0.3097385589336634}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.3583838430922206, 'rouge2': 0.20426774483378254, 'rougeL': 0.310671297596006, 'rougeLsum': 0.3110050218427736}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models computing ROUGE metrics. \n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb_6H-8wHv3H",
    "outputId": "6a4b773f-05ad-4393-95a5-2cd770c0d7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\n",
      "rouge1: 0.68%\n",
      "rouge2: -0.13%\n",
      "rougeL: 0.14%\n",
      "rougeLsum: 0.13%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(instruct_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TCKQCDWTDpD"
   },
   "source": [
    "### Setup the PEFT/LoRA model for Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Kt6wUjI9TC2R"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51Sb5zCxTHUe",
    "outputId": "f671d699-60cc-4103-be06-599f4d3c51ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model,\n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "xldRh9CfTHXn"
   },
   "outputs": [],
   "source": [
    "output_dir = f'/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-training'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    warmup_steps=10,\n",
    "    prediction_loss_only=True\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "VZSbXOPhTHad",
    "outputId": "bdb66e5e-317c-40fb-b428-d4d940245e00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 04:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local/tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Nqnw_siWTHdG"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                       '/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local/',\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_hzmsU5WDBp"
   },
   "source": [
    "###  Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XHudvobTHh0",
    "outputId": "c602bf57-844b-4905-af87-ea5cc8d67986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "Soldier is a soldier.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INSTRUCT MODEL:\n",
      "Soldier is a common soldier. He is used to warmer weather.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL: Soldier is a common soldier. He is used to warmer weather. He has spells to keep him warm.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['train'][0]['dialogue_text']\n",
    "baseline_human_summary = dataset['train'][0]['t0pp_prediction']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to('cuda:0')\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "input_ids = input_ids.to(instruct_model.device)\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "input_ids = input_ids.to(peft_model.device)\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ3DbVVtbZ3e"
   },
   "source": [
    "###  Evaluate the Model Quantitatively (with ROUGE Metric)\n",
    "\n",
    "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgIHliqJZx6e",
    "outputId": "8c13b883-46a9-4124-857d-0efba19ab71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['court wizard is cold on the night he is examining the stars. Soldier is a soldier doing his job.',\n",
       " 'soldier is a soldier doing his job. Court wizard is a court wizard. He wants to know when the horn was last tested. It was last tested a year ago.',\n",
       " \"thief wants to buy a beer for a homeless man, but he doesn't have enough money.\",\n",
       " 'thief wants to buy a beer for a homeless man but has no money.',\n",
       " 'witch and fairy are stuck in the tower. They are thinking of ways to get out.',\n",
       " \"witch is locked in a room with a fairy. She can't get out. She can't leave her family behind. She can't let the lantern down. She can't use magic. She has a cat as a familiar. The cat can't fit through the bars\",\n",
       " \"The king wants to see the prisoner. The prisoner is accused of disobeying the queen's order.\",\n",
       " \"The king wants to see the prisoner. The prisoner is accused of disobeying the queen's order.\",\n",
       " 'the king has invited archer to his castle to teach him archery.',\n",
       " 'princess wants to cross the bridge to leave her arranged marriage. She has no money, but she has a necklace of gems she can give the troll. The troll wants a ring or a riddle. The troll wants love.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['train'][0:10]['dialogue_text']\n",
    "human_baseline_summaries = dataset['train'][0:10]['t0pp_prediction']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to('cuda:0')\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "\n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    input_ids = input_ids.to(instruct_model.device)\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    input_ids = input_ids.to(peft_model.device)\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "    peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
    "\n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "5HQc8iQtcFcl",
    "outputId": "90e1c30a-0b6a-43c5-c93e-b3359f49cb12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-db7f43da-67b1-4b1d-8cb4-27e5a2474ad0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>instruct_model_summaries</th>\n",
       "      <th>peft_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>court wizard is cold on the night he is examin...</td>\n",
       "      <td>Soldier is cold.</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soldier is a soldier doing his job. Court wiza...</td>\n",
       "      <td>The soldier's horn is a bit dented.</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "      <td>Soldier is a common soldier. He is used to war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thief wants to buy a beer for a homeless man, ...</td>\n",
       "      <td>The thief is a homeless man.</td>\n",
       "      <td>The thief is going to buy a beer for the person.</td>\n",
       "      <td>The thief is looking for a bite to eat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thief wants to buy a beer for a homeless man b...</td>\n",
       "      <td>The thief is a homeless man.</td>\n",
       "      <td>The thief is looking down on the person.</td>\n",
       "      <td>The thief is looking for a beer. The person is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>witch and fairy are stuck in the tower. They a...</td>\n",
       "      <td>The fairy is having a bad state of affairs. Sh...</td>\n",
       "      <td>Fairy is having a bad day. She has Felix, but ...</td>\n",
       "      <td>Fairy is having a bad day. She has Felix, her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>witch is locked in a room with a fairy. She ca...</td>\n",
       "      <td>Fairy is locked in a room.</td>\n",
       "      <td>Fairy is locked in. She has Felix, her familia...</td>\n",
       "      <td>Fairy is locked in the house. She has Felix, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The king wants to see the prisoner. The prison...</td>\n",
       "      <td>The king wants to make a deal with the prisoner.</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "      <td>The king wants to see prisoner. The king wants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The king wants to see the prisoner. The prison...</td>\n",
       "      <td>The king is requesting to meet with prisoner.</td>\n",
       "      <td>The king wants to see prisoner.</td>\n",
       "      <td>The king wants to see prisoner. The king wants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the king has invited archer to his castle to t...</td>\n",
       "      <td>The king is a proud to have his bed frame and ...</td>\n",
       "      <td>Archer is a good archer. The king is a good heir.</td>\n",
       "      <td>Archer is a good archer. The king is a good ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>princess wants to cross the bridge to leave he...</td>\n",
       "      <td>Princess needs to cross the bridge. She has a ...</td>\n",
       "      <td>Princess needs to cross the bridge to leave he...</td>\n",
       "      <td>Princess needs to cross the bridge to leave he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db7f43da-67b1-4b1d-8cb4-27e5a2474ad0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-db7f43da-67b1-4b1d-8cb4-27e5a2474ad0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-db7f43da-67b1-4b1d-8cb4-27e5a2474ad0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b7c6add7-51af-4c6c-bb1e-71a69bfd9563\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7c6add7-51af-4c6c-bb1e-71a69bfd9563')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b7c6add7-51af-4c6c-bb1e-71a69bfd9563 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  court wizard is cold on the night he is examin...   \n",
       "1  soldier is a soldier doing his job. Court wiza...   \n",
       "2  thief wants to buy a beer for a homeless man, ...   \n",
       "3  thief wants to buy a beer for a homeless man b...   \n",
       "4  witch and fairy are stuck in the tower. They a...   \n",
       "5  witch is locked in a room with a fairy. She ca...   \n",
       "6  The king wants to see the prisoner. The prison...   \n",
       "7  The king wants to see the prisoner. The prison...   \n",
       "8  the king has invited archer to his castle to t...   \n",
       "9  princess wants to cross the bridge to leave he...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0                                   Soldier is cold.   \n",
       "1                The soldier's horn is a bit dented.   \n",
       "2                       The thief is a homeless man.   \n",
       "3                       The thief is a homeless man.   \n",
       "4  The fairy is having a bad state of affairs. Sh...   \n",
       "5                         Fairy is locked in a room.   \n",
       "6   The king wants to make a deal with the prisoner.   \n",
       "7      The king is requesting to meet with prisoner.   \n",
       "8  The king is a proud to have his bed frame and ...   \n",
       "9  Princess needs to cross the bridge. She has a ...   \n",
       "\n",
       "                            instruct_model_summaries  \\\n",
       "0  Soldier is a common soldier. He is used to war...   \n",
       "1  Soldier is a common soldier. He is used to war...   \n",
       "2   The thief is going to buy a beer for the person.   \n",
       "3           The thief is looking down on the person.   \n",
       "4  Fairy is having a bad day. She has Felix, but ...   \n",
       "5  Fairy is locked in. She has Felix, her familia...   \n",
       "6                    The king wants to see prisoner.   \n",
       "7                    The king wants to see prisoner.   \n",
       "8  Archer is a good archer. The king is a good heir.   \n",
       "9  Princess needs to cross the bridge to leave he...   \n",
       "\n",
       "                                peft_model_summaries  \n",
       "0  Soldier is a common soldier. He is used to war...  \n",
       "1  Soldier is a common soldier. He is used to war...  \n",
       "2            The thief is looking for a bite to eat.  \n",
       "3  The thief is looking for a beer. The person is...  \n",
       "4  Fairy is having a bad day. She has Felix, her ...  \n",
       "5  Fairy is locked in the house. She has Felix, h...  \n",
       "6  The king wants to see prisoner. The king wants...  \n",
       "7  The king wants to see prisoner. The king wants...  \n",
       "8  Archer is a good archer. The king is a good ar...  \n",
       "9  Princess needs to cross the bridge to leave he...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S59D7pKocM9f",
    "outputId": "23cd5a2a-fd2f-4ef7-8de0-254a5154e063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.33320098005223864, 'rouge2': 0.1600459057850362, 'rougeL': 0.2882529027883719, 'rougeLsum': 0.292340444875914}\n",
      "INSTRUCT MODEL:\n",
      "{'rouge1': 0.3863983003419402, 'rouge2': 0.22697422855721544, 'rougeL': 0.333065884274792, 'rougeLsum': 0.33917084676937254}\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.3869715955558476, 'rouge2': 0.2083942168942169, 'rougeL': 0.33320506964696345, 'rougeLsum': 0.3410040274459213}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMpJDc58cdHX"
   },
   "source": [
    "Calculate the improvement of PEFT over the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjIovpgicZqn",
    "outputId": "ab293b82-45a9-4b2a-dfb4-fa3aa4f18e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
      "rouge1: 5.38%\n",
      "rouge2: 4.83%\n",
      "rougeL: 4.50%\n",
      "rougeLsum: 4.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XltXOXFYcgNj"
   },
   "source": [
    "Now calculate the improvement of PEFT over a full fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3jBwyBNcZuT",
    "outputId": "5a4217de-e908-45bc-a561-d76fa363ddc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
      "rouge1: 0.06%\n",
      "rouge2: -1.86%\n",
      "rougeL: 0.01%\n",
      "rougeLsum: 0.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSj4m9NqKQlb"
   },
   "source": [
    "# Lab 3 Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UOroI37dPRT",
    "outputId": "bf03ec3b-469f-40ee-b5c2-e1036c62106c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl==0.7.2\n",
      "  Using cached trl-0.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (1.13.1)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (1.23.5)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (0.24.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (2.11.0)\n",
      "Requirement already satisfied: tyro>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.2) (0.5.17)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.2) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.2) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.7.2) (67.7.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.7.2) (0.41.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (0.19.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.7.2) (4.66.1)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl==0.7.2) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl==0.7.2) (13.7.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl==0.7.2) (1.6.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.7.2) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets->trl==0.7.2) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (3.8.6)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.2) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.7.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.7.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.7.2) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl==0.7.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl==0.7.2) (2.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.2) (2023.3.post1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl==0.7.2) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.7.2) (1.16.0)\n",
      "Using cached trl-0.7.2-py3-none-any.whl (124 kB)\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.7.4\n",
      "    Uninstalling trl-0.7.4:\n",
      "      Successfully uninstalled trl-0.7.4\n",
      "Successfully installed trl-0.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "%pip install trl==0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NS7eMSUal9q_",
    "outputId": "6a0359d3-abbc-4072-8359-35396901d247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-b6kiugs5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-b6kiugs5\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 0ae52fece17a3514116815984444116b75d9c5ca\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (1.13.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (4.27.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (0.24.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.6.3.dev0) (0.19.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.6.3.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.6.3.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.6.3.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.6.3.dev0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.3.dev0) (67.7.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.3.dev0) (0.41.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.6.3.dev0) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.6.3.dev0) (0.13.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HzHD7IZXHv8F"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rbctsepnkqEZ"
   },
   "outputs": [],
   "source": [
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "2032827037c945239de4aad71dceadf4",
      "1f19d1d02a11411fb4f3d7185295056d",
      "eef683ad06b34d419483cae503b43e88",
      "7e7695e440b840bea00ab99be116865d",
      "14dd0628e754457a9d5439172d534583",
      "0a94edd51ca345db8727cd0fe0891ead",
      "27e40bf4a0c54221be0d3d6d3b777321",
      "3174b99cb4394c06aa299f0bca95c9cf",
      "f767ed5346264aee9bed5998ed5c742d",
      "28fa3ab9826c4b7a8ca03f20ea38a3c4",
      "6020bacf09094e2484c81d2614f234e9"
     ]
    },
    "id": "8TABUaCwLWHq",
    "outputId": "d1ca370d-2e8d-4597-8023-81cf800f12df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2032827037c945239de4aad71dceadf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 17075\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue_text', 't0pp_prediction'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"npc-engine/light-batch-summarize-dialogue\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "fb9bc5c4f4624055969d384b3f1efea3",
      "3dfc1aeae6624a059c01d11aae47c09e",
      "cd119fa2d44b48a483109e251b9775eb",
      "dd4630fd33534ae2999e2052874bd2de",
      "eabb7b2d7aae4dbcb9d5b520cf3d075e",
      "b57544ed241747e18735d6b11edc554a",
      "8c9c19581ac14c55a7274c8440d83a65",
      "c2ccbefd9c0c4483baaf6ecdd942c418",
      "f1e47eaabdef49bbb65a8a168ae57dca",
      "c11be68fcc6747578049f70b0bee3541",
      "6f901107052e4d26977a8d0329077332"
     ]
    },
    "id": "tFjbytgWHv-O",
    "outputId": "cc9411c3-ef45-4e6e-9966-c7a967b90da5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/npc-engine___json/npc-engine--light-batch-summarize-dialogue-9ff052f8ae623a9a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-655fb7cec0063c4f.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9bc5c4f4624055969d384b3f1efea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue_text', 't0pp_prediction', 'input_ids', 'query'],\n",
      "        num_rows: 12514\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue_text', 't0pp_prediction', 'input_ids', 'query'],\n",
      "        num_rows: 3129\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length,\n",
    "                  input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "\n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "\n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue_text\"]) > input_min_text_length and len(x[\"dialogue_text\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    def tokenize(sample):\n",
    "\n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue_text\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "\n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "\n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200,\n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QBDR0DVMIG5"
   },
   "source": [
    "Prepare a function to pull out the number of model parameters (it is the same as in the previous lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CzY5IhA1MHjC"
   },
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQzLzsjuL8Lp"
   },
   "source": [
    "Add the adapter to the original FLAN-T5 model. In the previous lab you were adding the fully trained adapter only for inferences, so there was no need to pass LoRA configurations doing that. Now you need to pass them to the constructed PEFT model, also putting is_trainable=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OirOeNgeLcKJ",
    "outputId": "ad195158-afca-4771-f794-cfb19319ef17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model,\n",
    "                                       '/content/drive/MyDrive/Advanced_DS/peft-dialogue-summary-checkpoint-local/',\n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       device_map=\"auto\",\n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m94Rbf8Kqtib"
   },
   "source": [
    "In this lab, we are preparing to fine-tune the LLM using Reinforcement Learning (RL). RL will be briefly discussed in the next section of this lab, but at this stage, you just need to prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QybupsC-qsIF",
    "outputId": "a07bcd1d-2567-49bb-e4b6-ff11bd1f89ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-QDc-MzqwY-"
   },
   "source": [
    "During PPO, only a few parameters will be updated. Specifically, the parameters of the ValueHead. More information about this class of models can be found in the documentation. The number of trainable parameters can be computed as\n",
    ", where\n",
    " is the number of input units (here\n",
    ") and\n",
    " is the number of output units (you have\n",
    "). The\n",
    " term in the equation takes into account the bias term.\n",
    "\n",
    "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training. This is on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9D13Iczkqy1f",
    "outputId": "660993c1-03a9-4827-c400-daaccae17e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 251117569\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j15xE2VQgeWx"
   },
   "source": [
    "## Prepare Reward Model\n",
    "Reinforcement Learning (RL) is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the policy. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the reward function.\n",
    "\n",
    "In the previous section the original policy is based on the instruct PEFT model - this is the LLM before detoxification. Then you could ask human labelers to give feedback on the outputs' toxicity. However, it can be expensive to use them for the entire fine-tuning process. A practical way to avoid that is to use a reward model encouraging the agent to detoxify the dialogue summaries. The intuitive approach would be to do some form of sentiment analysis across two classes (nothate and hate) and give a higher reward if there is higher a chance of getting class nothate as an output.\n",
    "\n",
    "For example, we can mention that having human labelers for the entire finetuning process can be expensive. A practical way to avoid that is to use a reward model.\n",
    "\n",
    "use feedback generated by a model\n",
    "\n",
    "You will use Meta AI's RoBERTa-based hate speech model for the reward model. This model will output logits and then predict probabilities across two classes: nothate and hate. The logits of the output nothate will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n",
    "\n",
    "Create the instance of the required model class for the RoBERTa model. You also need to load a tokenizer to test the model. Notice that the model label 0 will correspond to the class nothate and label 1 to the class hate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUrtg4jMLcPF",
    "outputId": "427ce958-dee8-44ef-f7f9-a73a25d6e854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTw7MOvGg9ku"
   },
   "source": [
    "Take some non-toxic text, tokenize it, and pass it to the model. Print the output logits, probabilities, and the corresponding reward that will be used for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjkBLP0OLcRa",
    "outputId": "a2c501a0-fc1b-42e6-ce22-7cb23c5313c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.114100694656372, -2.4896175861358643]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.0036706167738884687]\n",
      "reward (high): [3.114100694656372]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "toxicity_input_ids = toxicity_input_ids.to('cuda:0')\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nU27bJPBt4la",
    "outputId": "458dd18f-668b-4dbd-9007-35ee58f9a03e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [-0.6921164393424988, 0.37227070331573486]\n",
      "probabilities [not hate, hate]: [0.2564719617366791, 0.7435280084609985]\n",
      "reward (low): [-0.6921164393424988]\n"
     ]
    }
   ],
   "source": [
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "toxicity_input_ids = toxicity_input_ids.to('cuda:0')\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (low): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADnpveR8hB-g"
   },
   "source": [
    "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "nFFOvOrtrj9g",
    "outputId": "6be48431-d2e5-4ca9-a737-6ffe4795847c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.34.1\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1)\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (4.5.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (2023.7.22)\n",
      "Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.3\n",
      "    Uninstalling huggingface-hub-0.19.3:\n",
      "      Successfully uninstalled huggingface-hub-0.19.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.2\n",
      "    Uninstalling transformers-4.27.2:\n",
      "      Successfully uninstalled transformers-4.27.2\n",
      "Successfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.34.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "huggingface_hub",
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install transformers==4.34.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRZWeAtQgmkY",
    "outputId": "ca8345a6-43dd-477f-e27a-abbd46232957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.114100694656372}, {'label': 'hate', 'score': -2.4896175861358643}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.003670616541057825}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.37227070331573486}, {'label': 'nothate', 'score': -0.6921164393424988}]\n",
      "[{'label': 'hate', 'score': 0.7435280084609985}, {'label': 'nothate', 'score': 0.25647199153900146}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"text-classification\",\n",
    "                          model=toxicity_model_name,\n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqDtAlfQuFJS"
   },
   "source": [
    "The outputs are the logits for both nothate (positive) and hate (negative) classes. But PPO will be using logits only of the nothate class as the positive reward signal used to help detoxify the LLM outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQucyASeuRQ0"
   },
   "source": [
    "### Evaluate Toxicity\n",
    "\n",
    "To evaluate the model before and after fine-tuning/detoxification you need to set up the toxicity evaluation metric. The toxicity score is a decimal value between 0 and 1 where 1 is the highest toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e04c30f5e0724da7a6c87c9413abd9c6",
      "8130c3ee35314dbca90ea2713837d3fe",
      "d60aaa03a94e45059e020bcedfc781f4",
      "d50e5cd6323a47f6ab09b62029d76c99",
      "1e0697a4444f4ad18eda19e5df5a83bb",
      "85b0b60bdfdd49c5885e7e8797a8b9a2",
      "a47a17a20dee4a01a534ca27c097dc2e",
      "d8eeb09273c34e7291cdf6443e2d1490",
      "9fe1d5671e884893b05ef73a51602fef",
      "9c302586bff249e181a7dbed343408b6",
      "739135eb14674e4c83bebcad4d2da828"
     ]
    },
    "id": "vzc4StMOgmr7",
    "outputId": "3427fcce-3479-415d-b3cf-a73e1bb335c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c30f5e0724da7a6c87c9413abd9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\",\n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsRHaOyagmuN",
    "outputId": "9f5528ea-44a4-4844-eda2-f99a950fba82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.003670616541057825]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435289621353149]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ7gAlO-udKl"
   },
   "source": [
    "This evaluator can be used to compute the toxicity of the dialogues prepared in section 2.1. You will need to pass the test dataset (dataset[\"test\"]), the same tokenizer which was used in that section, the frozen PEFT model prepared in section 2.2, and the toxicity evaluator. It is convenient to wrap the required steps in the function evaluate_toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "S0blZIS6gmwl"
   },
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model,\n",
    "                      toxicity_evaluator,\n",
    "                      tokenizer,\n",
    "                      dataset,\n",
    "                      num_samples):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"dialogue_text\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        input_ids = input_ids.to('cuda:0')\n",
    "\n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "\n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uyPuXmsgmyq",
    "outputId": "8c34028b-a735-4b4e-8d64-84316f031768"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:36,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.049949133430014954, 0.02331016123718669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model,\n",
    "                                                                          toxicity_evaluator=toxicity_evaluator,\n",
    "                                                                          tokenizer=tokenizer,\n",
    "                                                                          dataset=dataset[\"test\"],\n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF83igJyu8om"
   },
   "source": [
    "## Perform Fine-Tuning to Detoxify the Summaries\n",
    "\n",
    "### Initialize PPOTrainer\n",
    "For the PPOTrainer initialization, you will need a collator. Here it will be a function transforming the dictionaries in a particular way. You can define and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmAif65rueMg",
    "outputId": "2678c002-a65d-4cd8-9996-c3d56e72c7d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-24unq3vRL7"
   },
   "source": [
    "Set up the configuration parameters. Load the ppo_model and the tokenizer. You will also load a frozen version of the model ref_model. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g54FmR0MvLaJ"
   },
   "outputs": [],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config,\n",
    "                         model=ppo_model,\n",
    "                         ref_model=ref_model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset[\"train\"],\n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vvhdxD5vFNi"
   },
   "source": [
    "### Fine-Tune the Model\n",
    "The fine-tuning loop consists of the following main steps:\n",
    "\n",
    "Get the query responses from the policy LLM (PEFT model).\n",
    "Get sentiments for query/responses from hate speech RoBERTa model.\n",
    "Optimize policy with PPO using the (query, response, reward) triplet.\n",
    "The operation is running if you see the following metrics appearing:\n",
    "\n",
    "objective/kl: minimize kl divergence,\n",
    "ppo/returns/mean: maximize mean returns,\n",
    "ppo/policy/advantages_mean: maximize advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcJ_hKHIuePE",
    "outputId": "9b2d9ef5-03fd-4d3a-8b73-f8c8cbee66d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "1it [00:37, 37.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.11150603741407394\n",
      "ppo/returns/mean: 1.1376409530639648\n",
      "ppo/policy/advantages_mean: 0.011298708617687225\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:15, 37.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.09044323116540909\n",
      "ppo/returns/mean: 0.908376932144165\n",
      "ppo/policy/advantages_mean: 0.022010505199432373\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:38, 31.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.2957169711589813\n",
      "ppo/returns/mean: 1.252700924873352\n",
      "ppo/policy/advantages_mean: 0.05529604107141495\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:21, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.1604047417640686\n",
      "ppo/returns/mean: 1.0348403453826904\n",
      "ppo/policy/advantages_mean: 0.0456082820892334\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "5it [02:50, 33.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.31535449624061584\n",
      "ppo/returns/mean: 0.8840240240097046\n",
      "ppo/policy/advantages_mean: 0.22163742780685425\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [03:08, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.18221518397331238\n",
      "ppo/returns/mean: 1.2333779335021973\n",
      "ppo/policy/advantages_mean: 0.0013469010591506958\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:26, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.03232082724571228\n",
      "ppo/returns/mean: 1.118372917175293\n",
      "ppo/policy/advantages_mean: 0.11890614032745361\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:47, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.0606873482465744\n",
      "ppo/returns/mean: 0.9691619277000427\n",
      "ppo/policy/advantages_mean: 0.04041738063097\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:06, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.15578478574752808\n",
      "ppo/returns/mean: 1.076961874961853\n",
      "ppo/policy/advantages_mean: 0.03799702972173691\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [04:25, 26.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.1081928238272667\n",
      "ppo/returns/mean: 1.0370209217071533\n",
      "ppo/policy/advantages_mean: 0.015220753848552704\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrKVpWj4vjES"
   },
   "source": [
    "## Evaluate the Model Quantitatively\n",
    "Load the PPO/PEFT model back in from disk and use the test dataset split to evaluate the toxicity score of the RL-fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixXipVxqueRX",
    "outputId": "4527c49f-8a26-45c3-d94c-c12e4045e9c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:22,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] after detox: [0.03665001899935305, 0.0310408510653837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model,\n",
    "                                                                        toxicity_evaluator=toxicity_evaluator,\n",
    "                                                                        tokenizer=tokenizer,\n",
    "                                                                        dataset=dataset[\"test\"],\n",
    "                                                                        num_samples=10)\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhBti7xevq5w"
   },
   "source": [
    "And compare the toxicity scores of the reference model (before detoxification) and fine-tuned model (after detoxification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAJGDJrwueTv",
    "outputId": "78a4ef3b-9edf-41ed-f3b5-fdbc01a52a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage improvement of toxicity score after detoxification:\n",
      "mean: 26.63%\n",
      "std: -33.16%\n"
     ]
    }
   ],
   "source": [
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBtUTME2vv6n"
   },
   "source": [
    "###  Evaluate the Model Qualitatively\n",
    "\n",
    "Let's inspect some examples from the test dataset. You can compare the original ref_model to the fine-tuned/detoxified ppo_model using the toxicity evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T105_5X9ueWk",
    "outputId": "54a64747-3d2c-4f00-9497-e34031aeb00b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:48<00:00,  2.41s/it]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "\n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb9oA5sLv9sN"
   },
   "source": [
    "Store and review the results in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c8a0fq35vtl5",
    "outputId": "2ce8a1c0-eb78-4bb1-8e03-b474f17c318c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ab9d7257-8a6d-47b6-b799-f9c1b85790b2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. townperson: No. I don't hear much about it. I avoid a lot of those stories. Just rumors. villager: Look around. Can't you see this magnificent scenery and all the wildlife? These skittering chipmunks and crickets surly have to be magical. townperson: I think it's nature, but I doubt it's enchantment. villager: Nonsense. These tall thick plants and the life that the lake emits....I think there is something special to this place. I knew the villagers were ...</td>\n",
       "      <td>&lt;pad&gt; townperson dislikes the tales of imaginary worlds and even dislikes the villager sayings that his villages aren't nice.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Townperson is looking at some negative pictures about their area. They are from Trevno,point north.The villager is from 5 from Trevno,centurialty so near the boundaries.&lt;/s&gt;</td>\n",
       "      <td>2.952017</td>\n",
       "      <td>3.612338</td>\n",
       "      <td>0.660321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. hunter: I know where the wolves are sleeping! I can probably get a pup or two! person: Oh no hunter. Are you after me??? hunter: No, I am not after you. I told you I found the wolves person: Oh, I was afraid. I took food from the Lord's harvest. He sent people to get me. hunter: Why are you stealing from the lord's harvest? person: I have no food. He has tons. hunter: Can you not work? Do you not have a trade? person: I did but i was fired. Times are har...</td>\n",
       "      <td>&lt;pad&gt; The person is looking to buy a cub. He can use a chap from the Lord's harvest. He took food from the Lord's harvest. He has no money.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; person hired hunter to find the wolves. Hunter hunter said he found there is still nowhere to eat mice and not the slightest townspeople were certainly hungry. the patient dragged the wolves onto the field and used a...&lt;/s&gt;</td>\n",
       "      <td>1.894000</td>\n",
       "      <td>2.513767</td>\n",
       "      <td>0.619767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. villager: Look around. Can't you see this magnificent scenery and all the wildlife? These skittering chipmunks and crickets surly have to be magical. townperson: I think it's nature, but I doubt it's enchantment. villager: Nonsense. These tall thick plants and the life that the lake emits....I think there is something special to this place. I knew the villagers were right all along and I finally can see it now that I am here. townperson: I like the villa...</td>\n",
       "      <td>&lt;pad&gt; villager is from Trevno.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The town official tells villager he appreciates the beauty of Lydiante panorama. But the villager quarreles because he doesn't have the right to be here. The villager lives in Trevno, the town north of the forests. Villager decides to live in Katos and doesn't mind being separated from him.&lt;/s&gt;</td>\n",
       "      <td>2.978625</td>\n",
       "      <td>3.375443</td>\n",
       "      <td>0.396817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. person: Oh are you not allowed to explore the forest? villager: Oh yes, sometimes someone comes back a bit different...you know, not right in the head. But aside from that, it's a lovely forest. person: Well then that is why you get a bad reputation! Can you not have them see a physician villager: Well, the physicians refuse to see them until an exorcism is performed, and the priests refuse to perform an exorcism because \"none can cleanse the taint of th...</td>\n",
       "      <td>&lt;pad&gt; Villager and others enjoy sex and have secret meetings.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; villager was once an exorcism of the Earl. A part of human culture, he believes. It's also the practice of exorcism which, it turns out, was misused by an outlaw who had a skin to do sizable amounts of generally good, person's saved may be fishing in it nices \"holy boat\"\" that is used to raise, lowly position: the honourarium, annuelled, discounts total already, but Mr. Hill did, at least less painful than the drink, who did ticket sales. Thus once again, three heroic elephantvules hav...</td>\n",
       "      <td>1.397961</td>\n",
       "      <td>1.650126</td>\n",
       "      <td>0.252164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. bird: Oh my many fish here! I wish I could get one customer: Hello bird. I will trade you a fish for the new corn if you can find some for me bird: I can do that! I will search for it customer: Great, I think there is some coming in on a farmer's ship to sell in the town bird: Great I will go look and return the corn to you customer: And I will get some fish from the fishermen while you are off looking bird: Excellent we have a plan, be back in a shake! ...</td>\n",
       "      <td>&lt;pad&gt; bird is looking for a lot of fish. He needs to get new corn from the fishermen. The chickens are to be sold in the town. A bag of fish can be brought with bird. The next customer will return the corn.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; customers must find fish to trade them for corn and the corn picking for corn as chicken is coming in on a harvester's sale as well. Customer is offering to trade the corn to bird by wrapping the pasty in his shirt but the foxe is using its shirt to hold it in place. bird will bring the fish back to the customer if he can be sure to give him the order from him.&lt;/s&gt;</td>\n",
       "      <td>2.116979</td>\n",
       "      <td>2.284451</td>\n",
       "      <td>0.167471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. a frog: Ribbit.... servant: Hmm... maybe you do understand. I have plenty to eat and a nice, little room, but sometimes I wish I could go to the balls at the palace and dance. I do love to dance! a frog: Ribbit! Ribbit! Ribbit! servant: Ah, I see! You like to dance, too! We can dance together, wee frog! You will be my prince! a frog: Ahhhhhhh!!!!!! Ribbbbbb..... ittttt ahhhhhhhH! servant: Oh dear! Did I step on your foot? a frog: I'm aaaaaliiiiive!!! Hah...</td>\n",
       "      <td>&lt;pad&gt; A frog and a servant are going to dance at the ball \"oll on the palace\" and wish they could both eat there.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The frog uses a device to dance with another frog.&lt;/s&gt;</td>\n",
       "      <td>1.523583</td>\n",
       "      <td>1.680113</td>\n",
       "      <td>0.156529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. goblin: We are in the valley of doom! elf: Yes, this is my home. I love it here. No humans! goblin: What is so great of this doom? I cannot see what is so wonderful? elf: If you sit quite and stare in any direction for a while the magical animals will come out and they are beautiful indeed. goblin: Magical? Animals? How? What do they do that is so magical? elf: That is part of their mystery. each one has a different skill. goblin: Tell me elf, what anima...</td>\n",
       "      <td>&lt;pad&gt; elf loves the valley of doom, but got unsure where to go. The animal movies were filmed in the area.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Elena looks for a place in the valley, but ends up in one of the magical castles.&lt;/s&gt;</td>\n",
       "      <td>2.491690</td>\n",
       "      <td>2.638805</td>\n",
       "      <td>0.147115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. fox: Eh, I gobble them down in a couple of bites. I hardly notice the crunch. I've been lurking through these woods after being chased out of the kingdom. hog: This is my home. My owner is the sorceress. fox: Ah! You are lucky! She must make sure you are well-fed. Does she need another pet hog: I think she would like a fox. She really loves nature. fox: Oh, that would be majestic! And I could help her gather her ingredients for potions. hog: She could us...</td>\n",
       "      <td>&lt;pad&gt; fox and hog treat each other after being chased out of the kingdom.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Fox asks the sorceress, who has come from the throne and disappears deeply.&lt;/s&gt;</td>\n",
       "      <td>1.628430</td>\n",
       "      <td>1.767997</td>\n",
       "      <td>0.139567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. pirate: No sir. So we cannot let you go@ traveler: But I have a map. I was going to go treasure hunting. Would you be interested in that? I alone can read it. pirate: A treasure? Where would this treasure be? traveler: Oh how clumsy of me. It is due north of here. If you help me we could split the money..I mean booty. pirate: I will help you, but you split it 70/30.... 70 is mine! traveler: Why that is robbery...oh yea...pirate here. How about 60/40? I g...</td>\n",
       "      <td>&lt;pad&gt; Pirate faces robbery and pirate may trouble traveler being unintensified.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Pirate and pirate are petitioning over that pirate should rob pirate. Pirate has been allowed to save money, but can't get it to 60/550.&lt;/s&gt;</td>\n",
       "      <td>1.182047</td>\n",
       "      <td>1.275968</td>\n",
       "      <td>0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. a salesman: I have thought long and hard about this. I will want an initial fee for the sword. This price we can discuss. But I will need 20% of your proceeds. If you are willing to make me a named partner I will not charge a fee for the sword. owner: Why yes of course! We can definitely be partners for this deal, only if you promise none of the soldiers will get a hold of this sword. They are very indolent and all they do is camp here. I really need to ...</td>\n",
       "      <td>&lt;pad&gt; The salesman wants a fee but demands 20% of the salesmen's excess so that the two can negotiate a deal. His partner is the buyer.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The salesman asks the owner if they have heard of a deal for the sword and offers to double that amount. The salesman feels the plan gives the company a cost for chain mining.&lt;/s&gt;</td>\n",
       "      <td>1.912479</td>\n",
       "      <td>1.992040</td>\n",
       "      <td>0.079562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. guard: Pardon mine too! We work too hard to have fresh smelling feet, haha. Here, throw this over there with yours, would ya, so I don't lose 'em? mariner: Argggh your boots smell like whale barf, mate! geez... take a bath when we get to land, OK guard: Sorry, but that's the first time I've heard them described like that, and it's hilarious in it's accuracy! And sure thing, will do. mariner: Just wondering... you have been guarding this room, haven't you...</td>\n",
       "      <td>&lt;pad&gt; Guard and Mariner are going on a date. They are having a drink after trespassing on someone's property.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Mariner had a conversation with guard and a surfer intend to attract him outside.&lt;/s&gt;</td>\n",
       "      <td>1.579554</td>\n",
       "      <td>1.655710</td>\n",
       "      <td>0.076156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. pirate: A treasure? Where would this treasure be? traveler: Oh how clumsy of me. It is due north of here. If you help me we could split the money..I mean booty. pirate: I will help you, but you split it 70/30.... 70 is mine! traveler: Why that is robbery...oh yea...pirate here. How about 60/40? I get the 60 because I can read the map? And I want to go above decks to get some fresh air. I do not belong in this mess you call a sleeping quarter. pirate: 80/...</td>\n",
       "      <td>&lt;pad&gt; Pirate and traveler are going to split the money. Pirate advises them to head due north.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; pirate is going to solve an encounter.&lt;/s&gt;</td>\n",
       "      <td>1.472109</td>\n",
       "      <td>1.544614</td>\n",
       "      <td>0.072505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. mariner: pardon my smelly feet! haven't take a shower since who knows when. a few hours I think. This is not good. I will take a little rest and if he haven't come back, we'll look for him guard: Pardon mine too! We work too hard to have fresh smelling feet, haha. Here, throw this over there with yours, would ya, so I don't lose 'em? mariner: Argggh your boots smell like whale barf, mate! geez... take a bath when we get to land, OK guard: Sorry, but that...</td>\n",
       "      <td>&lt;pad&gt; When guard and mariner are going to land, mariner expects the man to take a shower but Dave doesn't want to go out. His boots smell like whale barf. After all this, the man cleaned theroom.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Mariner is having some sonorous bad breath. Guard is super thrilled and takes good care of that.&lt;/s&gt;</td>\n",
       "      <td>1.491166</td>\n",
       "      <td>1.561073</td>\n",
       "      <td>0.069907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. fisherman: Where is it you come from child? child: If you look through this you can see my home. It's very far away. fisherman: A crystal ball? You can see in this your home? I may not be able to see. child: Just stare and relax. You will see. fisherman: I will try, but I don't think it will work for me. It never has before? How are you seeing anything! child: Like this! You just have to relax and stop asking questions. Here I will start it for you. fish...</td>\n",
       "      <td>&lt;pad&gt; fisherman asks himself how to see the crystal ball, if he agreed to tell the child how to.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The writer says he already knew how to fish.&lt;/s&gt;</td>\n",
       "      <td>2.303893</td>\n",
       "      <td>2.260116</td>\n",
       "      <td>-0.043777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. hog: They must be pretty crunchy. fox: Eh, I gobble them down in a couple of bites. I hardly notice the crunch. I've been lurking through these woods after being chased out of the kingdom. hog: This is my home. My owner is the sorceress. fox: Ah! You are lucky! She must make sure you are well-fed. Does she need another pet hog: I think she would like a fox. She really loves nature. fox: Oh, that would be majestic! And I could help her gather her ingredie...</td>\n",
       "      <td>&lt;pad&gt; The sorceress is probably interested in giving hog something to eat. The sorceress doesn't eat, so pigs give him some things for a treat.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Boo is pleased with his new owner's attractiveness and his family. Buck once pestered the sorceress for his home. hog wonders if he can help to find the sorceress.&lt;/s&gt;</td>\n",
       "      <td>2.071638</td>\n",
       "      <td>2.006942</td>\n",
       "      <td>-0.064696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. owner: Why yes of course! We can definitely be partners for this deal, only if you promise none of the soldiers will get a hold of this sword. They are very indolent and all they do is camp here. I really need to get some gold out of this sale so my sons can eat, you see I've worked here on this land my whole life. Sometimes this warehouse work seems like it is not paying anything a salesman: We have a deal then. We must find a place to hide the sword. I...</td>\n",
       "      <td>&lt;pad&gt; The salesman agrees to agree on a deal. Sorry for hurting his reputation.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; A warehouse sale sells itself poorly. The item is in bad shape, so the mailbox needs to be opened before mass. After gifted it to the owner, the sword seller loses his feelings about money. He then agrees to pay the money but the seller dies during the sale. A witness is shot and killed when she sees her village yard defense patrol, pretends to be in an orgy with bulleyes. Her husband is shot three times, then finds the silver bullet lying everywhere but the her pet then drowns. She da...</td>\n",
       "      <td>2.224869</td>\n",
       "      <td>2.154382</td>\n",
       "      <td>-0.070488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. hunter: I know where the wolves are sleeping! I can probably get a pup or two! person: Oh no hunter. Are you after me??? hunter: No, I am not after you. I told you I found the wolves person: Oh, I was afraid. I took food from the Lord's harvest. He sent people to get me. hunter: Why are you stealing from the lord's harvest? person: I have no food. He has tons. hunter: Can you not work? Do you not have a trade? person: I did but i was fired. Times are har...</td>\n",
       "      <td>&lt;pad&gt; The person ran out of money to get wolves.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The person takes no food from the Lord's harvest. He took food from the Lord's harvest. Hunter is being pursued.&lt;/s&gt;</td>\n",
       "      <td>1.906589</td>\n",
       "      <td>1.797067</td>\n",
       "      <td>-0.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. goblin: We are in the valley of doom! elf: Yes, this is my home. I love it here. No humans! goblin: What is so great of this doom? I cannot see what is so wonderful? elf: If you sit quite and stare in any direction for a while the magical animals will come out and they are beautiful indeed. goblin: Magical? Animals? How? What do they do that is so magical? elf: That is part of their mystery. each one has a different skill. goblin: Tell me elf, what anima...</td>\n",
       "      <td>&lt;pad&gt; elf has been in this valley of doom.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Goblin tells elf the place of its located human's home.&lt;/s&gt;</td>\n",
       "      <td>2.385510</td>\n",
       "      <td>2.126285</td>\n",
       "      <td>-0.259225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. bird: Oh my many fish here! I wish I could get one customer: Hello bird. I will trade you a fish for the new corn if you can find some for me bird: I can do that! I will search for it customer: Great, I think there is some coming in on a farmer's ship to sell in the town bird: Great I will go look and return the corn to you customer: And I will get some fish from the fishermen while you are off looking bird: Excellent we have a plan, be back in a shake! ...</td>\n",
       "      <td>&lt;pad&gt; bird says it is trying to find pilaf.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; bird wishes to sell corn. His customer will help him do so.&lt;/s&gt;</td>\n",
       "      <td>2.423352</td>\n",
       "      <td>2.148040</td>\n",
       "      <td>-0.275312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. servant: I don't need this, but thank you. When I look at the drapings along the walls here, sometimes I pretend that I am a royal, too. You know what I mean? a frog: Ribbit.... servant: Hmm... maybe you do understand. I have plenty to eat and a nice, little room, but sometimes I wish I could go to the balls at the palace and dance. I do love to dance! a frog: Ribbit! Ribbit! Ribbit! servant: Ah, I see! You like to dance, too! We can dance together, wee ...</td>\n",
       "      <td>&lt;pad&gt; The servant is having a party at Promised Land.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Ribbit will be his next husband.&lt;/s&gt;</td>\n",
       "      <td>1.897188</td>\n",
       "      <td>1.569779</td>\n",
       "      <td>-0.327409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab9d7257-8a6d-47b6-b799-f9c1b85790b2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ab9d7257-8a6d-47b6-b799-f9c1b85790b2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ab9d7257-8a6d-47b6-b799-f9c1b85790b2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d11e94d6-b2e5-455f-8a98-9cdcdb32aaa5\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d11e94d6-b2e5-455f-8a98-9cdcdb32aaa5')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d11e94d6-b2e5-455f-8a98-9cdcdb32aaa5 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following conversation. townperson: No. I don't hear much about it. I avoid a lot of those stories. Just rumors. villager: Look around. Can't you see this magnificent scenery and all the wildlife? These skittering chipmunks and crickets surly have to be magical. townperson: I think it's nature, but I doubt it's enchantment. villager: Nonsense. These tall thick plants and the life that the lake emits....I think there is something special to this place. I knew the villagers were ...   \n",
       "1   Summarize the following conversation. hunter: I know where the wolves are sleeping! I can probably get a pup or two! person: Oh no hunter. Are you after me??? hunter: No, I am not after you. I told you I found the wolves person: Oh, I was afraid. I took food from the Lord's harvest. He sent people to get me. hunter: Why are you stealing from the lord's harvest? person: I have no food. He has tons. hunter: Can you not work? Do you not have a trade? person: I did but i was fired. Times are har...   \n",
       "2   Summarize the following conversation. villager: Look around. Can't you see this magnificent scenery and all the wildlife? These skittering chipmunks and crickets surly have to be magical. townperson: I think it's nature, but I doubt it's enchantment. villager: Nonsense. These tall thick plants and the life that the lake emits....I think there is something special to this place. I knew the villagers were right all along and I finally can see it now that I am here. townperson: I like the villa...   \n",
       "3   Summarize the following conversation. person: Oh are you not allowed to explore the forest? villager: Oh yes, sometimes someone comes back a bit different...you know, not right in the head. But aside from that, it's a lovely forest. person: Well then that is why you get a bad reputation! Can you not have them see a physician villager: Well, the physicians refuse to see them until an exorcism is performed, and the priests refuse to perform an exorcism because \"none can cleanse the taint of th...   \n",
       "4   Summarize the following conversation. bird: Oh my many fish here! I wish I could get one customer: Hello bird. I will trade you a fish for the new corn if you can find some for me bird: I can do that! I will search for it customer: Great, I think there is some coming in on a farmer's ship to sell in the town bird: Great I will go look and return the corn to you customer: And I will get some fish from the fishermen while you are off looking bird: Excellent we have a plan, be back in a shake! ...   \n",
       "5   Summarize the following conversation. a frog: Ribbit.... servant: Hmm... maybe you do understand. I have plenty to eat and a nice, little room, but sometimes I wish I could go to the balls at the palace and dance. I do love to dance! a frog: Ribbit! Ribbit! Ribbit! servant: Ah, I see! You like to dance, too! We can dance together, wee frog! You will be my prince! a frog: Ahhhhhhh!!!!!! Ribbbbbb..... ittttt ahhhhhhhH! servant: Oh dear! Did I step on your foot? a frog: I'm aaaaaliiiiive!!! Hah...   \n",
       "6   Summarize the following conversation. goblin: We are in the valley of doom! elf: Yes, this is my home. I love it here. No humans! goblin: What is so great of this doom? I cannot see what is so wonderful? elf: If you sit quite and stare in any direction for a while the magical animals will come out and they are beautiful indeed. goblin: Magical? Animals? How? What do they do that is so magical? elf: That is part of their mystery. each one has a different skill. goblin: Tell me elf, what anima...   \n",
       "7   Summarize the following conversation. fox: Eh, I gobble them down in a couple of bites. I hardly notice the crunch. I've been lurking through these woods after being chased out of the kingdom. hog: This is my home. My owner is the sorceress. fox: Ah! You are lucky! She must make sure you are well-fed. Does she need another pet hog: I think she would like a fox. She really loves nature. fox: Oh, that would be majestic! And I could help her gather her ingredients for potions. hog: She could us...   \n",
       "8   Summarize the following conversation. pirate: No sir. So we cannot let you go@ traveler: But I have a map. I was going to go treasure hunting. Would you be interested in that? I alone can read it. pirate: A treasure? Where would this treasure be? traveler: Oh how clumsy of me. It is due north of here. If you help me we could split the money..I mean booty. pirate: I will help you, but you split it 70/30.... 70 is mine! traveler: Why that is robbery...oh yea...pirate here. How about 60/40? I g...   \n",
       "9   Summarize the following conversation. a salesman: I have thought long and hard about this. I will want an initial fee for the sword. This price we can discuss. But I will need 20% of your proceeds. If you are willing to make me a named partner I will not charge a fee for the sword. owner: Why yes of course! We can definitely be partners for this deal, only if you promise none of the soldiers will get a hold of this sword. They are very indolent and all they do is camp here. I really need to ...   \n",
       "10  Summarize the following conversation. guard: Pardon mine too! We work too hard to have fresh smelling feet, haha. Here, throw this over there with yours, would ya, so I don't lose 'em? mariner: Argggh your boots smell like whale barf, mate! geez... take a bath when we get to land, OK guard: Sorry, but that's the first time I've heard them described like that, and it's hilarious in it's accuracy! And sure thing, will do. mariner: Just wondering... you have been guarding this room, haven't you...   \n",
       "11  Summarize the following conversation. pirate: A treasure? Where would this treasure be? traveler: Oh how clumsy of me. It is due north of here. If you help me we could split the money..I mean booty. pirate: I will help you, but you split it 70/30.... 70 is mine! traveler: Why that is robbery...oh yea...pirate here. How about 60/40? I get the 60 because I can read the map? And I want to go above decks to get some fresh air. I do not belong in this mess you call a sleeping quarter. pirate: 80/...   \n",
       "12  Summarize the following conversation. mariner: pardon my smelly feet! haven't take a shower since who knows when. a few hours I think. This is not good. I will take a little rest and if he haven't come back, we'll look for him guard: Pardon mine too! We work too hard to have fresh smelling feet, haha. Here, throw this over there with yours, would ya, so I don't lose 'em? mariner: Argggh your boots smell like whale barf, mate! geez... take a bath when we get to land, OK guard: Sorry, but that...   \n",
       "13  Summarize the following conversation. fisherman: Where is it you come from child? child: If you look through this you can see my home. It's very far away. fisherman: A crystal ball? You can see in this your home? I may not be able to see. child: Just stare and relax. You will see. fisherman: I will try, but I don't think it will work for me. It never has before? How are you seeing anything! child: Like this! You just have to relax and stop asking questions. Here I will start it for you. fish...   \n",
       "14  Summarize the following conversation. hog: They must be pretty crunchy. fox: Eh, I gobble them down in a couple of bites. I hardly notice the crunch. I've been lurking through these woods after being chased out of the kingdom. hog: This is my home. My owner is the sorceress. fox: Ah! You are lucky! She must make sure you are well-fed. Does she need another pet hog: I think she would like a fox. She really loves nature. fox: Oh, that would be majestic! And I could help her gather her ingredie...   \n",
       "15  Summarize the following conversation. owner: Why yes of course! We can definitely be partners for this deal, only if you promise none of the soldiers will get a hold of this sword. They are very indolent and all they do is camp here. I really need to get some gold out of this sale so my sons can eat, you see I've worked here on this land my whole life. Sometimes this warehouse work seems like it is not paying anything a salesman: We have a deal then. We must find a place to hide the sword. I...   \n",
       "16  Summarize the following conversation. hunter: I know where the wolves are sleeping! I can probably get a pup or two! person: Oh no hunter. Are you after me??? hunter: No, I am not after you. I told you I found the wolves person: Oh, I was afraid. I took food from the Lord's harvest. He sent people to get me. hunter: Why are you stealing from the lord's harvest? person: I have no food. He has tons. hunter: Can you not work? Do you not have a trade? person: I did but i was fired. Times are har...   \n",
       "17  Summarize the following conversation. goblin: We are in the valley of doom! elf: Yes, this is my home. I love it here. No humans! goblin: What is so great of this doom? I cannot see what is so wonderful? elf: If you sit quite and stare in any direction for a while the magical animals will come out and they are beautiful indeed. goblin: Magical? Animals? How? What do they do that is so magical? elf: That is part of their mystery. each one has a different skill. goblin: Tell me elf, what anima...   \n",
       "18  Summarize the following conversation. bird: Oh my many fish here! I wish I could get one customer: Hello bird. I will trade you a fish for the new corn if you can find some for me bird: I can do that! I will search for it customer: Great, I think there is some coming in on a farmer's ship to sell in the town bird: Great I will go look and return the corn to you customer: And I will get some fish from the fishermen while you are off looking bird: Excellent we have a plan, be back in a shake! ...   \n",
       "19  Summarize the following conversation. servant: I don't need this, but thank you. When I look at the drapings along the walls here, sometimes I pretend that I am a royal, too. You know what I mean? a frog: Ribbit.... servant: Hmm... maybe you do understand. I have plenty to eat and a nice, little room, but sometimes I wish I could go to the balls at the palace and dance. I do love to dance! a frog: Ribbit! Ribbit! Ribbit! servant: Ah, I see! You like to dance, too! We can dance together, wee ...   \n",
       "\n",
       "                                                                                                                                                                                                       response_before  \\\n",
       "0                                                                                    <pad> townperson dislikes the tales of imaginary worlds and even dislikes the villager sayings that his villages aren't nice.</s>   \n",
       "1                                                                      <pad> The person is looking to buy a cub. He can use a chap from the Lord's harvest. He took food from the Lord's harvest. He has no money.</s>   \n",
       "2                                                                                                                                                                                   <pad> villager is from Trevno.</s>   \n",
       "3                                                                                                                                                    <pad> Villager and others enjoy sex and have secret meetings.</s>   \n",
       "4   <pad> bird is looking for a lot of fish. He needs to get new corn from the fishermen. The chickens are to be sold in the town. A bag of fish can be brought with bird. The next customer will return the corn.</s>   \n",
       "5                                                                                                <pad> A frog and a servant are going to dance at the ball \"oll on the palace\" and wish they could both eat there.</s>   \n",
       "6                                                                                                       <pad> elf loves the valley of doom, but got unsure where to go. The animal movies were filmed in the area.</s>   \n",
       "7                                                                                                                                        <pad> fox and hog treat each other after being chased out of the kingdom.</s>   \n",
       "8                                                                                                                                  <pad> Pirate faces robbery and pirate may trouble traveler being unintensified.</s>   \n",
       "9                                                                          <pad> The salesman wants a fee but demands 20% of the salesmen's excess so that the two can negotiate a deal. His partner is the buyer.</s>   \n",
       "10                                                                                                   <pad> Guard and Mariner are going on a date. They are having a drink after trespassing on someone's property.</s>   \n",
       "11                                                                                                                  <pad> Pirate and traveler are going to split the money. Pirate advises them to head due north.</s>   \n",
       "12             <pad> When guard and mariner are going to land, mariner expects the man to take a shower but Dave doesn't want to go out. His boots smell like whale barf. After all this, the man cleaned theroom.</s>   \n",
       "13                                                                                                                <pad> fisherman asks himself how to see the crystal ball, if he agreed to tell the child how to.</s>   \n",
       "14                                                                 <pad> The sorceress is probably interested in giving hog something to eat. The sorceress doesn't eat, so pigs give him some things for a treat.</s>   \n",
       "15                                                                                                                                 <pad> The salesman agrees to agree on a deal. Sorry for hurting his reputation.</s>   \n",
       "16                                                                                                                                                                <pad> The person ran out of money to get wolves.</s>   \n",
       "17                                                                                                                                                                      <pad> elf has been in this valley of doom.</s>   \n",
       "18                                                                                                                                                                     <pad> bird says it is trying to find pilaf.</s>   \n",
       "19                                                                                                                                                           <pad> The servant is having a party at Promised Land.</s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         response_after  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                   <pad> Townperson is looking at some negative pictures about their area. They are from Trevno,point north.The villager is from 5 from Trevno,centurialty so near the boundaries.</s>   \n",
       "1                                                                                                                                                                                                                                                                                 <pad> person hired hunter to find the wolves. Hunter hunter said he found there is still nowhere to eat mice and not the slightest townspeople were certainly hungry. the patient dragged the wolves onto the field and used a...</s>   \n",
       "2                                                                                                                                                                                                         <pad> The town official tells villager he appreciates the beauty of Lydiante panorama. But the villager quarreles because he doesn't have the right to be here. The villager lives in Trevno, the town north of the forests. Villager decides to live in Katos and doesn't mind being separated from him.</s>   \n",
       "3   <pad> villager was once an exorcism of the Earl. A part of human culture, he believes. It's also the practice of exorcism which, it turns out, was misused by an outlaw who had a skin to do sizable amounts of generally good, person's saved may be fishing in it nices \"holy boat\"\" that is used to raise, lowly position: the honourarium, annuelled, discounts total already, but Mr. Hill did, at least less painful than the drink, who did ticket sales. Thus once again, three heroic elephantvules hav...   \n",
       "4                                                                                                                                 <pad> customers must find fish to trade them for corn and the corn picking for corn as chicken is coming in on a harvester's sale as well. Customer is offering to trade the corn to bird by wrapping the pasty in his shirt but the foxe is using its shirt to hold it in place. bird will bring the fish back to the customer if he can be sure to give him the order from him.</s>   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                          <pad> The frog uses a device to dance with another frog.</s>   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                           <pad> Elena looks for a place in the valley, but ends up in one of the magical castles.</s>   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                 <pad> Fox asks the sorceress, who has come from the throne and disappears deeply.</s>   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                    <pad> Pirate and pirate are petitioning over that pirate should rob pirate. Pirate has been allowed to save money, but can't get it to 60/550.</s>   \n",
       "9                                                                                                                                                                                                                                                                                                                             <pad> The salesman asks the owner if they have heard of a deal for the sword and offers to double that amount. The salesman feels the plan gives the company a cost for chain mining.</s>   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                          <pad> Mariner had a conversation with guard and a surfer intend to attract him outside.</s>   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <pad> pirate is going to solve an encounter.</s>   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                           <pad> Mariner is having some sonorous bad breath. Guard is super thrilled and takes good care of that.</s>   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                               <pad> The writer says he already knew how to fish.</s>   \n",
       "14                                                                                                                                                                                                                                                                                                                                        <pad> Boo is pleased with his new owner's attractiveness and his family. Buck once pestered the sorceress for his home. hog wonders if he can help to find the sorceress.</s>   \n",
       "15  <pad> A warehouse sale sells itself poorly. The item is in bad shape, so the mailbox needs to be opened before mass. After gifted it to the owner, the sword seller loses his feelings about money. He then agrees to pay the money but the seller dies during the sale. A witness is shot and killed when she sees her village yard defense patrol, pretends to be in an orgy with bulleyes. Her husband is shot three times, then finds the silver bullet lying everywhere but the her pet then drowns. She da...   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                           <pad> The person takes no food from the Lord's harvest. He took food from the Lord's harvest. Hunter is being pursued.</s>   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                    <pad> Goblin tells elf the place of its located human's home.</s>   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                <pad> bird wishes to sell corn. His customer will help him do so.</s>   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                           <pad> Ribbit will be his next husband.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        2.952017      3.612338     0.660321  \n",
       "1        1.894000      2.513767     0.619767  \n",
       "2        2.978625      3.375443     0.396817  \n",
       "3        1.397961      1.650126     0.252164  \n",
       "4        2.116979      2.284451     0.167471  \n",
       "5        1.523583      1.680113     0.156529  \n",
       "6        2.491690      2.638805     0.147115  \n",
       "7        1.628430      1.767997     0.139567  \n",
       "8        1.182047      1.275968     0.093921  \n",
       "9        1.912479      1.992040     0.079562  \n",
       "10       1.579554      1.655710     0.076156  \n",
       "11       1.472109      1.544614     0.072505  \n",
       "12       1.491166      1.561073     0.069907  \n",
       "13       2.303893      2.260116    -0.043777  \n",
       "14       2.071638      2.006942    -0.064696  \n",
       "15       2.224869      2.154382    -0.070488  \n",
       "16       1.906589      1.797067    -0.109522  \n",
       "17       2.385510      2.126285    -0.259225  \n",
       "18       2.423352      2.148040    -0.275312  \n",
       "19       1.897188      1.569779    -0.327409  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nn3iXw5Pvtoj"
   },
   "source": [
    "## Conclusion\r\n",
    "In our laboratory sessions, we explored the concepts of zero-shot, one-shot, and few-shot inference, observing their impact on the results. Additionally, we delved into some aspects of prompt engineering. Utilizing various Google models as foundational structures, we enhanced our understanding of in-context learning. Moreover, we employed an instruction fine-tuned model, commonly referred to as the instruct model, and conducted comparisons of the outcomes both manually and through quantitative measures, specifically using ROUGE scores. Our experiments also included the implementation of PEFT models, which revealed variations in the summarization results. Furthermore, we integrated a reward model aimed at diminishing the toxicity in the generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "https://www.coursera.org/learn/generative-ai-with-llms <br>\n",
    "https://huggingface.co/google/flan-t5-small <br>\n",
    "https://huggingface.co/google/flan-t5-base <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "027ecc2d035e4eb396bbeec01df6f25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c7fc2d679fb4a519355d9f714f37f7f",
      "max": 2537,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4906877023364f64af7e081e5d3ac686",
      "value": 2537
     }
    },
    "0a7d32c78a764292b949d6947de2c9c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a94edd51ca345db8727cd0fe0891ead": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aefca061d89495ba0e1307135def6af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b638837398342ebad950dff6b4c3493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c21ed5919ab410bae4add1db65f08e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ec4b4c9c0344cb9ae7fa197fe1dc972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10be47defc7f46fa939cf640576b99a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1239fcdcec9b409eb17ae440074d9e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1373fc9ae45941eaa6ea028924e2e4d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7327f316e1fd412ca23078f7e330137a",
      "placeholder": "​",
      "style": "IPY_MODEL_f970e8b182314bdebb5af6bc2af3a4a1",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "14dd0628e754457a9d5439172d534583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "191c55958be04f42a0990b8a76f40765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff11862c28243f787fae3c862ae1c5a",
      "max": 990345061,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e61fd9cff00042ad91957999f6a5f811",
      "value": 990345061
     }
    },
    "1e0697a4444f4ad18eda19e5df5a83bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eb050def9f7466ba826632e9a00af61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f19d1d02a11411fb4f3d7185295056d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a94edd51ca345db8727cd0fe0891ead",
      "placeholder": "​",
      "style": "IPY_MODEL_27e40bf4a0c54221be0d3d6d3b777321",
      "value": "100%"
     }
    },
    "1fb43199f93a4de584107239d0bac3c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67142236414f4a0e97441b99d19a5994",
      "placeholder": "​",
      "style": "IPY_MODEL_3a6e943f24b54d2ea5aca34cc924ae95",
      "value": " 2.54k/2.54k [00:00&lt;00:00, 90.8kB/s]"
     }
    },
    "2032827037c945239de4aad71dceadf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f19d1d02a11411fb4f3d7185295056d",
       "IPY_MODEL_eef683ad06b34d419483cae503b43e88",
       "IPY_MODEL_7e7695e440b840bea00ab99be116865d"
      ],
      "layout": "IPY_MODEL_14dd0628e754457a9d5439172d534583"
     }
    },
    "2526f953adf54c5b9a888a2f8e374829": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27e40bf4a0c54221be0d3d6d3b777321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28fa3ab9826c4b7a8ca03f20ea38a3c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bdf2425e0f24510a35bb15984d97aea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c21ed5919ab410bae4add1db65f08e4",
      "placeholder": "​",
      "style": "IPY_MODEL_fda25a48119e4a5cbcf1b31bf2093c6c",
      "value": " 3/3 [00:00&lt;00:00, 83.12it/s]"
     }
    },
    "2c7fc2d679fb4a519355d9f714f37f7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dd4947b23614e0f892133a90254ff72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fe6a592c6204280a97104617bf9c177": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30acc5313a9247c19af03e9434149e80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad2049edf78440e29678c1198b19dc32",
      "max": 1404,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1239fcdcec9b409eb17ae440074d9e82",
      "value": 1404
     }
    },
    "30e051f96c3445e0b7998b1099761799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3174b99cb4394c06aa299f0bca95c9cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3698755ea8cc419298b7b400f0b874a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a0c370cea5b4909a5fad8a16d989bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff918ed720ee40fc8ed29cb2d0e4d99a",
      "max": 147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ec4b4c9c0344cb9ae7fa197fe1dc972",
      "value": 147
     }
    },
    "3a6e943f24b54d2ea5aca34cc924ae95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b27aaef0b154038bffcad853f222ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_671c75c18d634e5387ef8bd57262caf8",
      "placeholder": "​",
      "style": "IPY_MODEL_770320f9ee854bebbb48438928359244",
      "value": " 2.20k/2.20k [00:00&lt;00:00, 105kB/s]"
     }
    },
    "3b8096fab86248fc9c725bee05d255d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2d12a67df2c4b9abcd11a29fe70bfd5",
      "placeholder": "​",
      "style": "IPY_MODEL_e277e398cf7f4f3b9045f77b5936d23a",
      "value": "spiece.model: 100%"
     }
    },
    "3c9f1eb5d85841d3ade023c6f68e4019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dfc1aeae6624a059c01d11aae47c09e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b57544ed241747e18735d6b11edc554a",
      "placeholder": "​",
      "style": "IPY_MODEL_8c9c19581ac14c55a7274c8440d83a65",
      "value": "Map: 100%"
     }
    },
    "404c41de83b04a77a43b4f132474a33d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc2e255d013d4f28a973fc1ce3874ce8",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc53fd3726a04a5bb7b0f17cb0b2ef87",
      "value": 3
     }
    },
    "448da687a7b94002ba2dda5d0360bf62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4e9d941c1bf477ebf20fcbb068a579c",
       "IPY_MODEL_74e21f20186d4fadbc8e0aa2800b4e68",
       "IPY_MODEL_a921a89da88746f397d28c8c7cb5934a"
      ],
      "layout": "IPY_MODEL_5bbc14a35549475b8df92d97b5400a29"
     }
    },
    "468d7f1483274b12831d74364775a519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4716fb6c7f8746f193d38a50723480a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4906877023364f64af7e081e5d3ac686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4affcf780bc840e2abe512444471be67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dd4947b23614e0f892133a90254ff72",
      "placeholder": "​",
      "style": "IPY_MODEL_4716fb6c7f8746f193d38a50723480a6",
      "value": " 6.27k/6.27k [00:00&lt;00:00, 158kB/s]"
     }
    },
    "4da6a4319c774d8ca794606e67f92990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4f187d4a06e49b284e61ffbd317e645",
      "placeholder": "​",
      "style": "IPY_MODEL_3698755ea8cc419298b7b400f0b874a0",
      "value": " 147/147 [00:00&lt;00:00, 5.71kB/s]"
     }
    },
    "528051e895794cefb3a970202a168391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8bf3c4364fd4baab0d4d256c6cebc08",
       "IPY_MODEL_191c55958be04f42a0990b8a76f40765",
       "IPY_MODEL_970153e1dec8433690c8e246e424da9f"
      ],
      "layout": "IPY_MODEL_0aefca061d89495ba0e1307135def6af"
     }
    },
    "52c2d6b209c64619ae4ee1b5f49c9cc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6821ed0c449d4d4ea1f360cb103f3bc6",
      "placeholder": "​",
      "style": "IPY_MODEL_f0bb6ca5f8d0463d8f4849cbc7f47497",
      "value": " 792k/792k [00:00&lt;00:00, 23.0MB/s]"
     }
    },
    "5bbc14a35549475b8df92d97b5400a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dbe9cb7ff044680b61cd5940f8ae9dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ed10e114bbf4c68aeca616190bccaad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb050def9f7466ba826632e9a00af61",
      "max": 2201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2526f953adf54c5b9a888a2f8e374829",
      "value": 2201
     }
    },
    "6020bacf09094e2484c81d2614f234e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63468159691e4b3fa59ee40e4da5d612": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67142236414f4a0e97441b99d19a5994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671c75c18d634e5387ef8bd57262caf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6821ed0c449d4d4ea1f360cb103f3bc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ee95d8239f648afb32d1a5eae3b2f1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f6acdb712a14424a8f1d63910f46442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f901107052e4d26977a8d0329077332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7164cfaa96f8438a9c7f0318e3c9626a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d31541976ef740589f6f3bf1a2d1f350",
      "placeholder": "​",
      "style": "IPY_MODEL_6f6acdb712a14424a8f1d63910f46442",
      "value": " 1.40k/1.40k [00:00&lt;00:00, 41.1kB/s]"
     }
    },
    "718d60ee34c84b80a5b035fc9b61e305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7327f316e1fd412ca23078f7e330137a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "739135eb14674e4c83bebcad4d2da828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74e21f20186d4fadbc8e0aa2800b4e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd3e74037aed41d9b1eaf4386ddb750a",
      "max": 2424064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fe6a592c6204280a97104617bf9c177",
      "value": 2424064
     }
    },
    "770320f9ee854bebbb48438928359244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e7695e440b840bea00ab99be116865d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28fa3ab9826c4b7a8ca03f20ea38a3c4",
      "placeholder": "​",
      "style": "IPY_MODEL_6020bacf09094e2484c81d2614f234e9",
      "value": " 3/3 [00:00&lt;00:00, 119.72it/s]"
     }
    },
    "8130c3ee35314dbca90ea2713837d3fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85b0b60bdfdd49c5885e7e8797a8b9a2",
      "placeholder": "​",
      "style": "IPY_MODEL_a47a17a20dee4a01a534ca27c097dc2e",
      "value": "Downloading builder script: 100%"
     }
    },
    "85b0b60bdfdd49c5885e7e8797a8b9a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "870b71f731fb4f1bbad10e4ce8f220e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6a1491312b548ab84beeddec0cb6a4e",
      "max": 6270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10be47defc7f46fa939cf640576b99a7",
      "value": 6270
     }
    },
    "89a85f8a572048a596b89b3fc0f5d14e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aae0f53ea7f4d748029fb27f0682f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ed876973494467fa31f4d80bfef5743",
      "placeholder": "​",
      "style": "IPY_MODEL_c1817231aa124b7e82cbc293a9f00882",
      "value": "Downloading builder script: 100%"
     }
    },
    "8c9c19581ac14c55a7274c8440d83a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ce5e351eabb424a8d15806de65066cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b8096fab86248fc9c725bee05d255d5",
       "IPY_MODEL_d4dcac2f2b5e46129899bdb0ba947d80",
       "IPY_MODEL_52c2d6b209c64619ae4ee1b5f49c9cc9"
      ],
      "layout": "IPY_MODEL_a901aa9a6da34191b5bb8cf64f1a3b4b"
     }
    },
    "8ce765416bcd4611b4fd71d51e0c1534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3ee07279d0542a6a3dcbd74271a9d2b",
       "IPY_MODEL_3a0c370cea5b4909a5fad8a16d989bc2",
       "IPY_MODEL_4da6a4319c774d8ca794606e67f92990"
      ],
      "layout": "IPY_MODEL_9d5b9cf44f6b43f583c101b0cf963e17"
     }
    },
    "8ff11862c28243f787fae3c862ae1c5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91095f8fb1944ab49d15b0f3baafebf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1373fc9ae45941eaa6ea028924e2e4d7",
       "IPY_MODEL_027ecc2d035e4eb396bbeec01df6f25f",
       "IPY_MODEL_1fb43199f93a4de584107239d0bac3c2"
      ],
      "layout": "IPY_MODEL_89a85f8a572048a596b89b3fc0f5d14e"
     }
    },
    "936577ac1f284728868ec2e6d879ea59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "970153e1dec8433690c8e246e424da9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abfd83929c5247c28602115d8c2ee985",
      "placeholder": "​",
      "style": "IPY_MODEL_3c9f1eb5d85841d3ade023c6f68e4019",
      "value": " 990M/990M [00:11&lt;00:00, 102MB/s]"
     }
    },
    "9c302586bff249e181a7dbed343408b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d5b9cf44f6b43f583c101b0cf963e17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed876973494467fa31f4d80bfef5743": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f3995f33cf84bb08ef97942a0aa585b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fe1d5671e884893b05ef73a51602fef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a47a17a20dee4a01a534ca27c097dc2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8bf3c4364fd4baab0d4d256c6cebc08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ee95d8239f648afb32d1a5eae3b2f1f",
      "placeholder": "​",
      "style": "IPY_MODEL_5dbe9cb7ff044680b61cd5940f8ae9dd",
      "value": "model.safetensors: 100%"
     }
    },
    "a901aa9a6da34191b5bb8cf64f1a3b4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a921a89da88746f397d28c8c7cb5934a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b638837398342ebad950dff6b4c3493",
      "placeholder": "​",
      "style": "IPY_MODEL_dc696166acdd49b1b5998138aa686f35",
      "value": " 2.42M/2.42M [00:00&lt;00:00, 19.0MB/s]"
     }
    },
    "abfd83929c5247c28602115d8c2ee985": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad2049edf78440e29678c1198b19dc32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4e9d941c1bf477ebf20fcbb068a579c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfc838acc7414d349e8ac50a8119ad91",
      "placeholder": "​",
      "style": "IPY_MODEL_718d60ee34c84b80a5b035fc9b61e305",
      "value": "tokenizer.json: 100%"
     }
    },
    "b57544ed241747e18735d6b11edc554a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad9196edf9f48f1b2555b3e799b7619": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc838acc7414d349e8ac50a8119ad91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c11be68fcc6747578049f70b0bee3541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1817231aa124b7e82cbc293a9f00882": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2ccbefd9c0c4483baaf6ecdd942c418": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3e590bf625044b2a59aa7f3c9f6d813": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86b7db535f243b1880b6052eb513fcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc53fd3726a04a5bb7b0f17cb0b2ef87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd119fa2d44b48a483109e251b9775eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2ccbefd9c0c4483baaf6ecdd942c418",
      "max": 15643,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1e47eaabdef49bbb65a8a168ae57dca",
      "value": 15643
     }
    },
    "cd3e74037aed41d9b1eaf4386ddb750a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdfc69ad5a8446cbb307868bed7f15ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0d55511b3bd4af4802faa94f5c14bee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d31541976ef740589f6f3bf1a2d1f350": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3ee07279d0542a6a3dcbd74271a9d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63468159691e4b3fa59ee40e4da5d612",
      "placeholder": "​",
      "style": "IPY_MODEL_c86b7db535f243b1880b6052eb513fcb",
      "value": "generation_config.json: 100%"
     }
    },
    "d4dcac2f2b5e46129899bdb0ba947d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d878acdaa271469896c7b8c6340e8037",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30e051f96c3445e0b7998b1099761799",
      "value": 791656
     }
    },
    "d50e5cd6323a47f6ab09b62029d76c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c302586bff249e181a7dbed343408b6",
      "placeholder": "​",
      "style": "IPY_MODEL_739135eb14674e4c83bebcad4d2da828",
      "value": " 6.08k/6.08k [00:00&lt;00:00, 118kB/s]"
     }
    },
    "d60aaa03a94e45059e020bcedfc781f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8eeb09273c34e7291cdf6443e2d1490",
      "max": 6077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fe1d5671e884893b05ef73a51602fef",
      "value": 6077
     }
    },
    "d878acdaa271469896c7b8c6340e8037": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8eeb09273c34e7291cdf6443e2d1490": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9b435ac405540bb8784f7746eab2e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0cb30dfa089441da738316359923a38",
       "IPY_MODEL_404c41de83b04a77a43b4f132474a33d",
       "IPY_MODEL_2bdf2425e0f24510a35bb15984d97aea"
      ],
      "layout": "IPY_MODEL_bad9196edf9f48f1b2555b3e799b7619"
     }
    },
    "db675fbb65d74ca6b1417f512d45ac26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff4f6daa3c624fae96b7bfe93c387dae",
       "IPY_MODEL_30acc5313a9247c19af03e9434149e80",
       "IPY_MODEL_7164cfaa96f8438a9c7f0318e3c9626a"
      ],
      "layout": "IPY_MODEL_cdfc69ad5a8446cbb307868bed7f15ad"
     }
    },
    "dc696166acdd49b1b5998138aa686f35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd4630fd33534ae2999e2052874bd2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c11be68fcc6747578049f70b0bee3541",
      "placeholder": "​",
      "style": "IPY_MODEL_6f901107052e4d26977a8d0329077332",
      "value": " 15637/15643 [00:51&lt;00:00, 219.69 examples/s]"
     }
    },
    "e04c30f5e0724da7a6c87c9413abd9c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8130c3ee35314dbca90ea2713837d3fe",
       "IPY_MODEL_d60aaa03a94e45059e020bcedfc781f4",
       "IPY_MODEL_d50e5cd6323a47f6ab09b62029d76c99"
      ],
      "layout": "IPY_MODEL_1e0697a4444f4ad18eda19e5df5a83bb"
     }
    },
    "e0cb30dfa089441da738316359923a38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3e590bf625044b2a59aa7f3c9f6d813",
      "placeholder": "​",
      "style": "IPY_MODEL_f58bd2519b834a02854123612b8d272e",
      "value": "100%"
     }
    },
    "e277e398cf7f4f3b9045f77b5936d23a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e35a4e5afc7c4cca884ea096951e283c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8aae0f53ea7f4d748029fb27f0682f67",
       "IPY_MODEL_870b71f731fb4f1bbad10e4ce8f220e1",
       "IPY_MODEL_4affcf780bc840e2abe512444471be67"
      ],
      "layout": "IPY_MODEL_9f3995f33cf84bb08ef97942a0aa585b"
     }
    },
    "e4f187d4a06e49b284e61ffbd317e645": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e61fd9cff00042ad91957999f6a5f811": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9557c292dca4197bda09b0e731ab1db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eabb7b2d7aae4dbcb9d5b520cf3d075e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "eef683ad06b34d419483cae503b43e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3174b99cb4394c06aa299f0bca95c9cf",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f767ed5346264aee9bed5998ed5c742d",
      "value": 3
     }
    },
    "f0bb6ca5f8d0463d8f4849cbc7f47497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1e47eaabdef49bbb65a8a168ae57dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2d12a67df2c4b9abcd11a29fe70bfd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f58bd2519b834a02854123612b8d272e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6a1491312b548ab84beeddec0cb6a4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f754d8ae08ed45c9a41b3ec67ecffebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d55511b3bd4af4802faa94f5c14bee",
      "placeholder": "​",
      "style": "IPY_MODEL_468d7f1483274b12831d74364775a519",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "f767ed5346264aee9bed5998ed5c742d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f970e8b182314bdebb5af6bc2af3a4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb9bc5c4f4624055969d384b3f1efea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dfc1aeae6624a059c01d11aae47c09e",
       "IPY_MODEL_cd119fa2d44b48a483109e251b9775eb",
       "IPY_MODEL_dd4630fd33534ae2999e2052874bd2de"
      ],
      "layout": "IPY_MODEL_eabb7b2d7aae4dbcb9d5b520cf3d075e"
     }
    },
    "fc2e255d013d4f28a973fc1ce3874ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fda25a48119e4a5cbcf1b31bf2093c6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff4f6daa3c624fae96b7bfe93c387dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a7d32c78a764292b949d6947de2c9c6",
      "placeholder": "​",
      "style": "IPY_MODEL_936577ac1f284728868ec2e6d879ea59",
      "value": "config.json: 100%"
     }
    },
    "ff6811fb1f7341709d8c64625f813bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f754d8ae08ed45c9a41b3ec67ecffebd",
       "IPY_MODEL_5ed10e114bbf4c68aeca616190bccaad",
       "IPY_MODEL_3b27aaef0b154038bffcad853f222ae1"
      ],
      "layout": "IPY_MODEL_e9557c292dca4197bda09b0e731ab1db"
     }
    },
    "ff918ed720ee40fc8ed29cb2d0e4d99a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
