{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d4b8c7-6b49-47bb-8937-32ae6d972053",
   "metadata": {},
   "source": [
    "#  Intelligent Resume Screening with LangChain and LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf8cbb-097e-46fd-9a60-79b792d5ab72",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"LLMAppUsingLangchain.png\" style=\"height:400px; width: 750px\" />\n",
    "\n",
    "Generated using Lucidchart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d1e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.57.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.57.2-py3-none-any.whl (389 kB)\n",
      "   ---------------------------------------- 0.0/389.9 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 174.1/389.9 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 389.9/389.9 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 206.7/206.7 kB 6.3 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, httpcore, distro, httpx, openai\n",
      "Successfully installed distro-1.9.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.57.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain)\n",
      "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "     ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 102.4/172.0 kB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 172.0/172.0 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.24->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.24->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.3/1.0 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.7/1.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "   ---------------------------------------- 0.0/410.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 410.6/410.6 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.2.2-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.6 kB ? eta -:--:--\n",
      "   --------------------------------------  317.4/320.6 kB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 320.6/320.6 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "   ---------------------------------------- 0.0/457.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 457.0/457.0 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/2.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.5 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.12-cp311-none-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.1/135.1 kB ? eta 0:00:00\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pydantic-core, packaging, orjson, jsonpatch, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.16.2\n",
      "    Uninstalling pydantic_core-2.16.2:\n",
      "      Successfully uninstalled pydantic_core-2.16.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.1\n",
      "    Uninstalling pydantic-2.6.1:\n",
      "      Successfully uninstalled pydantic-2.6.1\n",
      "Successfully installed jsonpatch-1.33 langchain-0.3.11 langchain-core-0.3.24 langchain-text-splitters-0.3.2 langsmith-0.2.2 orjson-3.10.12 packaging-24.2 pydantic-2.10.3 pydantic-core-2.27.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.10.3 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires visions[type_image_path]==0.7.5, but you have visions 0.7.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone) (2023.7.22)\n",
      "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
      "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone) (1.26.16)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone) (0.4.6)\n",
      "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
      "   ---------------------------------------- 0.0/427.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 122.9/427.3 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  419.8/427.3 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 427.3/427.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone\n",
      "Successfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98d0eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.11 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.24)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (1.24.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB 660.6 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/2.5 MB 919.0 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/2.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/2.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.4/2.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.7/2.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.9/2.5 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.1/2.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.5 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.5/2.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.6/2.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.9/2.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.0/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.2/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.3/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.5/49.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.11 marshmallow-3.23.1 pydantic-settings-2.6.1 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910cfed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.24)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-openai) (1.57.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.2.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.55.3->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.7/50.7 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   --------------------------------------  880.6/884.5 kB 18.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 884.5/884.5 kB 18.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.2.12 tiktoken-0.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ad5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone\n",
      "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting aiohttp<3.10,>=3.9.5 (from langchain-pinecone)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-pinecone) (0.3.24)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-pinecone) (1.24.3)\n",
      "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain-pinecone)\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.8.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (0.2.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2023.7.22)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.66.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (1.26.16)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-pinecone) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (3.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-pinecone) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-pinecone) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain-pinecone) (3.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (2.0.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.3.1)\n",
      "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 122.9/370.8 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 286.7/370.8 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 370.8/370.8 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.8 kB ? eta -:--:--\n",
      "   -------------------------------------- - 235.5/244.8 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 244.8/244.8 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.4/85.4 kB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pinecone-plugin-inference, pinecone-client, aiohttp, langchain-pinecone\n",
      "  Attempting uninstall: pinecone-plugin-inference\n",
      "    Found existing installation: pinecone-plugin-inference 3.1.0\n",
      "    Uninstalling pinecone-plugin-inference-3.1.0:\n",
      "      Successfully uninstalled pinecone-plugin-inference-3.1.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.5\n",
      "    Uninstalling aiohttp-3.8.5:\n",
      "      Successfully uninstalled aiohttp-3.8.5\n",
      "Successfully installed aiohttp-3.9.5 langchain-pinecone-0.2.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pinecone 5.4.2 requires pinecone-plugin-inference<4.0.0,>=2.0.0, but you have pinecone-plugin-inference 1.1.0 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.6.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdec7-42bd-4611-9d49-3ea72a411ede",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d67554f-663c-45e0-a75d-fb303cbff229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import pinecone\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8a7cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\riyac\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb611999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path='C:/Users/riyac/Downloads/NaturalLanguageProcessing-main/NaturalLanguageProcessing-main/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945fd43b-33d8-4f6d-ad24-4f06c5e4465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['OPENAI_API_KEY']='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'\n",
    "# os.environ['PINECONE_API_KEY'] = 'pcsk_6JH24x_KS4QjYfKYKppLDKLfcEwZNviWhKrMZBeqGDTuMAi8ANmcGobmrxZ6C3nSRCcGPz'\n",
    "# os.environ['PINECONE_ENVIRONMENT'] = ''\n",
    "# #pine_cone_api=\"pcsk_6JH24x_KS4QjYfKYKppLDKLfcEwZNviWhKrMZBeqGDTuMAi8ANmcGobmrxZ6C3nSRCcGPz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439eb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Fetch API keys securely\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e836c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: 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\n",
      "PINECONE_API_KEY: pcsk_6JH24x_KS4QjYfKYKppLDKLfcEwZNviWhKrMZBeqGDTuMAi8ANmcGobmrxZ6C3nSRCcGPz\n",
      "PINECONE_ENVIRONMENT: us-west-1\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print the keys to ensure they are loaded (Optional, remove in production)\n",
    "print(\"OPENAI_API_KEY:\", openai_api_key)\n",
    "print(\"PINECONE_API_KEY:\", pinecone_api_key)\n",
    "print(\"PINECONE_ENVIRONMENT:\", pinecone_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99409953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that API keys are loaded\n",
    "if not openai_api_key or not pinecone_api_key or not pinecone_env:\n",
    "    raise ValueError(\"API keys are missing! Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df37e01c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "API keys are missing! Check your .env file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m pinecone_env \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_ENVIRONMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Validate that API keys are loadedifnot openai.api_key ornot pinecone_api_key ornot pinecone_env:\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI keys are missing! Check your .env file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: API keys are missing! Check your .env file."
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# # Fetch API keys securely\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "# pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    " \n",
    "# # Validate that API keys are loadedifnot openai.api_key ornot pinecone_api_key ornot pinecone_env:\n",
    "# raise ValueError(\"API keys are missing! Check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6fd25-b83b-4cc9-9a24-2b665c90f951",
   "metadata": {},
   "source": [
    "#### Read the (pdf) document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4890d8-69d1-40e6-8624-2c58597eb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b4782f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: pypdf in c:\\users\\riyac\\anaconda3\\lib\\site-packages (5.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\riyac\\anaconda3\\lib\\site-packages (0.3.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (0.3.24)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n",
    "!pip install PyPDF2\n",
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d6d60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = read_doc('C:/Users/riyac/Documents/Riya documents/documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3f80c4-0516-403a-b67f-5ecf386d6e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='VIREN PASALKAR\\nwww.linkedin.com/in/pviren ⋄ 410-369-6630 ⋄ vpasalk1@jh.edu\\nEDUCATION\\nJohns Hopkins University, US Aug 2022 - Dec 2023\\nMasters in Engineering Management (Major: Energy)\\nClasses: Energy & Climate Finance, Data Analytics, Risk & Decision Analysis, Energy Policy & Planning,\\nLinear & Non-linear Optimization, Environmental & Resource Economics\\nSavatribai Phule Pune University, India Aug 2016 - May 2020\\nBachelors in Computer Science\\nTECHNICAL SKILLS\\nCoding: Python 3, R, C++, Data Engineer, LCA, OSI PI, NLP, SQL, Tableau, Power BI, Excel Solver\\nAncillary: GHG Accounting, Bloomberg MC, Energy Modelling, Risk Assessment, Quantitative Analysis,\\nSAM, QGIS, Statistical Analysis, GE-MAPS, Plexos, Problem Optimization, Carbon Markets\\nPROFESSIONAL EXPERIENCE\\nResearch Analyst Intern, Solar Energy Industries Association (SEIA) Sep 2023 - Present\\n· Economic analysis of solar viability for all schools in US using PVWatts and SAM under the solar decade vision\\n· Identified dormant brown-fields projects using OpenInfraMap to identify interconnection points for new solar\\n· Incorporated NER on Storage to identify potential clients and acquired Core Solar Certification within a week\\nResearch Analyst Intern, S&P Global Jun 2023 - Aug 2023\\n· Analyzed Coal data with lagged Natural Gas prices to determine its significance and co-relation to spot price\\n· Modelled price for Powder River Coal and assessed its negative covariance to wind capacity additions in MISO\\n· Quantified global wind outlook till 2050, accounting for sustainable transition considering the capacity credit\\nAccounting & Finance Teaching Assistant, JHU (top 1%) May 2023 - Present\\n· Aided in setting syllabus & selected articles portraying real world examples of financial concepts for discussion\\n· Conduct weekly doubt-clearing sessions and guide students with regards to assignments and grade assignments\\nDeveloper, TCS Nov 2020 - Jun 2022\\n· Performed data analysis of real-time production line data to ensure smooth manufacturing of pharmaceuticals\\n· Utilized EnterprisePI to set up analyses to keep tab on data and notify sites during an outage for quick recovery\\n· Troubleshooted data discrepancies to achieve exact replication of data for BI tools on level 4 Enterprise system\\nPROJECTS & CONSULTING EXPERIENCE\\nFacial Expression Synthesis using Voice Tone Analysis(Computer Society of India InApp 2020 winner)\\n· Utilized deep learning techniques for driving 3D facial animation conveying emotion and lip-syncing by audio\\n· Network learns to map input audio to the facial landmarks while considering one hot encoded emotions data\\n· Blender then renders 3D modeled facial animation capable of lip-syncing audio input while portraying emotion\\nReduced time to administer critical antibiotics in Sepsis patients(Student Consultant, JHMI)\\n· Entrusted to achieve the golden hour for treatment of suspect Sepsis patients in the Adult Emergency Room\\n· Revamped supply-chain and proposed & improved communication channels to deal with constant alarm fatigue\\n· Reduced time to administer antibiotics by 26% in suspect Sepsis patients, mitigating potential mortality rate\\nGlobal market-entry strategy for Heat Recuperation Systems(Student Consultant, Sowillo Energy)\\n· Presented market entry opportunities and barriers for Sowillo’s product in markets like India, China and US\\n· Prioritised and initiated potential tie-ups with customers from domains having synergy with clients product\\nCOMMUNITY & LEADERSHIP\\nTaught Math for a semester to students affected by covid in US and for a year to under-privileged ones in India\\nPlanned and oversaw a state level college event as Secretary of ACM chapter, PES MCOE, 2019\\nVolunteered at Robinhood Army for 5 years, where we distributed excess food to the poor\\nParticipated in World Cleanup Day, 2018 where we carried out a river cleaning drive.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_resume = documents[-1]\n",
    "latest_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebb98f0-6be5-4031-8b88-d6398623c353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VIREN PASALKAR\\nwww.linkedin.com/in/pviren ⋄ 410-369-6630 ⋄ vpasalk1@jh.edu\\nEDUCATION\\nJohns Hopkins University, US Aug 2022 - Dec 2023\\nMasters in Engineering Management (Major: Energy)\\nClasses: Energy & Climate Finance, Data Analytics, Risk & Decision Analysis, Energy Policy & Planning,\\nLinear & Non-linear Optimization, Environmental & Resource Economics\\nSavatribai Phule Pune University, India Aug 2016 - May 2020\\nBachelors in Computer Science\\nTECHNICAL SKILLS\\nCoding: Python 3, R, C++, Data Engineer, LCA, OSI PI, NLP, SQL, Tableau, Power BI, Excel Solver\\nAncillary: GHG Accounting, Bloomberg MC, Energy Modelling, Risk Assessment, Quantitative Analysis,\\nSAM, QGIS, Statistical Analysis, GE-MAPS, Plexos, Problem Optimization, Carbon Markets\\nPROFESSIONAL EXPERIENCE\\nResearch Analyst Intern, Solar Energy Industries Association (SEIA) Sep 2023 - Present\\n· Economic analysis of solar viability for all schools in US using PVWatts and SAM under the solar decade vision\\n· Identified dormant brown-fields projects using OpenInfraMap to identify interconnection points for new solar\\n· Incorporated NER on Storage to identify potential clients and acquired Core Solar Certification within a week\\nResearch Analyst Intern, S&P Global Jun 2023 - Aug 2023\\n· Analyzed Coal data with lagged Natural Gas prices to determine its significance and co-relation to spot price\\n· Modelled price for Powder River Coal and assessed its negative covariance to wind capacity additions in MISO\\n· Quantified global wind outlook till 2050, accounting for sustainable transition considering the capacity credit\\nAccounting & Finance Teaching Assistant, JHU (top 1%) May 2023 - Present\\n· Aided in setting syllabus & selected articles portraying real world examples of financial concepts for discussion\\n· Conduct weekly doubt-clearing sessions and guide students with regards to assignments and grade assignments\\nDeveloper, TCS Nov 2020 - Jun 2022\\n· Performed data analysis of real-time production line data to ensure smooth manufacturing of pharmaceuticals\\n· Utilized EnterprisePI to set up analyses to keep tab on data and notify sites during an outage for quick recovery\\n· Troubleshooted data discrepancies to achieve exact replication of data for BI tools on level 4 Enterprise system\\nPROJECTS & CONSULTING EXPERIENCE\\nFacial Expression Synthesis using Voice Tone Analysis(Computer Society of India InApp 2020 winner)\\n· Utilized deep learning techniques for driving 3D facial animation conveying emotion and lip-syncing by audio\\n· Network learns to map input audio to the facial landmarks while considering one hot encoded emotions data\\n· Blender then renders 3D modeled facial animation capable of lip-syncing audio input while portraying emotion\\nReduced time to administer critical antibiotics in Sepsis patients(Student Consultant, JHMI)\\n· Entrusted to achieve the golden hour for treatment of suspect Sepsis patients in the Adult Emergency Room\\n· Revamped supply-chain and proposed & improved communication channels to deal with constant alarm fatigue\\n· Reduced time to administer antibiotics by 26% in suspect Sepsis patients, mitigating potential mortality rate\\nGlobal market-entry strategy for Heat Recuperation Systems(Student Consultant, Sowillo Energy)\\n· Presented market entry opportunities and barriers for Sowillo’s product in markets like India, China and US\\n· Prioritised and initiated potential tie-ups with customers from domains having synergy with clients product\\nCOMMUNITY & LEADERSHIP\\nTaught Math for a semester to students affected by covid in US and for a year to under-privileged ones in India\\nPlanned and oversaw a state level college event as Secretary of ACM chapter, PES MCOE, 2019\\nVolunteered at Robinhood Army for 5 years, where we distributed excess food to the poor\\nParticipated in World Cleanup Day, 2018 where we carried out a river cleaning drive.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_resume.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "382e6e38-622f-45d7-a799-19666ceff9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331692d2-be50-400a-9434-e5e8b15f1020",
   "metadata": {},
   "source": [
    "#### Convert the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a66505-a3de-4638-96f0-7d65a0c2db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into chunks dur to the limitation of maximum token size for the model\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    doc = text_splitter.split_documents(docs)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70df2ab4-ced7-4bc7-b1b4-1b1bc3742eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='RIYA CHADDHA \\n(857) 405-9051 | chaddha.ri@northeastern.edu | LinkedIn | GitHub  \\nEDUCATION \\nMaster of Science in Information Systems, Northeastern University               Aug 2023 – Present \\nRelevant Coursework: Programming Structures and Algorithms, Application Engineering and Development, Object Oriented \\nDesigning \\nBachelor of Engineering in Computer Science, University of Pune             Aug 2016 - May 2020       \\nRelevant Coursework: Advanced Data Structures, Object Oriented Programming, Computer Network, Database Management \\nSystem, Designing and Analysis of Algorithms                      \\nTECHNICAL SKILLS \\nProgramming Languages:           Python, Java, C++, R, Linux/Shell Scripting, JavaScript, AngularJS, Node JS, Typescript, React'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='Databases:              MySQL, Oracle SQL, SQL Server, NoSQL, PL/SQL, Snowflake \\nTools & Technologies:              VS Code, MS Azure, GitHub, REST API, Jenkins, Azure DevOps, SDLC, Agile, MVC \\nCertifications:              Python 3- Beginner to Advanced, Microsoft Azure Data Fundamentals \\nWORK EXPERIENCE \\nGraduate Teaching Assistant, Northeastern University               Sept 2024 – Present \\n• Supporting 100+ students with assignments and course administration for the Data Management and Database Design \\ncourse by providing detailed feedback on assignments, helping students apply key concepts in data management'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='Software Engineer, LTIMindtree                                                                                                                                      Jan 2021 - Jun 2023  \\n• Conducted comprehensive Reports Testing, ensuring flawless data flow between Data Warehouse and Data Mart \\n• Deployed Power BI for data visualization and validated data using SQL leveraging SSMS to generate insightful reports, \\ndriving informed decision-making reduced time spent on manual reporting by 45 hours per week \\n• Key contributor to Project Release-1 launch ensuring 94% defect-free results in UAT by collaborating within Azure DevOps \\n• Identified 60% critical defects; earned recognition from executives for a pivotal contribution to quality assurance efforts'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='• Revitalized testing speed and efficiency by 90% through the automation of Regression and Iteration Testing using the IPAT \\nframework \\nAndroid Developer Intern, Optinno Mobitech                                                                                                            Dec 2018 - Feb 2019  \\n• Developed an Android application for calling and messaging with a variety of features using Android Studio software \\n• Employed SQLite for managing contact details from the database resulting in 40% improvement in data retrieval efficiency \\n• Implemented message segregation through text analysis, categorizing incoming messages into spam and important \\nACADEMIC PROJECTS \\nHealthcare Ecosystem Application | NetBeans, Java, db4o             Nov 2023 – Dec 2023'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='• Developed a comprehensive healthcare ecosystem application using Java in Apache NetBeans \\n• Designed and implemented entities including patient, nurse, doctor, insurance broker, pharmacy, and insurance architect \\nto simulate a complete patient treatment process \\n• Utilized db4o as the database solution to efficiently store and manage session data, ensuring persistent data handling  \\nOnline Banking System | VS Code, Java               Mar 2021 - Apr 2021 \\n• Implemented an online banking system by utilizing the MVC concept and tools like Eclipse, Postman, Jenkins, VS Code \\n• Developed a full-stack online banking system using AngularJS for the front-end and Java with Spring for the back-end'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Riya Chaddha.pdf', 'page': 0}, page_content='• Integrated MySQL Connector and Hibernate for robust database connectivity and object-relational mapping \\n• Utilized Maven for build management and Jenkins for continuous integration and deployment, ensuring efficient \\ndevelopment workflows \\n• Implemented RESTful APIs to enable seamless communication between the client-side interface and server-side processes \\nIntrusion Alert System | IoT, Python, Raspberry Pi, IFTTT               Feb 2019- Mar 2019  \\n• Designed and implemented a home security alert system utilizing Raspberry Pi to detect and respond to unusual \\nmovements using IR sensor and Buzzer  \\n• Integrated the system with IFTTT application to notify the owner upon detecting activity'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='RIYA CHADDHA \\n(857) 405-9051 | Boston, MA | chaddha.ri@northeastern.edu | LinkedIn | Github \\nSUMMARY \\nA data-savvy college graduate with 2+ years of experience in Data Engineering and a solid grasp of database and business \\narchitecture, driven by a fervor for data engineering and statistical analysis, and now poised to harness analytical skills for the \\npurpose of enhancing corporate performance in the role of a Business Intelligence Engineer. \\nEDUCATION \\nMaster of Science in Information Systems, Northeastern University                              Aug 2023 - Present \\nBachelor of Engineering in Computer Science, University of Pune                          Aug 2016 - May 2020                             \\nTECHNICAL SKILLS'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='TECHNICAL SKILLS \\nProgramming Languages:          Python, Java, R, C, C++, HTML, CSS, JavaScript, AngularJS, Node JS, Typescript, React \\nDatabase & Data Warehouses:     MS SQL, MySQL, Oracle, PL/SQL, MongoDB(NoSQL), Azure Data Studio, Azure Data Factory \\nTools & Technologies:                     Power BI/DAX, Tableau, Git, RStudio, Talend, Alteryx, Snowflake, Apache Spark, Informatica \\nFrameworks:                 TensorFlow, NumPy, Pandas, OpenCV, Sci-kit learn, Matplotlib, PyTorch, Jupyter \\nRelevant Skills:                 ETL/ELT process, Data Warehousing, Data Manipulation, Statistical Analysis, NLP, LLM \\nWORK EXPERIENCE \\nData Engineer, Larsen & Toubro Infotech (LTI)                                                                   Aug 2021 - Jun 2023'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='• Created Power BI dashboards by querying, loading, and transforming data from the Warehouse and Data Mart into SSMS \\n• Contributed to a 30% increase in decision-making efficiency by delivering interactive and insightful Power BI reports \\n• Key contributor to Project Release-1 launch, ensuring 94% defect-free results in UAT by collaborating within Azure DevOps \\n• Earned recognition from executives for pivotal contribution to quality assurance efforts by identifying 60% critical defects \\nData Engineer Trainee, Larsen & Toubro Infotech (LTI)                                                                    Jan 2021 - Jul 2021  \\n• Conducted comprehensive Reports Testing, ensuring flawless data flow from Data Warehouse and Data Mart into SSMS'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='• Revitalized testing efficiency by 90% through the automation of regression and iteration testing using the IPAT framework \\n• Executed functional testing for insurance applications, including policy, claims and billing within Duck Creek environment \\nAndroid Developer Intern, Optinno Mobitech                                                                                Dec 2018 - Feb 2019  \\n• Designed and designed an Android calling and messaging app with diverse functionalities using Android Studio \\n• Employed SQLite for managing and retrieving contact details to and from the database efficiently  \\n• Implemented message segregation through text analysis, categorizing incoming messages into spam and important \\nACADEMIC PROJECTS'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='ACADEMIC PROJECTS \\nFood Inspection BI: Dallas & Chicago Data Analysis               Jan 2024 - Feb 2024 \\n• Designed and implemented dimensional modeling for analyzing food inspection data from Dallas and Chicago cities \\n• Conducted data profiling to check quality of data including missing values using Alteryx and y-data profiling tools \\n• Conducted data staging and cleaning in Talend, including addressing missing values and consolidating columns \\n• Generated Power BI and Talend dashboards to visualize the analysis done on the clean data and verified it using SSMS \\nHousing Price Prediction using Neural Networks                              Jan 2024 – Feb 2024 \\n• Implemented a neural network model for predicting housing prices using strategic feature selection to enhance accuracy'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='• Utilizing NumPy, Pandas, Seaborn, sklearn for data manipulation and preprocessing to address dataset inconsistencies \\n• Applied AutoML and SHAP analysis techniques to evaluate the optimal model, providing explanations for model outputs \\nInventory Management System                                    Nov 2023 – Dec 2023 \\n• Engineered an efficient inventory system for frozen food product management across suppliers and end-users \\n• Developed insightful Power BI reports to visualize critical information related to the top order lists and inventory stock \\n• Leveraged SQL Server Management Studio (SSMS) for the design and administration of the database infrastructure'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\RiyaChaddha Swisher.pdf', 'page': 0}, page_content='Classification and Detection of Galaxies using Faster RCNN                                                        Nov 2019 - Apr 2020 \\n• Led training of a machine learning model that successfully classifies galaxies based on the Hubble Sequence \\n• Operationalized Faster Region-based Convolutional Neural Network (R-CNN) algorithm for an 86% accuracy boost \\n• Utilized TensorFlow, Keras to train neural networks for galaxy classification, and NumPy, Pandas for data manipulation \\n• Employed OpenCV for image processing tasks, such as object detection, feature extraction and image segmentation'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='VIGNESH SANKAR \\nBoston, MA | (857) 234-9164 | sankar.vi@northeastern.edu | LinkedIn | GitHub \\nEDUCATION \\nNortheastern University                                                                                                    Sep. 2023 – Expected May 2025                                          \\nMS in Data Science; CGPA – 4.0/4.0                                                                                                                                     Boston, MA  \\n• Coursework: Data Management and Processing, Machine Learning and Algorithms. \\nAnna University                                                                                                                                       Aug. 2017 – Jun. 2021'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='B.E. – Electronics and Communication Engineering; CGPA – 8.8/10.0                                                                  Chennai, India \\n• Coursework: Linear Algebra, Data Structures, Probability and Statistics, Database Systems.                                      \\nPROFESSIONAL EXPERIENCE \\nNortheastern University                                                                                                                                  Jan. 2024 – Present \\nTeaching Assistant                                                                                                                                                                  Boston, MA \\n• Assisting the course DS3000 – “Foundations of Data Science” by hosting office hours and clarifying doubts.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='LatentView Analytics                                                                                                                                    Jun. 2021 – Aug. 2023    \\nData Analyst                                                                                                                                                                           Chennai, India                                                              \\n• Analyzed an annual flagship campaign with SQL, Databricks and Python, elevating reports to director-level \\nvisibility and achieving a 20% efficiency boost in decision-making. \\n• Developed a Hadoop data pipeline with Python to detect anomalies, reducing turnaround time by 3 days.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='• Devised an Audience Profiling Tool in Tableau, employing statistical techniques like the z-test to estimate \\ncampaign audience size, optimizing selection, and achieving a 30% efficiency boost. \\n• Engineered an A/B Testing tool in R to test newly launched campaigns, yielding a 15% optimization boost. \\n• Delivered a quarterly Excel plan with customer conversion rate breakdown and KPI analysis for 10k+ past \\ncampaigns, enhancing budget planning and increasing click and open rates from 3% to 6% QoQ. \\nCaterpillar Inc.                                                                                                                                                 Dec. 2020 – May 2021'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='Machine Learning Intern                                                                                                                                                  Chennai, India                                                                      \\n• Built a SARIMAX model in Python to predict the failure time of heavy mining equipment, which in turn and \\nreduced monitoring labour and turnaround time from 4 days to 2 days. \\n• Applied Multiclass Classification to Engine ignition impurity data points with an accuracy of 93%.  \\nACADEMIC PROJECTS \\nSample Size Estimation Tool                                                                                           \\n• Designed a quantitative marketing tool  with z-test in Tableau to compare the performance of Marketing'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='Campaigns by KPIs and other demographics with an accuracy of 90%. \\nQuora – Duplicate question pair prediction                                                                          \\n• Implemented NLP and ML Algorithms, such as SVM and Random Forest, to accurately predict duplication in \\nquestion pairs, achieving an impressive 80% accuracy rate. \\nMovie Recommendation System                                                                                       \\n• Deployed and fine -tuned a User-Based Collaborative  Movie Recommendation Engine in Python and \\nmeticulously crafted a UI in HTML, resulting in a notable performance accuracy of 86%. \\nCustomer Subscription Management System'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='• Unified a cross-functional MySQL database with a Python UI that replicates a subscription-based business \\nmodel to track the journey of customers engaged to a product. \\nUser Experience Maximization Engine \\n• Implemented a clustering engine with GMM, KMeans and DBScan to a large geospatial dataset to assign \\nTaxi drivers to the optimum nearest hub, thereby increasing user experience.  \\nTECHNICAL SKILLS \\n• Programming Languages: Python, R, SQL, MATLAB, C, C++, NoSQL, Scala, Kafka, Spark. \\n• Framework & Tools: Jira, Hive, Scikit, Pandas, PyTorch, Numpy, Matplotlib, TensorFlow, Pyspark, MongoDB. \\n• Technical Interests: Data Science, NLP, ML, Data Visualization, Deep Learning and Data Engineering.  \\nPUBLICATIONS'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Vignesh_Resume-2.pdf', 'page': 0}, page_content='PUBLICATIONS \\n• Implemented a Security Protocol for D2D Co mmunications in 5 G Networks with MATLA B and tested its \\nresilience against attacks with Scyther (A protocol verification tool)        \\nAWADS & RECOGNITION \\nLatentView Analytics                                                                                                                                                        Chennai, India.  \\n• ENCORE: Effective communication skills and timely delivery of tasks with high quality.                       Jun. 2022  \\n• SPOT: Leadership, Networking, Client Success in Agile Environment                                                         Dec. 2022'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='VIREN PASALKAR\\nwww.linkedin.com/in/pviren ⋄ 410-369-6630 ⋄ vpasalk1@jh.edu\\nEDUCATION\\nJohns Hopkins University, US Aug 2022 - Dec 2023\\nMasters in Engineering Management (Major: Energy)\\nClasses: Energy & Climate Finance, Data Analytics, Risk & Decision Analysis, Energy Policy & Planning,\\nLinear & Non-linear Optimization, Environmental & Resource Economics\\nSavatribai Phule Pune University, India Aug 2016 - May 2020\\nBachelors in Computer Science\\nTECHNICAL SKILLS\\nCoding: Python 3, R, C++, Data Engineer, LCA, OSI PI, NLP, SQL, Tableau, Power BI, Excel Solver\\nAncillary: GHG Accounting, Bloomberg MC, Energy Modelling, Risk Assessment, Quantitative Analysis,\\nSAM, QGIS, Statistical Analysis, GE-MAPS, Plexos, Problem Optimization, Carbon Markets\\nPROFESSIONAL EXPERIENCE'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='PROFESSIONAL EXPERIENCE\\nResearch Analyst Intern, Solar Energy Industries Association (SEIA) Sep 2023 - Present\\n· Economic analysis of solar viability for all schools in US using PVWatts and SAM under the solar decade vision\\n· Identified dormant brown-fields projects using OpenInfraMap to identify interconnection points for new solar\\n· Incorporated NER on Storage to identify potential clients and acquired Core Solar Certification within a week\\nResearch Analyst Intern, S&P Global Jun 2023 - Aug 2023\\n· Analyzed Coal data with lagged Natural Gas prices to determine its significance and co-relation to spot price\\n· Modelled price for Powder River Coal and assessed its negative covariance to wind capacity additions in MISO'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='· Quantified global wind outlook till 2050, accounting for sustainable transition considering the capacity credit\\nAccounting & Finance Teaching Assistant, JHU (top 1%) May 2023 - Present\\n· Aided in setting syllabus & selected articles portraying real world examples of financial concepts for discussion\\n· Conduct weekly doubt-clearing sessions and guide students with regards to assignments and grade assignments\\nDeveloper, TCS Nov 2020 - Jun 2022\\n· Performed data analysis of real-time production line data to ensure smooth manufacturing of pharmaceuticals\\n· Utilized EnterprisePI to set up analyses to keep tab on data and notify sites during an outage for quick recovery\\n· Troubleshooted data discrepancies to achieve exact replication of data for BI tools on level 4 Enterprise system'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='PROJECTS & CONSULTING EXPERIENCE\\nFacial Expression Synthesis using Voice Tone Analysis(Computer Society of India InApp 2020 winner)\\n· Utilized deep learning techniques for driving 3D facial animation conveying emotion and lip-syncing by audio\\n· Network learns to map input audio to the facial landmarks while considering one hot encoded emotions data\\n· Blender then renders 3D modeled facial animation capable of lip-syncing audio input while portraying emotion\\nReduced time to administer critical antibiotics in Sepsis patients(Student Consultant, JHMI)\\n· Entrusted to achieve the golden hour for treatment of suspect Sepsis patients in the Adult Emergency Room\\n· Revamped supply-chain and proposed & improved communication channels to deal with constant alarm fatigue'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='· Reduced time to administer antibiotics by 26% in suspect Sepsis patients, mitigating potential mortality rate\\nGlobal market-entry strategy for Heat Recuperation Systems(Student Consultant, Sowillo Energy)\\n· Presented market entry opportunities and barriers for Sowillo’s product in markets like India, China and US\\n· Prioritised and initiated potential tie-ups with customers from domains having synergy with clients product\\nCOMMUNITY & LEADERSHIP\\nTaught Math for a semester to students affected by covid in US and for a year to under-privileged ones in India\\nPlanned and oversaw a state level college event as Secretary of ACM chapter, PES MCOE, 2019\\nVolunteered at Robinhood Army for 5 years, where we distributed excess food to the poor'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\riyac\\\\Documents\\\\Riya documents\\\\documents\\\\Viren_F.pdf', 'page': 0}, page_content='Participated in World Cleanup Day, 2018 where we carried out a river cleaning drive.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8831d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAIEmbeddings with API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')  # API key should be set in the environment\n",
    "embeddings = OpenAIEmbeddings(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44e447c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa71cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\riyac\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (2023.7.22)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77126049-ad92-4dc1-a75d-85ee39a1a9b5",
   "metadata": {},
   "source": [
    "#### Generating OpenAI embeddings for previously created chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6552ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11f512b-6e79-41c5-8930-12fea139722f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000002172603E2D0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x0000021726049E50>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1dd2149-c7e0-4063-a87b-018df749d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = embeddings.embed_query(\"How are you?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0900a9-8f0a-40b7-8010-56ce5c6b7585",
   "metadata": {},
   "source": [
    "#### Create a Vector searchDB using Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1276e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\riyac\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (2023.7.22)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\riyac\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bebd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import Pinecone\n",
    "# pc = Pinecone(api_key=\"pcsk_5NcTog_PCWqkdDri72gei3npqfPuezxYDy9QxAM2KieE2H2Z6xX72CfSBeVcU3Y19hkE1v\")\n",
    "# index = pc.Index(host='https://langchain-qk9anc4.svc.aped-4627-b74a.pinecone.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65830738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index = pc.Index(host='https://langchain-qk9anc4.svc.aped-4627-b74a.pinecone.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d9fe020-8854-44bf-ad0e-8c697d503e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "        documents,\n",
    "        index_name=\"langchain\",\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bc0127d-ff15-438e-b295-112d7f78d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riyac\\AppData\\Local\\Temp\\ipykernel_30968\\3647108293.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  openai_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.4)\n",
      "C:\\Users\\riyac\\AppData\\Local\\Temp\\ipykernel_30968\\3647108293.py:5: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(openai_model, chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI model with the API\n",
    "openai_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.4)\n",
    "\n",
    "# Load the QA chain with the updated API\n",
    "chain = load_qa_chain(openai_model, chain_type=\"stuff\")\n",
    "\n",
    "# Function to retrieve matching documents from VectorDB\n",
    "def retrieve_query(query, k=2):\n",
    "    matching_results = vectorstore_from_docs.similarity_search(query, k=k)\n",
    "    return matching_results\n",
    "\n",
    "# Function to retrieve answers using the QA chain\n",
    "def retrieve_answers(query):\n",
    "    doc_search = retrieve_query(query)\n",
    "    # print(type(doc_search))\n",
    "    \n",
    "    response = chain.invoke({\"input_documents\": doc_search, \"question\": query})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3dfc94-ced3-4d7e-b60b-0cd2433c3009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, Riya Chaddha has experience in Data Engineering, database management, statistical analysis, and business intelligence. While she has worked on projects involving machine learning models like neural networks for housing price prediction and galaxy classification, the depth of her expertise in machine learning specifically is not explicitly mentioned. It would be safe to say that Riya Chaddha has some experience with machine learning but may not be classified as an expert in the field.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question1 = \"Is this person an expert in Machine Learning?\"\n",
    "answer1 = retrieve_answers(question1)\n",
    "print(answer1['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "458018f0-b86f-4e14-a964-9e4aedaff204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in Riya's resume, she has a strong background in data engineering, programming languages such as Python, and frameworks like TensorFlow and PyTorch. She also has experience with machine learning algorithms and neural networks. Given her technical skills and experience, Riya seems well-equipped to work on Generative AI and Deep Learning use cases.\n"
     ]
    }
   ],
   "source": [
    "question2 = \"Based on her resume, do you think Riya will be able to work on Generative AI and Deep learning use cases?\"\n",
    "answer2 = retrieve_answers(question2)\n",
    "print(answer2['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1370ce5-8ab9-4edf-a1ee-27e9b3a94a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, Riya Chaddha has a strong educational background in Computer Science and Information Systems, with relevant coursework and technical skills in programming languages like Java, Python, JavaScript, and frameworks like AngularJS and React. Riya also has experience in software engineering, including full-stack development projects like the Online Banking System. With her experience in front-end and back-end technologies, database management, and development tools, Riya has the potential to transition into a professional full-stack web developer.\n"
     ]
    }
   ],
   "source": [
    "question3 = \"Can Riya be a good professional full stack web developer?\"\n",
    "answer3 = retrieve_answers(question3)\n",
    "print(answer3['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2105555e-7a73-4bdc-b9eb-0ebe91728a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the general job description of a data science role, the profile of Vignesh Sankar seems highly relevant. Vignesh has a strong educational background with a Master's in Data Science, relevant coursework, and a high GPA. Additionally, their professional experience includes roles as a Data Analyst and Machine Learning Intern, where they worked on various projects involving data analysis, machine learning, and data engineering. Vignesh also has a diverse set of technical skills, experience with relevant tools and frameworks, and has published work in the field. Overall, I would rate this profile a 9 out of 10 for a data scientist position.\n"
     ]
    }
   ],
   "source": [
    "question4 = \"What do you think of this profile for a data scientist position? Rate the relevance of this profile out of 10 for \\\n",
    "            a data scientist position out of 10 based on general job description of a data science role.\"\n",
    "answer4 = retrieve_answers(question4)\n",
    "print(answer4['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4885b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the general job description of a data science role, I would rate this profile as a 9 out of 10 for a data scientist position. The candidate has a strong educational background with relevant coursework in Data Science and has practical experience in Data Analysis, Machine Learning, and Data Engineering. They have worked on various projects involving statistical analysis, machine learning algorithms, and data visualization. The technical skills align well with the requirements for a data scientist role, covering programming languages, frameworks, and tools commonly used in data science. The candidate also has experience in relevant tools like Tableau, Python, SQL, and statistical techniques. The only area that might be slightly lacking is specific experience in deep learning, but overall, this profile is quite strong for a data scientist position.\n"
     ]
    }
   ],
   "source": [
    "question5 = \"What are the candidate's primary areas of expertise?\"\n",
    "answer5 = retrieve_answers(question4)\n",
    "print(answer5['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39e6be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the general job description of a data science role, I would rate this profile as a 9 out of 10 for a data scientist position. The candidate has a strong educational background with relevant coursework, a Master's in Data Science, and a Bachelor's in Electronics and Communication Engineering. They have practical experience as a Data Analyst and Teaching Assistant, showcasing hands-on skills in SQL, Python, Tableau, and various data science techniques. The candidate has worked on a variety of projects related to data analysis, machine learning, and data engineering, demonstrating a diverse skill set. Additionally, they have technical skills in various programming languages, frameworks, and tools commonly used in data science roles. The only area that might be improved is more specific experience in certain advanced techniques or tools, but overall, the profile is very strong for a data scientist position.\n"
     ]
    }
   ],
   "source": [
    "question6 = \"Summarize this candidate's professional background\"\n",
    "answer6 = retrieve_answers(question4)\n",
    "print(answer6['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a3bd31-ad03-4974-94d4-d172f81c44d8",
   "metadata": {},
   "source": [
    "### References\n",
    " \n",
    "1. **Streamlit**: [Streamlit Documentation](https://docs.streamlit.io/)\n",
    "2. **LangChain**: [LangChain Documentation](https://langchain.readthedocs.io/)\n",
    "3. **OpenAI API**: [OpenAI API Documentation](https://platform.openai.com/docs/)\n",
    "4. **Pinecone**: [Pinecone Documentation](https://docs.pinecone.io/)\n",
    "5. **PyPDF**: [PyPDF Documentation](https://pypdf2.readthedocs.io/)\n",
    "6. **Embedding Models**: [OpenAI’s text-embedding-ada-002](https://platform.openai.com/docs/guides/embeddings)\n",
    "7. **Semantic Search**: [Pinecone Semantic Search](https://www.pinecone.io/learn/semantic-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d479f7-1e7a-492d-8cd2-4f460485c78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
