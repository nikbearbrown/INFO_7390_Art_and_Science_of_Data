Hi, I’m Aashish. I’m working on this project as part of my Master’s Project for Summer 2, and I have been actively involved since the first day of classes. I will be contributing to this project through the end of August 2025.

### Below are the links to the Jupyter Notebooks that I created:
Introduction: https://colab.research.google.com/drive/1JCiHxjbQndtlRq1eZpmpU8c4XWDiLW7k?usp=sharing </br>
Bias Detection Methodologies: https://colab.research.google.com/drive/1pTyC2pETlBdlQaQIAMxiXw9fllQtSWKC#scrollTo=MNwO8J6WLTCg</br>
Ai Bias Case Studies: https://colab.research.google.com/drive/1At5CZ3nOAFWJWa1DkmlDprzXD5Wdicvg#scrollTo=W4n2_4foJiRw</br>
Integration with Botspeak: https://colab.research.google.com/drive/1NVFAEADgIMY94aTAN2--y3JM9AFD4z48#scrollTo=7UBAHhFlLDpT</br>
Drive Link Containing Videos: https://drive.google.com/drive/folders/1_lH5WkPfqmlgsuANxDvX8rsXVRd7wIs7

## Week 1 (Starting July 7, 2025):
- Created a Jupyter notebook explaining what bias is, including its mathematical definition and real-world examples.
- Researched and documented various types of bias commonly encountered in machine learning systems, along with real world examples.

## Week 2 (July 14, 2025):
- Working on providing hands-on exercise for Module 3.
- Created Readmes for modules 1-5
- Updated Jupyter Notebook with concepts of bias detection methodologies

## Week 3 (July 21, 2025):
- Created a new Jupyter Notebook with hands-on exercises for different bias detection methodologies
- Created scripts for 2 videos of the bias detection methodologies

## Week 4 (July 28, 2025):
- Created 2 new scripts for 2 more videos of the bias detection methodologies
- Created 4 videos for the four bias detection methodologies

## Week 5 (Aug 4, 2025):
- Created a jupyter notebook for AI Bias case studies
- Created a script and a video for the same
- Created detailed youtube captions for all the 5 videos
- Created a jupyter notebook for Integration with Botspeak framework

## Week 6 (Aug 11, 2025):
- Created 2 Videos for Integration with Botspeak framework
- Created Youtube captions for the same and updated all other youtube captions
- Researched about how we can build AI agents which will help us detect Bias and mitigate it

## Week 7 (Aug 18, 2025):
- Created a video speaking about how to make a video
- Updated all the previous videos with Intro and Outros

# Module 3: Bias Detection and Mitigation in AI

## Overview

This module explores the critical intersection of bias and artificial intelligence, examining how AI systems can inherit, amplify, or create biases that impact their decisions and outputs. Students will develop both the theoretical understanding and practical skills necessary to identify, measure, and mitigate various forms of bias in AI systems.

## Philosophical Foundations

The module begins with an exploration of implicit and cognitive biases through philosophical lenses. We examine how human biases shape the data we collect, the algorithms we design, and ultimately the AI systems we deploy. Key philosophical questions include:

- Do AI systems merely reflect societal biases, or do they create new forms of bias?
- Can an AI system ever be truly "neutral" or "objective"?
- What responsibility do AI developers have in addressing systemic biases?

We'll study perspectives from feminist philosophy, critical race theory, and postmodernism to understand how power structures and privilege influence AI development and deployment.

## Learning Objectives

By the end of this module, students will be able to:

1. Identify different types of bias in AI systems (sampling bias, measurement bias, algorithmic bias, etc.)
2. Apply quantitative metrics to detect and measure bias in datasets and model outputs
3. Implement bias mitigation techniques at various stages of the AI pipeline
4. Critically evaluate the ethical implications of biased AI systems
5. Articulate the relationship between social power structures and technological systems
6. Apply the Botspeak pillars of Ethical Reasoning and Stochastic Reasoning to bias recognition

## Key Topics

### 1. Types of Bias in AI
- **Data-Related Biases** create the foundation for unfair outcomes through problematic training data(Historical Bias, Representation Bias, Measurement Bias) 
- **Algorithmic Biases** amplify these problems through technical design choices(Aggregation Bias, Selection Bias, Confirmation Bias, Measurement Bias)
- **Cognitive and Human Biases** prevent proper oversight and correction(Evaluation Bias, Anchoring Bias, Automation Bias)
- **Deployment and Feedback Biases** ensure that biases persist and worsen over time(Interaction Bias, Feedback Loops)

### 2. Bias Detection Methodologies
- Statistical measures of fairness and bias
- Intersectional analysis of model outputs
- Counterfactual testing approaches
- Bias auditing tools and frameworks

### 3. Mitigation Strategies
- Pre-processing techniques (data reweighing, sampling methods)
- In-processing techniques (adversarial debiasing, constraint-based methods)
- Post-processing techniques (calibration, threshold adjustments)
- Holistic approaches to bias mitigation

### 4. Case Studies in AI Bias
- Facial recognition and racial bias
- Natural language processing and gender bias
- Predictive policing and socioeconomic bias
- Healthcare AI and accessibility bias

### 5. Integration with Botspeak Framework
- Applying Ethical Reasoning to identify normative concerns in AI systems
- Using Stochastic Reasoning to understand probabilistic aspects of bias
- Critical Evaluation methods for bias detection
- Technical Understanding of model architectures and their relationship to bias

## Assignments and Activities

1. **Bias Audit Project**: Students will conduct a comprehensive bias audit of an existing AI system or dataset, documenting their methodology and findings.

2. **Bias Mitigation Implementation**: Implement and compare multiple bias mitigation strategies on a biased dataset, analyzing the tradeoffs between fairness and model performance.

3. **Philosophical Analysis**: Write a critical essay examining one type of AI bias through the lens of a specific philosophical framework (e.g., feminist ethics, utilitarianism, deontology).

4. **Interactive Bias Visualization**: Create an interactive visualization that demonstrates how bias manifests in AI outputs and how various mitigation strategies affect those outputs.

5. **Group Discussion**: Participate in structured discussions about the ethical implications of biased AI systems and the challenges of creating truly fair AI.

## References

1. Gebru, T., et al. (2021). "Datasheets for Datasets." Communications of the ACM[Link](https://cacm.acm.org/research/datasheets-for-datasets/)

2. Barocas, S., Hardt, M., & Narayanan, A. (2023). "Fairness and Machine Learning: Limitations and Opportunities"[Link](https://mitpress.ublish.com/book/fairness-and-machine-learning-limitations-and-opportunities)

3. Benjamin, R. (2019). "Race After Technology: Abolitionist Tools for the New Jim Code." Polity[Link](https://www.politybooks.com/bookdetail?book_slug=race-after-technology-abolitionist-tools-for-the-new-jim-code--9781509526390)

4. D'Ignazio, C., & Klein, L. F. (2020). "Data Feminism." MIT Press[Link](https://data-feminism.mitpress.mit.edu/)

## Recommended Tools

- Fairlearn: Microsoft's toolkit for assessing and improving fairness in AI systems [Link](https://github.com/fairlearn/fairlearn)
- AI Fairness 360: IBM's comprehensive toolkit for bias detection and mitigation [Link](https://github.com/Trusted-AI/AIF360)
- What-If Tool: Google's interactive visual interface for understanding model behavior [Link](https://pair-code.github.io/what-if-tool/)
- Aequitas: An open-source bias audit toolkit for machine learning developers [Link](https://dssg.github.io/aequitas/)

## Resources

### Academic Papers
- Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). "Semantics derived automatically from language corpora contain human-like biases." Science.
- Buolamwini, J., & Gebru, T. (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." Proceedings of the Conference on Fairness, Accountability and Transparency.

### Online Resources
- [Fairness in Machine Learning Course](https://fairmlclass.github.io/)
- [Tutorial on Fairness in AI](https://sites.google.com/view/fairness-tutorial/home?authuser=0)

## Connection to Final Project

For students focusing on bias detection and mitigation in their final projects, this module provides essential theoretical frameworks and practical tools. Your project should demonstrate not only technical solutions to bias, but also thoughtful consideration of the philosophical and ethical dimensions explored in this module.
