Hi, I’m Neha, and I’m working on this project as part of my OPT contract
Jupyter Notebook link: https://colab.research.google.com/drive/1UkakHHEerssKb9IZuAFNVRT_Y1Sc8Ipg

Week 1 (July 21): 
- Attended multiple meetings and finalized the project.

Week 2 (July 28):
* Created a jupyter notebook and started working on Module 1-Section 1. Researched and documented about Botspeak, prompt engineering, skepticism and its philosophical pillars.
  
Week 3 (Aug 4):
* Created scripts and videos on “Skepticism” with focus on Cartesian doubt
* Created scripts for Hume’s problem of induction, and Popper’s falsifiability.
* Added real-world case studies illustrating certain vs. uncertain knowledge, including medical AI label inconsistency and AI hallucinations in healthcare.
* Documented key philosophical challenges for AI trust, such as non-stationarity, overfitting, bias, and Black Swan events.
* Integrated empirical knowledge limitations in AI with examples from NLP hallucinations.

Week 4 (Aug 11):
* Created scripts on Section 2 covering "Framework Overview: The Botspeak System"
* Research about Structured Methodology for AI Interaction and what are the methods (e.g. Clarify the Question Before Asking, Iterative Query and Verification, Cross-Model & Cross-Source Validation).
* Research about Balancing AI Capabilities with Human Oversight method.

Week 5 (Aug 18):
* Created 3 videos on methods for Structured Methodology for AI Interaction.
* Drive Link : https://drive.google.com/drive/folders/1hRR4IiVU8rITdy0rM3BmNFd6N_UBW2ll
* Continued Research on Section 2 for other parts - Continuous Validation and Critical Assessment Protocols.

Week 6 (Aug 29):
* Started Working on Section 5.
* Created detailed scripts for titles in the “Integration with Computational Skepticism” section.
* Outlined key concepts of systematic doubt, emphasizing the need to rigorously question AI outputs rather than accepting claims at face value.Included examples of high-stakes AI failures, such as IBM Watson for Oncology, to illustrate real-world consequences of unvalidated AI systems.
* Scripted content on computational validation methods, including adversarial testing and robustness evaluation, showing how AI vulnerabilities can be systematically detected.
* Developed segments on balancing skepticism with productive human-AI collaboration, using studies like Stanford CheXaid to demonstrate AI as a “second reader” under human oversight.
* Added coverage of continuous assessment frameworks, such as TensorFlow Data Validation, highlighting techniques for detecting data drift, schema anomalies, and performance degradation over time.
* Ensured all scripts aligned with the Botspeak principles of Cartesian doubt, epistemic rigor, and embedding skepticism into practical AI workflows.

Week 7 (Sept 05):
* For Section 2 - Created video section on Balancing AI Capabilities with Human Oversight, emphasizing role clarity, continuous feedback, and fail-safe governance in high-stakes systems.Added case studies from autonomous driving, healthcare diagnostics, and financial trading to highlight human–AI accountability mechanisms.
* Documented Continuous Validation and Critical Assessment Protocols, covering automated fact-checking, ground-truth revalidation, human escalation, and feedback loops. Integrated findings from multiple peer-reviewed sources demonstrating performance improvements when humans remain in the loop.
* Produced videos on Integration of Philosophical Rigor with Practical AI, showing how Descartes, Hume, and Popper’s principles map directly into workflows. Highlighted practical applications of falsifiability, explainability, and ethical oversight across healthcare, finance, and policing systems.
* Ensured that Botspeak’s philosophical pillars are connected to applied governance practices, bridging theory with real-world human–AI collaboration.
* For Section 5 - Created videos on “Integration with Computational Skepticism”, covering systematic doubt, computational validation methods, human-AI collaboration, and continuous assessment frameworks.


# Module 1: Botspeak - The Nine Pillars of AI Fluency

## Overview

This foundational module introduces students to the theoretical and practical frameworks that will guide their exploration of computational skepticism and AI fluency throughout the course. Students will develop both the philosophical understanding and practical skills necessary to navigate the complex landscape of human-AI collaboration effectively.

By examining classical skeptical traditions and their modern applications to artificial intelligence, students will establish a critical foundation for evaluating AI systems and learn essential skills for productive human-AI interaction across diverse domains.

## Philosophical Foundations

The module begins with an exploration of skepticism in philosophy, examining how classical thinkers approached questions of knowledge, certainty, and validation. We study the works of Descartes, Hume, and Popper to understand how systematic doubt and critical inquiry can be applied to modern AI systems. Key philosophical questions include:

- How can we apply Cartesian doubt to AI-generated outputs and claims?
- What does Hume's problem of induction tell us about trusting AI predictions?
- How can Popper's falsifiability criterion guide AI model validation?
- What is the relationship between philosophical skepticism and computational validation?

We'll examine how these classical frameworks provide essential tools for developing healthy skepticism about AI capabilities while maintaining productive collaboration with AI systems.

## Learning Objectives

By the end of this module, students will be able to:

- Articulate the philosophical foundations of skepticism and their relevance to AI evaluation
- Understand and apply the complete Botspeak framework for human-AI collaboration
- Identify and describe each of the nine pillars of AI fluency with practical examples
- Distinguish between automation, augmentation, and agency modes in human-AI interaction
- Apply systematic doubt and critical evaluation to AI outputs and claims
- Integrate philosophical thinking with practical AI collaboration strategies

## Key Topics

### 1. Philosophical Foundations of Skepticism

**Descartes and Systematic Doubt:**
- Method of doubt and its application to AI validation
- Distinguishing between certain and uncertain knowledge in AI contexts
- Building reliable knowledge from first principles

**Hume and the Problem of Induction:**
- Challenges of predicting future outcomes from past data
- Implications for trusting AI predictions and recommendations
- Understanding the limits of empirical knowledge in AI systems

**Popper and Falsifiability:**
- Applying falsifiability criteria to AI model validation
- The role of hypothesis testing in AI development
- Critical rationalism and continuous model improvement

### 2. Framework Overview: The Botspeak System

The Botspeak framework represents a comprehensive approach to human-AI collaboration that emphasizes:
- Structured methodology for AI interaction
- Balance between leveraging AI capabilities and maintaining human oversight
- Continuous validation and critical assessment protocols
- Integration of philosophical rigor with practical application

### 3. The Nine Pillars of AI Fluency

**Strategic Delegation:**
- Identifying tasks appropriate for AI automation vs. human oversight
- Understanding AI capabilities and limitations in different domains
- Developing frameworks for effective task allocation

**Effective Communication:**
- Mastering prompt engineering and instruction clarity
- Interpreting AI responses within appropriate contexts
- Establishing clear communication protocols with AI systems

**Critical Evaluation:**
- Applying systematic skepticism to AI outputs
- Developing validation methodologies for AI claims
- Identifying potential errors, biases, and limitations

**Technical Understanding:**
- Gaining sufficient knowledge of AI architectures and processes
- Understanding the relationship between data, algorithms, and outputs
- Recognizing technical constraints and possibilities

**Ethical Reasoning:**
- Considering moral implications of AI deployment and use
- Ensuring human values guide AI implementation
- Addressing ethical dilemmas in AI decision-making

**Stochastic Reasoning:**
- Understanding probability, uncertainty, and randomness in AI
- Calibrating confidence levels in AI predictions
- Working effectively with probabilistic AI outputs

**Learning by Doing:**
- Embracing iterative experimentation with AI systems
- Developing practical fluency through hands-on engagement
- Building experience through systematic practice

**Rapid Prototyping:**
- Quickly testing ideas and validating concepts using AI tools
- Iterating on solutions efficiently
- Balancing speed with quality in AI-assisted development

**Theoretical Foundation:**
- Maintaining grounding in fundamental principles
- Adapting to rapidly evolving AI capabilities
- Connecting practical applications to underlying theory

### 4. Interaction Modes in Human-AI Collaboration

**Automation Mode:**
- AI systems operating independently within defined parameters
- Human oversight and intervention capabilities
- Appropriate use cases and risk management

**Augmentation Mode:**
- AI enhancing human capabilities while humans maintain decision authority
- Collaborative problem-solving approaches
- Balancing human judgment with AI insights

**Agency Mode:**
- AI systems operating with greater autonomy within ethical boundaries
- Human strategic guidance and goal-setting
- Managing AI agency responsibly and effectively

### 5. Integration with Computational Skepticism

Connecting philosophical skepticism with practical AI validation:
- Applying systematic doubt to AI claims and outputs
- Developing computational methods for validation
- Balancing skepticism with productive AI collaboration
- Creating frameworks for continuous assessment and improvement

## Assignments and Activities

**Skeptical Analysis Project:** Students will analyze a recent AI application or claim using classical skeptical frameworks, documenting their methodology and findings while applying Cartesian doubt, Humean induction problems, or Popperian falsifiability.

**Botspeak Framework Application:** Apply all nine pillars to a real-world AI collaboration scenario, demonstrating understanding of each pillar and their integration in practice.

**Philosophical Essay:** Write a critical analysis examining how one classical skeptical philosopher's work applies to modern AI validation challenges, connecting historical ideas to contemporary issues.

**Interaction Mode Analysis:** Evaluate an existing AI system and recommend optimal interaction modes for different use cases, justifying recommendations based on the Botspeak framework.

**Critical Evaluation Exercise:** Practice systematic doubt and validation techniques on AI-generated content, developing personal protocols for ongoing AI assessment.

## References

**Classical Philosophy:**
- Descartes, R. "Meditations on First Philosophy" (selected passages)
- Hume, D. "An Enquiry Concerning Human Understanding" (relevant sections)
- Popper, K. "The Logic of Scientific Discovery" (key chapters)

**Contemporary AI Philosophy:**
- Russell, S. "Human Compatible: Artificial Intelligence and the Problem of Control"
- Floridi, L. "The Fourth Revolution: How the Infosphere is Reshaping Human Reality"

## Recommended Tools

**AI Interaction Platforms**:

- [OpenAI Playground](https://platform.openai.com/playground)
- [Claude (Anthropic)]( https://claude.ai)
- [ChatGPT](https://chat.openai.com)
- [Google Gemini](https://gemini.google.com/)

**Prompt Engineering Tools**:

- PromptLayer - https://www.promptlayer.com (Advanced prompt management and evaluation)
- PromptPerfect - https://promptperfect.jina.ai (AI prompt optimization for multiple models)
- Prompt Engineering Guide - https://www.promptingguide.ai (Comprehensive prompting techniques)
  
**AI Validation Frameworks**:

- NIST AI Risk Management Framework - https://www.nist.gov/itl/ai-risk-management-framework
- AI Verify (Singapore) - https://aiverifyfoundation.sg (AI governance testing framework)
- Robust Intelligence AI Validation - https://www.robustintelligence.com/platform/ai-validation
- NIST AI Test, Evaluation, Validation and Verification - https://www.nist.gov/ai-test-evaluation-validation-and-verification-tevv

**Critical Evaluation Tools**:

- SHAP (SHapley Additive exPlanations) - [Link](https://shap.readthedocs.io)
- LIME (Local Interpretable Model-agnostic Explanations) - [Link](https://lime-ml.readthedocs.io)
- Fairlearn (Bias detection and mitigation) - [Link](https://fairlearn.org)
- What-If Tool (Model behavior analysis) - [Link](https://pair-code.github.io/what-if-tool)

## Resources

**Academic Papers**:

- Evaluating Human-AI Collaboration: A Review and Methodological Framework - [Link](https://arxiv.org/abs/2407.19098)
- Epistemology and Artificial Intelligence - [Link](https://www.sciencedirect.com/science/article/pii/S1570868304000473)
- AI and Epistemic Agency: How AI Influences Belief Revision - [Link](https://www.tandfonline.com/doi/full/10.1080/02691728.2025.2466164)
- Systematic Literature Review of Validation Methods for AI Systems - [Link](https://www.sciencedirect.com/science/article/pii/S0164121221001473)

**Online Resources**:

- Stanford Encyclopedia of Philosophy: Computational Philosophy - [Link](https://plato.stanford.edu/entries/computational-philosophy/)
- Anthropic's AI Fluency: Frameworks and Foundations Course - [Link](https://www.anthropic.com/ai-fluency)
- Partnership on AI: Human-AI Collaboration Framework & Case Studies - [Link](https://partnershiponai.org/paper/human-ai-collaboration-framework-case-studies/)
- TrueSciPhi.AI: Computational Philosophy Resources - [Link](https://www.truesciphi.ai/p/computational-philosophy)
- Daily Nous: Philosophy of AI / AI Ethics Syllabi, Lessons, Readings - [Link](https://dailynous.com/2024/12/10/philosophy-of-ai-ai-ethics-syllabi-lessons-readings/)

## Connection to Final Project

For students focusing on foundational AI collaboration frameworks in their final projects, this module provides essential theoretical grounding and practical tools. Your project should demonstrate not only technical implementation of collaboration strategies, but also thoughtful consideration of the philosophical and methodological dimensions explored in this module.

Students will be expected to apply the complete Botspeak framework, showing how all nine pillars work together to create effective and responsible human-AI collaboration systems.
