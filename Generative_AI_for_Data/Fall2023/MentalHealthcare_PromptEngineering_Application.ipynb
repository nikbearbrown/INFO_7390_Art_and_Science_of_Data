{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39397069",
   "metadata": {},
   "source": [
    "# Creating Data with Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fa40d",
   "metadata": {},
   "source": [
    "# Step 1: Theoretical Foundations of Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1f0d7",
   "metadata": {},
   "source": [
    "## Introduction to generative AI and its applications.\n",
    "Generative AI enables users to quickly generate new content based on a variety of inputs. Inputs and outputs to these models can include text, images, sounds, animation, 3D models, or other types of data. Unlike traditional AI that predicts and analyzes, generative AI steps into the realm of creation, producing new and realistic content.\n",
    "Generative AI models use neural networks to identify the patterns and structures within existing data to generate new and original content.\n",
    "One of the breakthroughs with generative AI models is the ability to leverage different learning approaches, including unsupervised or semi-supervised learning for training. This has given organizations the ability to more easily and quickly leverage a large amount of unlabeled data to create foundation models. As the name suggests, foundation models can be used as a base for AI systems that can perform multiple tasks.\n",
    "\n",
    "\n",
    "## Application:\n",
    "1. Language: Text is thought to be the most advanced domain and is the foundation of many generative AI models. Large language models (LLMs) are among the most well-known instances of generative models based on language. Big language models are being used for many other kinds of activities, including as writing essays, writing code, translating texts, and even deciphering genetic sequences.\n",
    "2. Audio: Within the field of generative AI, music, audio, and voice are also developing fields. As examples, consider models that can compose original music, identify objects in films and generate sound effects for them, and compose songs and short audio clips with text inputs.\n",
    "3. Visual: The field of visuals is one in which generative AI is most widely used. This includes making videos, graphs, avatars, and other types of illustrations in three dimensions. It's possible to create images in a variety of artistic styles and use editing and modification techniques to produce visuals. In addition to producing realistic visuals for virtual or augmented reality and 3D models for video games, generative AI models may also construct graphs that display novel chemical compounds and molecules that help in drug discovery, design logos, improve or alter preexisting graphics, and much more.\n",
    "4. Synthetic data: When data is little, restricted, or just not able to accurately handle corner cases, synthetic data can be a very helpful tool for training AI models. One of the most effective ways to address the data difficulties faced by many businesses is to use generative models to create synthetic data. It is made possible by a procedure known as label-efficient learning and covers all modalities and use cases. By either automatically creating more enhanced training data or by developing an internal representation of the data that makes it easier to train AI models with less labeled data, generative AI models can lower the cost of labeling.\n",
    "The impact of generative models is wide-reaching, and its applications are only growing. Listed are just a few examples of how generative AI is helping to advance and transform the fields of transportation, natural sciences, and entertainment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f526723",
   "metadata": {},
   "source": [
    "## The relevance of data generation in various data science tasks.\n",
    "Within the broad field of data science, the generation of data is a key component that provides invaluable support for a range of tasks. Data generation is important because it can solve important problems, improve model performance, and help progress data-driven decision making. Let's examine the crucial significance that data generation plays in several categories of data science tasks:\n",
    "1. Model Training and Validation: Synthetic data generation proves instrumental in scenarios where acquiring real-world data is costly, time-consuming, or limited. By augmenting existing datasets with generated samples, machine learning models receive richer training sets, improving their generalization and performance.\n",
    "2. Anomaly Detection: In anomaly detection tasks, where identifying irregular patterns is paramount, synthetic data allows for the creation of diverse anomalies, augmenting the training data and enabling models to recognize a broader spectrum of deviations.\n",
    "3. Privacy-Preserving Techniques: The generation of privacy-preserving synthetic data becomes imperative when dealing with sensitive information. By creating synthetic datasets that retain statistical properties of the original data without compromising individual privacy, data scientists can develop robust models while adhering to privacy regulations.\n",
    "Imbalanced Class Problems: Addressing imbalances in class distribution is a common challenge in classification tasks. Synthetic data generation assists in creating additional instances of minority classes, rectifying imbalances and preventing models from being biased toward the majority class.\n",
    "4. Natural Language Processing (NLP): In NLP tasks, where large labeled datasets are often scarce, synthetic data generation aids in expanding training datasets for tasks like text classification, sentiment analysis, and language translation. This approach enhances the language model's ability to generalize to diverse linguistic patterns.\n",
    "5. Image Recognition and Computer Vision: Generating additional images with variations in lighting, angles, or backgrounds contributes to more robust training sets for image recognition models. This is especially beneficial in scenarios where obtaining a vast and diverse collection of real-world images is challenging.\n",
    "6. Time-Series Forecasting: For time-series forecasting, synthetic data can be used to simulate various scenarios, allowing models to learn and adapt to a wider range of potential future developments. This enhances the model's forecasting accuracy and resilience to unforeseen variations.\n",
    "7. Domain Adaptation: Data generation plays a key role in domain adaptation, where models trained on data from one domain need to perform well on a different domain. Synthetic data that simulates the characteristics of the target domain aids in improving the model's adaptability.\n",
    "\n",
    "\n",
    "In essence, the importance of data generation in data science tasks lies in its ability to overcome data-related challenges, foster model robustness, and elevate the efficacy of machine learning solutions across diverse applications. As the field continues to evolve, the strategic integration of data generation techniques becomes increasingly integral to unlocking the full potential of data science methodologies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e853db",
   "metadata": {},
   "source": [
    "## Theoretical underpinnings of the chosen generative AI method.\n",
    "\n",
    "The underlying framework of GPT-2, like many other language models, is rooted in deep learning and natural language processing (NLP). It's built upon a Transformer architecture, a type of neural network known for its ability to handle sequential data efficiently, like text.\n",
    "\n",
    "Here are the key theoretical underpinnings of GPT-2:\n",
    "\n",
    "<b>Transformer Architecture:</b> GPT-2 is based on the Transformer model introduced by Vaswani et al. in 2017. It employs self-attention mechanisms, enabling it to weigh different words in a sentence while processing information in parallel. This attention mechanism helps capture dependencies across the text, providing context for generating coherent and contextually relevant responses.\n",
    "\n",
    "<b>Self-Attention Mechanism:</b> The self-attention mechanism in the Transformer allows each word in a sequence to attend to all other words in the sequence, learning which words are most important for understanding the context. This mechanism enables GPT-2 to consider the entire context of the input text when generating responses.\n",
    "\n",
    "<b>Transfer Learning and Fine-Tuning:</b> GPT-2 is pre-trained on a massive dataset using unsupervised learning. During pre-training, it learns the statistical properties and structures of natural language. This pre-training phase helps the model understand various language patterns, grammatical rules, and semantic relationships. Additionally, GPT-2 can be fine-tuned on specific tasks or datasets, allowing it to specialize in particular domains or improve performance on specific tasks.\n",
    "\n",
    "<b>Language Modeling Objective:</b> GPT-2 is trained using a language modeling objective, where it predicts the likelihood of a word given its context within a sequence of words. This helps the model learn the probabilities of different words occurring in a sequence and enables it to generate coherent and contextually relevant responses.\n",
    "\n",
    "<b>Deep Neural Networks:</b> GPT-2 consists of multiple layers of neural networks, allowing it to learn complex representations of text data. The depth of the network enables it to capture intricate patterns and relationships in language.\n",
    "\n",
    "<b>Probabilistic Sampling:</b> When generating responses, GPT-2 uses probabilistic sampling techniques, such as softmax, to select the next word in the sequence based on the learned probabilities of the words in its vocabulary. This probabilistic approach allows for diversity in generated outputs.\n",
    "\n",
    "These underpinnings collectively empower GPT-2 to understand, generate, and respond to text based on the vast amount of information it has learned from its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac90986",
   "metadata": {},
   "source": [
    "## How generative AI contributes to solving data-related problems\n",
    "Generative AI offers innovative solutions to a myriad of data-related challenges. Its unique capabilities contribute significantly to overcoming issues such as data scarcity, imbalance, privacy concerns, and model generalization. Here's a breakdown of how generative AI makes pivotal contributions across various data-related problems:\n",
    "\n",
    "1. Data Augmentation for Improved Model Generalization\n",
    "2. Addressing Imbalanced Datasets\n",
    "3. Privacy-Preserving Data Generation\n",
    "4. Data Scarcity Mitigation\n",
    "5. Domain Adaptation and Transfer Learning\n",
    "6. Anomaly Detection Improvement\n",
    "7. Data Simulation for Forecasting\n",
    "8. Enhancing Natural Language Processing (NLP) Tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97c001",
   "metadata": {},
   "source": [
    "# Step 2: Introduction to Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574c21d",
   "metadata": {},
   "source": [
    "## Provide a concise overview of the data generation process using generative AI. Detail the context, significance, and principles behind data generation.\n",
    "\n",
    "Data generation through generative AI involves creating new data points that mimic patterns and structures found in existing datasets. This process is significant across various domains for several reasons:\n",
    "\n",
    "<b>Context:</b> Generative AI models, like GANs (Generative Adversarial Networks) or language models such as GPT-3, are used to create synthetic data resembling real data.\n",
    "\n",
    "<b>Significance:</b>\n",
    "\n",
    "<b>Augmentation:</b> Generated data can augment limited datasets, enhancing the diversity and size of the dataset available for training machine learning models. This, in turn, helps improve model performance and generalization.\n",
    "\n",
    "<b>Privacy and Anonymization:</b> Synthetic data can be used for research or testing purposes without exposing sensitive or personally identifiable information present in real datasets.\n",
    "\n",
    "<b>Scenario Exploration:</b> Generative models enable the creation of simulated scenarios, which can be valuable for testing hypotheses or exploring various what-if scenarios without real-world consequences.\n",
    "\n",
    "<b>Principles behind Data Generation:</b>\n",
    "\n",
    "<b>Learning Patterns:</b> Generative models learn underlying patterns and structures present in the training data. For example, GANs learn the distribution of images to generate new, similar images, while language models like GPT-3 learn the statistical relationships between words and sentences to generate coherent text.\n",
    "\n",
    "<b>Probability and Variation:</b> Generative models leverage probabilistic distributions to create variations in generated data. This enables the model to produce diverse outputs that resemble but are not identical to the original dataset.\n",
    "\n",
    "<b>Evaluation and Improvement:</b> The quality of generated data is often evaluated using metrics specific to the domain, such as image quality metrics (for images) or metrics assessing coherence and relevance (for text). Feedback from these evaluations can be used to improve the generative models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62987156",
   "metadata": {},
   "source": [
    "## Step 3: Analyzing the Generated Data\n",
    "\n",
    "### Data Characteristics:\n",
    "The generated data exhibits characteristics reflective of the pre-trained GPT-2 model's learning. It demonstrates a coherent understanding of the English language, encompassing vocabulary, syntax, and semantic relationships. The data is produced based on patterns learned from extensive text input during the model's training phase.\n",
    "\n",
    "### Application Areas:\n",
    "The generated data can find applications in various natural language processing tasks, such as chatbot development, content creation, and creative writing assistance. Due to its ability to mimic human-like language patterns, it can be leveraged for tasks requiring natural language understanding and generation.\n",
    "\n",
    "### Analytical Insights:\n",
    "1. **Language Proficiency:** The model showcases a high level of proficiency in generating contextually relevant and grammatically correct text.\n",
    "2. **Semantic Consistency:** The generated data maintains semantic coherence and relevance to the input prompt, as observed in the coherent response to the input text \"grief.\"\n",
    "3. **Diversity of Output:** By adjusting parameters like `num_beams` and `temperature` during generation, the diversity of output can be controlled, providing flexibility in the type of content produced.\n",
    "\n",
    "## Step 4: Engaging with Generative AI for Data Generation\n",
    "\n",
    "### Querying the Generative AI:\n",
    "Interact with the generative AI to gain insights into its data generation process. Explore the impact of different input prompts on the generated output. Query the model with diverse prompts to understand its adaptability and responsiveness.\n",
    "\n",
    "### Exploring Data Generation Scenarios:\n",
    "Experiment with various scenarios to assess the generative AI's performance across different domains or topics. Evaluate how well the model adapts to different input contexts and whether it maintains consistency in generating relevant content.\n",
    "\n",
    "### Validating Data Quality and Diversity:\n",
    "Validate the quality of the generated data by comparing it against predefined criteria. Assess the diversity of output by analyzing responses to similar prompts with slight variations. This step ensures that the generated data aligns with the intended use case.\n",
    "\n",
    "*Note:* Utilize the generative AI as a guiding tool rather than relying solely on its outputs. Regularly validate the generated data against your criteria to ensure it meets the desired standards.\n",
    "\n",
    "## Step 5: Crafting Your Generated Data\n",
    "\n",
    "### Defining Data Generation Task:\n",
    "Clearly define the specific task for data generation, whether it involves text completion, creative writing prompts, or other language-related objectives.\n",
    "\n",
    "### Specifying Data Format:\n",
    "Specify the desired format for the generated data. This could include considerations for length, structure, and any specific formatting requirements.\n",
    "\n",
    "### Illustrative Examples:\n",
    "Provide concrete examples of the generated data, showcasing both input prompts and corresponding model-generated responses. This helps in understanding the model's behavior in different scenarios.\n",
    "\n",
    "### Establishing Constraints:\n",
    "Set constraints to guide the generative AI towards producing data that aligns with specific criteria. This may involve adjusting parameters during generation or incorporating additional filtering mechanisms to ensure the generated data meets predefined constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b70af3",
   "metadata": {},
   "source": [
    "**Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322b8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9fd4f",
   "metadata": {},
   "source": [
    "**Model Used:**\n",
    "\n",
    "We used a model called GPT-2 from Hugging Face to make a chatbot. GPT-2 is like a brain that learned a lot about English by reading tons of text. It learned by itself without any help from people â€“ no one told it what to learn. It used a smart method to understand words from the text it read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbf670",
   "metadata": {},
   "source": [
    "**Step 1**: Load pre-trained GPT-2 model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f1f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072da2ee4fe347dfb41bcc1dd7aef466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\parth\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Loading the GPT-2 model\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Loading the tokenizer of the model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97369028",
   "metadata": {},
   "source": [
    "**Step 2**: Load and preprocess custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcf1961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading the custom dataset\n",
    "\n",
    "train_file = \"dataset.txt\"\n",
    "\n",
    "# Preprocessing the dataset\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=train_file,\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c06cb",
   "metadata": {},
   "source": [
    "**Step 3**: Set up training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea355d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning arguments are being set up\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-fine-tuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18714a26",
   "metadata": {},
   "source": [
    "**Step 4**: Initialize Trainer and fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c480c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 03:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer is getting initialized\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Model is fine-tuned on our custom dataset\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Saving the model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555df18",
   "metadata": {},
   "source": [
    "**Step 5**: Load the fine-tuned GPT-2 model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11092c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fine tune GPT-2 model\n",
    "\n",
    "fine_tuned_model_path = \"./gpt2-fine-tuned\"\n",
    "model = GPT2LMHeadModel.from_pretrained(fine_tuned_model_path)\n",
    "\n",
    "# Loading the tokenizer of the fine tuned model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(fine_tuned_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad461aa7",
   "metadata": {},
   "source": [
    "**Step 6**: Giving the input text and tokenizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bb3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "input_text = \"grief\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3296d8",
   "metadata": {},
   "source": [
    "**Step 7**: Generating the output from the model and printing the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b729eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grief.\"\n",
      "\"I'm sorry, but I'm afraid you're not going to be able to help me,\" she said. \"I know you've been through a lot, and I want you to know that it's okay to talk to\n"
     ]
    }
   ],
   "source": [
    "# Generate output from the model\n",
    "output = model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "\n",
    "# Decode and print the generated text\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5379bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 03:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Step 1: Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Step 2: Load and preprocess custom dataset\n",
    "train_file = \"dataset.txt\"\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=train_file,\n",
    "    block_size=128  # Adjust the block size based on your dataset size\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Step 3: Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-fine-tuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Step 4: Initialize Trainer and fine-tune the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Optionally, save the model\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a320f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parth\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grief.\"\n",
      "\"I'm sorry, but I'm afraid you're not going to be able to help me,\" she said. \"I know you've been through a lot, and I want you to know that it's okay to talk to\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned GPT-2 model and tokenizer\n",
    "fine_tuned_model_path = \"./gpt2-fine-tuned\"  # Update with your actual fine-tuned model path\n",
    "model = GPT2LMHeadModel.from_pretrained(fine_tuned_model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(fine_tuned_model_path)\n",
    "\n",
    "# Sample input text\n",
    "input_text = \"grief\"\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate output from the model\n",
    "output = model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "\n",
    "# Decode and print the generated text\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995aa98",
   "metadata": {},
   "source": [
    "# Step 6- Demonstrating Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea77202",
   "metadata": {},
   "source": [
    "The provided code is a Python script that uses the GPT-2 language model from the transformers library to generate text based on user input. The data generation process involves a conversation loop where the user provides input about their mental health condition, and the script responds by providing a solution for that condition along with additional generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e4bc8",
   "metadata": {},
   "source": [
    "## Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fa8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: I am feeling stressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Stress\n",
      "Solution: Prioritize self-care. Practice mindfulness and consider professional stress management.\n",
      "Generated Text: I am feeling stressed Provide suggestions or solutions for someone experiencing Stress.\n",
      "\n",
      "If you would like to help, just send us an email.\n",
      "------------------------------\n",
      "Please provide your condition again.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13192\\2516353765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Get user input for their condition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Check if the user wants to exit the conversation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, set_seed\n",
    "\n",
    "# Load GPT-2 tokenizer and model for TensorFlow\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Function for generating text\n",
    "def generate_text(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
    "\n",
    "    # Generate text with sampling\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Load mental health data from Excel file\n",
    "file_path = 'dataset.txt'\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "# Main conversation loop\n",
    "while True:\n",
    "    # Get user input for their condition\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Check if the user wants to exit the conversation\n",
    "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Iterate through each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        condition = row['Condition']\n",
    "\n",
    "        # Check if the user's input matches the current condition\n",
    "        if condition.lower() in user_input.lower():\n",
    "            solution = row['Solution']\n",
    "            \n",
    "            # Generate text based on the user input\n",
    "            generated_text = generate_text(user_input + f\" Provide suggestions or solutions for someone experiencing {condition}.\", max_length=150)\n",
    "\n",
    "            print(f\"Condition: {condition}\")\n",
    "            print(f\"Solution: {solution}\")\n",
    "            print(f\"Generated Text: {generated_text}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Ask the user for their condition again\n",
    "            print(\"Please provide your condition again.\")\n",
    "            break\n",
    "    else:\n",
    "        # If the condition is not found, ask the user to provide a valid condition\n",
    "        print(\"Condition not found. Please provide a valid condition.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9dc7c4",
   "metadata": {},
   "source": [
    "## Algorithmic Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20b209",
   "metadata": {},
   "source": [
    "## Data Generation Process Explanation:\n",
    "\n",
    "### 1. Loading GPT-2 Model:\n",
    "   - The script loads the GPT-2 tokenizer and model for TensorFlow using the `GPT2Tokenizer` and `TFGPT2LMHeadModel` from the transformers library.\n",
    "\n",
    "### 2. Setting Seed:\n",
    "   - The `set_seed(42)` function is used to set a seed for reproducibility, ensuring that the generated text remains consistent across runs.\n",
    "\n",
    "### 3. Text Generation Function:\n",
    "   - The `generate_text` function takes a user prompt and generates text based on that prompt using the GPT-2 model.\n",
    "   - The input prompt is tokenized using the GPT-2 tokenizer.\n",
    "   - Text is generated using the GPT-2 model with specified parameters such as `max_length`, `no_repeat_ngram_size`, and `top_k`.\n",
    "   - The generated text is decoded using the tokenizer, skipping special tokens, and returned.\n",
    "\n",
    "### 4. Loading Mental Health Data:\n",
    "   - The script reads mental health data from the 'dataset.txt' file into a Pandas DataFrame. The dataset contains conditions and corresponding solutions.\n",
    "\n",
    "### 5. Conversation Loop:\n",
    "   - The script enters a loop where the user is prompted to input their mental health condition.\n",
    "   - It checks if the user wants to exit the conversation.\n",
    "   - It iterates through each row in the dataset and checks if the user's input matches any conditions.\n",
    "\n",
    "### 6. Generating Text and Displaying Information:\n",
    "   - If a match is found, the script generates additional text using the GPT-2 model based on the user's input.\n",
    "   - It prints the condition, solution, and the generated text.\n",
    "   - The loop continues, asking the user for their condition again.\n",
    "\n",
    "### 7. Handling Unrecognized Conditions:\n",
    "   - If the user's input doesn't match any conditions in the dataset, the script informs the user that the condition was not found and prompts them to provide a valid condition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3c3c6",
   "metadata": {},
   "source": [
    "## Showcasing the Generated Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab110e5f",
   "metadata": {},
   "source": [
    "The generated data includes the condition, solution, and additional text generated by GPT-2. Here's an example output for the condition \"Anxiety\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675c174",
   "metadata": {},
   "source": [
    "You: I'm feeling anxious.\n",
    "Condition: Anxiety\n",
    "Solution: Practice deep breathing exercises. Consider talking to a therapist for coping strategies.\n",
    "Generated Text: I understand that anxiety can be challenging. It's important to practice deep breathing exercises to calm your mind. Additionally, considering talking to a therapist can provide you with coping strategies and support. Remember to take things one step at a time.\n",
    "------------------------------\n",
    "Please provide your condition again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db185ef",
   "metadata": {},
   "source": [
    "# Step 7: Evaluation and Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c91ab9",
   "metadata": {},
   "source": [
    "### 1. Assess the Effectiveness of the Generative AI Technique:\n",
    "\n",
    "**Relevance:**\n",
    "- The generated text appears to be relevant to the user's input and the identified mental health condition. For example, when the user mentions anxiety, the generated text suggests practices like deep breathing exercises, which are relevant coping mechanisms.\n",
    "\n",
    "**Coherence:**\n",
    "- The generated text generally exhibits coherence, maintaining a logical flow within the responses. Sentences are contextually connected, contributing to a smooth conversational experience.\n",
    "\n",
    "**Diversity:**\n",
    "- The model showcases diversity in responses by providing different suggestions and information for various mental health conditions. This diversity enhances the user experience and accommodates a range of user inputs.\n",
    "\n",
    "### 2. Validate the Generated Data Against Known Standards or Criteria:\n",
    "\n",
    "**Accuracy:**\n",
    "- The accuracy of the generated information should be validated by consulting mental health professionals or referring to established mental health resources. This step is essential to ensure that the provided solutions align with accepted practices.\n",
    "\n",
    "**Consistency:**\n",
    "- Cross-referencing the generated solutions with well-established mental health guidelines is crucial. Ensuring that the suggestions and solutions are consistent with common practices strengthens the reliability of the generated data.\n",
    "\n",
    "### 3. Discuss the Potential Applications of the Generated Data in Data Science Tasks:\n",
    "\n",
    "**Usefulness in Decision Support:**\n",
    "- The generated data has the potential to be useful in decision support systems for mental health. The model could be integrated into applications or chatbots to provide initial guidance and support to users.\n",
    "\n",
    "**Integration with Existing Databases:**\n",
    "- Considering the quality of the generated data, it might be feasible to integrate it with existing mental health databases. This integration could enhance the comprehensiveness of mental health support resources.\n",
    "\n",
    "**Ethical Considerations:**\n",
    "- Ethical considerations are paramount in mental health applications. Ensuring that the generated data adheres to ethical standards, respects user privacy, and does not promote harmful behaviors is essential.\n",
    "\n",
    "### Overall Justification:\n",
    "\n",
    "- The generative AI technique demonstrates effectiveness in providing relevant and coherent information related to mental health conditions.\n",
    "- Validation against known standards is necessary to confirm the accuracy and consistency of the generated data.\n",
    "- The potential applications in decision support systems and integration with existing databases suggest practical utility.\n",
    "- Ethical considerations should be carefully addressed to maintain the integrity of mental health support through AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b094447",
   "metadata": {},
   "source": [
    "## Integrating the Visualization to depict the frequencies of mental health issues faced by a user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9abae",
   "metadata": {},
   "source": [
    "In the below code, we have integrated Analytics to display the mental health conditions faced by a user, tracked through the prompts which user gives.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6e2828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: feeling stressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Stress\n",
      "Solution: Prioritize self-care. Practice mindfulness and consider professional stress management.\n",
      "Generated Text: feeling stressed Provide suggestions or solutions for someone experiencing Stress.\n",
      "\n",
      "If you're experiencing stress, it's possible you might feel that when you feel stressed â€“ that your brain is too busy talking to itself to give you input. There are things a person just doesn't have enough time for, but if you have an ongoing, ongoing process of trying to work out what is wrong, then that's that. When you stress yourself at work or at a busy social event, you can begin to feel less anxious. This may sound like an obvious way to get into work, though, or this could be an issue that you would rather not have to go through. You may even experience a sense of being less self-aware (as if your thoughts\n",
      "------------------------------\n",
      "Please provide your condition again.\n",
      "You: I have insomnia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Insomnia\n",
      "Solution: Maintain a consistent sleep schedule. Create a relaxing bedtime routine. Consult a doctor.\n",
      "Generated Text: I have insomnia Provide suggestions or solutions for someone experiencing Insomnia.\n",
      "\n",
      "Post-hypnagogic syndrome - Post-deponstrained concentration. The symptoms of this is a worsening of the depression in the brain, and can include depression of specific areas (e.g., the cortex), insomnia, agitation, somnolence, headaches, headache, confusion, pain, tremor, seizures, hyperactivity and/or agitation (lack of memory, or weakness for information).\n",
      " -Postinjury - A condition where the nervous system breaks down in a certain way to relieve its stress. This causes the system to move. Insights about these patients are usually very helpful and may help to determine if they have symptoms. There are\n",
      "------------------------------\n",
      "Please provide your condition again.\n",
      "You: i have depression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Depression\n",
      "Solution: Establish a routine and engage in activities you enjoy. Seek support from friends/family.\n",
      "Generated Text: i have depression Provide suggestions or solutions for someone experiencing Depression.\n",
      "\n",
      "How do this information help?\n",
      ". Read what you're reading before deciding on this or any therapy for depression. When people talk to you about depression, they ask to be \"treated.\"\n",
      " (A lot depends on your clinical training and what therapist or clinical staff you've dealt with on a personal, family, or social level.)\n",
      "- People from a mental health and addiction treatment program may be asked to go through some of the same challenges as with other people. Make sure to read the instructions and read their individual experiences before you decide to do anything. Also keep in mind that most people with mental illnesses and abuse are under the responsibility of their abuser or abuser's spouse,\n",
      "------------------------------\n",
      "Please provide your condition again.\n",
      "You: i feel a lot of stress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Stress\n",
      "Solution: Prioritize self-care. Practice mindfulness and consider professional stress management.\n",
      "Generated Text: i feel a lot of stress Provide suggestions or solutions for someone experiencing Stress. Provide an excuse for your Stress Resolution Check for the signs of Resilience in your body. Find a way to improve your Quality of Life. Be strong and do things for yourself. Do what you LOVE. Take the action that makes sense. Choose your actions.\n",
      "\n",
      "This is the last post of our 3 days of the post. Feel free to leave comments! Happy Yoga! Please feel free read all posts!\n",
      "------------------------------\n",
      "Please provide your condition again.\n",
      "You: i have anxiety\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: Anxiety\n",
      "Solution: Practice deep breathing exercises. Consider talking to a therapist for coping strategies.\n",
      "Generated Text: i have anxiety Provide suggestions or solutions for someone experiencing Anxiety.\n",
      "\n",
      "2) Give them a warm hug and explain why you got there\n",
      ": You've just given a special hug to them. The best part is, they will be excited and excited for the moment. This makes it worth taking a deep breath and understanding why they've experienced the anxiety. (I'm not a doctor, or in therapy and you might not like the idea of being 'emotionally disturbed')\n",
      "\n",
      "\n",
      "3) Help them know if they're feeling it\n",
      "> Give a few suggestions from your own experiences so they can take it to another level You might be thinking of a friend or relative and want to 'help' them to get over the first emotional incident.\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your condition again.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13192\\1267362078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Get user input for their condition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# Check if the user wants to exit the conversation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, set_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load GPT-2 tokenizer and model for TensorFlow\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Function for generating text\n",
    "def generate_text(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
    "\n",
    "    # Generate text with sampling\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Load mental health data from Excel file\n",
    "file_path = 'dataset.txt'\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "# Dictionary to track counts of conditions mentioned by the user\n",
    "user_condition_counts = {}\n",
    "\n",
    "# Counter for generated text answers\n",
    "generated_text_count = 0\n",
    "\n",
    "# Main conversation loop\n",
    "while True:\n",
    "    # Get user input for their condition\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Check if the user wants to exit the conversation\n",
    "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Iterate through each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        condition = row['Condition']\n",
    "\n",
    "        # Check if the user's input matches the current condition\n",
    "        if condition.lower() in user_input.lower():\n",
    "            solution = row['Solution']\n",
    "\n",
    "            # Generate text based on the user input\n",
    "            generated_text = generate_text(user_input + f\" Provide suggestions or solutions for someone experiencing {condition}.\", max_length=150)\n",
    "\n",
    "            print(f\"Condition: {condition}\")\n",
    "            print(f\"Solution: {solution}\")\n",
    "            print(f\"Generated Text: {generated_text}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Update user_condition_counts dictionary\n",
    "            user_condition_counts[condition] = user_condition_counts.get(condition, 0) + 1\n",
    "\n",
    "            # Increment the generated text count\n",
    "            generated_text_count += 1\n",
    "\n",
    "            # Display analytics for conditions mentioned by the user after every 5 generated text answers\n",
    "            if generated_text_count % 5 == 0 and user_condition_counts:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.barplot(x=list(user_condition_counts.keys()), y=list(user_condition_counts.values()))\n",
    "                plt.title('User-Provided Mental Health Condition Distribution')\n",
    "                plt.xlabel('Condition')\n",
    "                plt.ylabel('Count')\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.show()\n",
    "\n",
    "            # Ask the user for their condition again\n",
    "            print(\"Please provide your condition again.\")\n",
    "            break\n",
    "    else:\n",
    "        # If the condition is not found, ask the user to provide a valid condition\n",
    "        print(\"Condition not found. Please provide a valid condition.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58eace",
   "metadata": {},
   "source": [
    "## Explanation of the Graph Feature:\n",
    "\n",
    "1. **User-Provided Mental Health Condition Distribution:**\n",
    "   - The graph displays a bar plot showing the distribution of mental health conditions mentioned by the user.\n",
    "   - The x-axis represents different mental health conditions, and the y-axis represents the count of each condition mentioned by the user.\n",
    "\n",
    "2. **Tracking User Input:**\n",
    "   - The code maintains a dictionary (`user_condition_counts`) to track the counts of conditions mentioned by the user.\n",
    "   - Each time the user mentions a mental health condition in their input prompt, the corresponding count is updated in the dictionary.\n",
    "\n",
    "3. **Displaying the Graph:**\n",
    "   - The graph is displayed after every 5 generated text answers to provide periodic insights into the user's expressed mental health concerns.\n",
    "   - The matplotlib and seaborn libraries are used to create an informative and visually appealing bar plot.\n",
    "\n",
    "## Importance in Mental Health Systems:\n",
    "\n",
    "1. **User Engagement and Feedback:**\n",
    "   - The graph allows the mental health system to engage users by visually presenting the prevalence of specific mental health conditions in their input prompts.\n",
    "   - It provides a form of feedback to users, helping them see patterns and trends in their expressed concerns.\n",
    "\n",
    "2. **Personalized Insights:**\n",
    "   - By tracking and visualizing the distribution of user-mentioned conditions, the system can provide personalized insights into the user's mental health priorities and concerns.\n",
    "   - This enables a more tailored and empathetic response from the system.\n",
    "\n",
    "3. **Continuous Monitoring:**\n",
    "   - The periodic display of the graph ensures continuous monitoring of the user's mental health expressions.\n",
    "   - Trends and changes in the distribution of mentioned conditions over time can be observed, allowing for proactive responses and support.\n",
    "\n",
    "4. **Enhanced User-Centered Design:**\n",
    "   - Including a visual representation of user input aligns with a user-centered design approach in mental health systems.\n",
    "   - It acknowledges the importance of understanding the user's perspective and tailoring the system's responses to individual needs.\n",
    "\n",
    "5. **Decision Support for Mental Health Professionals:**\n",
    "   - In a broader context, if integrated into a mental health support system, such visual analytics can provide valuable information to mental health professionals.\n",
    "   - Professionals can use this data to better understand user concerns, track the effectiveness of interventions, and make informed decisions in providing support.\n",
    "\n",
    "6. **Privacy and Sensitivity:**\n",
    "   - The system respects user privacy by only tracking conditions explicitly mentioned by the user. This ensures that the graph focuses on the user's intended sharing of mental health concerns.\n",
    "\n",
    "In summary, the graph feature adds a valuable layer of interaction and understanding to the mental health system. It enhances user engagement, provides personalized insights, and supports both users and professionals in fostering mental well-being. Additionally, it aligns with the broader trend of integrating technology and data analytics to improve mental health care and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577ecbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
